<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml"
	schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main"> La TEI pour les corpus linguistiques: un standard qui se renouvelle</title>
            <author>
               <name>
                  <forename>Lou</forename>
                  <surname>Burnard</surname>
               </name><affiliation/>
               <email>lou.burnard@gmail.com</email>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>Lou Burnard Consulting</publisher>
             <availability>
               <p>Creative Commons Attribution 4.0 International</p>
            </availability>
            <date>February 2017</date>
         </publicationStmt>
         <seriesStmt>
            <title level="j">Lou Burnard Consulting</title>
            <biblScope unit="issue" n="1701">Submission draft</biblScope>
         </seriesStmt>
         <sourceDesc>
            <p>No source, born digital.</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="fr">fr</language>
         </langUsage>
         <textClass>
            <keywords xml:lang="en">
               <term>Text Encoding Initiative</term>
               <term>ODD language</term>
               <term>XML Customization</term>
               <term>Standards</term>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change when="2017-01-29">Stylistic tweaks from Marjorie; continued de-onification</change>
         <change when="2017-01-29">Typos from Mathieu; spellcheck</change>
         <change when="2017-01-26">More or less complete</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract">
            <p>Depuis plusieurs décennies, la Text Encoding Initiative (TEI) est un standard incontournable
               pour l’encodage des ressources textuelles et des métadonnées en sciences humaines, notamment
               pour les ressources linguistiques et littéraires. Après avoir considéré la variété des efforts
               de standardisation possibles (top-down et bottom-up, générique et spécifique) nous évoquerons
               le contexte historique dont l’Initiative a émergé, et ses effets sur son architecture,
               notamment sur la flexibilité et la capacité à être modifié du système. Nous discuterons des
               étapes typiques d’une application réussie de la TEI, en considérant quelques cas spécifiques,
               et nous terminerons avec la proposition selon laquelle la longévité du standard TEI serait en
               grande partie due à ses capacités de mutation et à sa flexibilité.</p>
         </div>
         <div type="acknowledgements">
       <!--     <head>Note de l’auteur</head>
      -->      <p>L’auteur tient à remercier chaleureusement ses collègues Mathieu et Marjorie pour leur
               relecture patiente de ce texte, dont la lisibilité est due en grande partie à leur aide
               précieuse, et assume l’entière responsabilité des barbarismes anglo-saxons qui subsistent.</p>
         </div>
      </front>
      <body>
         <div>
            <head>Combien de standards faut-il dans le monde ?</head>
            <p>Face à la complexité et à la fragmentation du monde scientifique actuel, nous constatons une
               croissance inévitable des standards, chacun bien adapté aux besoins et aux priorités d’une
               communauté donnée, mais inutile, incompréhensible, voire contraire aux intérêts d’une autre.
               Pour bien fonctionner, tout standard de métadonnées devrait être capable de co-exister avec
               tout autre, permettant ainsi une interaction mutuelle. Par conséquent, il y a une tendance à
               construire des standards de plus en plus <soCalled>méta</soCalled>, de plus en plus ambitieux.
               Ainsi sont élaborés à la fois des politiques globales, des standards génériques, capable de
               gérer tous les points de vues particuliers, tout en permettant leur propre continuité, et en
               même temps des standards de plus en plus minutieux, spécialisés pour les contextes de plus en
               plus précis. Et les standards naissent et évoluent et se multiplient dans un paysage complexe.
               En somme, il n’est guère difficile de trouver des standards. Le problème reste de savoir
               comment choisir parmi eux.</p>
            <p>On peut les distinguer nettement par rapport aux agences responsables de leur création et de
               leur maintenance. Par exemple, les standards ressortant des agences officielles de
               standardisation, au niveau national (l’AFNOR, l’ANSI, le BSI, ou le DIN en Europe) ou
               international (ISO, IEC, W3C, OASIS ...) sont forcément élaborés et gérés d’une autre manière
               que les standards émanant des industries intéressées (LISA, MPEG ...); les politiques d’accès
               aux standards seront assez différentes dans ces deux cas. Et pour le monde scientifique,
               nombreux sont les projets ayant des enjeux pré-normatifs, tels que les projets français du
               Consortium Cahier, Ortolang etc.<note>Pour Cahier voir https://cahier.hypotheses.org/, pour
                  Ortolang https://www.ortolang.fr/</note> en même temps que des agences (DARIAH,
                  CLARIN...)<note>Pour ces infrastructures voir http://www.dariah.eu/ et
                  https://www.clarin.eu/</note> qui ont comme mission la promotion des standards et des bonnes
               pratiques qui y sont associées. Et (mais peut-être un peu moins qu’avant) les enjeux des
               agences appartenant au monde scientifique risquent toujours de se différencier de ceux qui sont
               nés du monde des affaires ou dans les sociétés privées. </p>
            <p>On peut aussi positionner les standards selon leur manière de répondre à la question <q>Combien
                  de standards faut-il au monde ?</q>, pour gérer les complexités déjà évoquées. La plus
               simple des réponses serait de dire <q>un seul</q>: il faut trouver une solution centralisée et
               dirigiste, qu’on pourrait caricaturer avec l’acronyme WKWBFY (We Know What’s Best For You). À
               l’autre extrême nous pourrions répondre <q>aucun</q> et rester satisfait des
                  <soCalled>standards</soCalled> entièrement anarchiques, en supposant que chacun des
               utilisateurs aurait ses propres besoins, même ses propres perceptions, jusqu’au point où aucun
               standard ne serait possible parce que (encore un acronyme) NWEUMP (Nobody Will Ever Understand
               My Problems). Et entre ces deux extrêmes nous allons répondre <q>autant qu’il s’en crée</q>: la
               solution pragmatique ou laissez-faire, qui suivrait bêtement les voix qui crient le plus fort:
               la solution FTH (Follow The Herd).</p>
            <p>Si ces remarques ont l’air un peu cyniques, c’est peut-être à cause du fait que les normes ne
               s’imposent pas aisément dans la vie intellectuelle. Soit elles émergent d’un besoin de la
               communauté; soit leur usage dérive de la nécessité d’utiliser une technologie particulière,
               mais le scientifique ne renonce pas volontairement à son indépendance scientifique !
               Quelques-uns de nos collègues ont même tendance à s’imaginer qu’ils peuvent se passer des
               standards. Pour ces collègues, les standards constituent un inconvénient majeur : il n’est pas
               forcément souhaitable de figer un état de la connaissance, mais la standardisation l’exige.
               Ceux qui sont en train de formuler de nouvelles hypothèses et de revoir constamment la
               structuration d’un problème ont bien raison d’envisager d’un œil sceptique la nécessité d’une
               standardisation jugée prématurée et étouffante. D’ailleurs, la production des standards est
               toujours chronophage, nécessitant des compétences interdisciplinaires qui ne sont pas forcément
               à la portée de tout scientifique. De même, l’apprentissage et l’utilisation des standards peut
               être également chronophage. </p>
            <p>Néanmoins, les standards disposent de plusieurs avantages qu’il faut montrer à ces collègues
               sceptiques. En l’absence de standards numériques, comment sur le web identifier et retrouver
               des ressources numériques ayant un intérêt linguistique ? Comment valider les résultats
               scientifiques obtenus par d’autres personnes ? Comment enrichir ou intégrer les ressources
               existantes avec ses propres idées ? Comment séparer les ressources des outils qui les gèrent ou
               les analysent ? Pour tout cela, les standards restent essentiels. Ils répondent aussi à
               plusieurs besoins techniques, que tout scientifique devrait reconnaître : par exemple, la
               possibilité de recombiner ou de réutiliser les systèmes existants; l’évolution modulaire des
               logiciels ; la réduction des coûts de formation ; et la possibilité de profiter de l’existence
               de <q>frequently answered questions</q> &#x2014; des solutions qui s’appliquent dans plusieurs
               domaines. Les standards offrent donc des possibilités qui ne doivent pas être négligées ! </p>
         </div>
         <div>
            <head>Origines et enjeux de la TEI</head>
            <p>Dans le domaine des Humanités numériques, la Text Encoding Initiative (TEI) <note>Le site du
                  Consortium TEI se trouve à l’adresse www.tei-c.org: parmi plusieurs textes introductifs,
                  nous citons celui du présent auteur <title>Qu’est-ce que la TEI?</title> (Open Edition
                  Press; 2015 http://books.openedition.org/oep/1237)</note> est responsable de l’un des
               standards scientifiques les plus établis, et les plus discutés, même par les gens qui ne s’en
               servent pas, et cela pour de bonnes raisons. D’abord, la lecture est au cœur des études de
               sciences humaines, et lire, c’est encoder. L’interprétation des mots d’un objet écrit n’est pas
               aléatoire : elle est guidée par les signes de ponctuation, par les changements de police, par
               leur disposition spatiale etc ! Pour indiquer les mêmes choses (et d’autres) dans un texte
               numérique, un balisage devient essentiel, car c’est le balisage qui sert à exprimer nos
               lectures préalables, et qui rend possible une polyvalence des ressources textuelles. Le
               balisage induit également des réflexions profondes sur la matérialité des textes concernés.</p>
            <p>Plus précisément, le terme TEI (Initiative pour l’Encodage Textuel) est utilisé pour identifier
               trois choses différentes: <list rend="bulleted">
                  <item>un ensemble de recommandations pour l’encodage des ressources numériques en XML</item>
                  <item>une infrastructure internationale responsable de la maintenance, de l’évolution, et de
                     la distribution de ces recommandations </item>
                  <item>une communauté internationale d’utilisateurs de ces recommandations</item>
               </list> Ainsi serait-il peut-être préférable de considérer la TEI plutôt comme un cadre
               permettant de réfléchir sur ce que c’est qu’un texte numérisé que comme un standard fixe. </p>
            <p>Dès sa conception initiale en 1987, la Text Encoding Initiative s’est proposée comme méthode
               permettant de faciliter la construction, la description, la structuration, et l’annotation des
               corpus linguistiques et littéraires &#x2014; de tous types, de toutes périodes, dans toutes les
               langues. Elle a été conçue comme format pivot, son but étant de rendre possible l’échange,
               voire l’interopérabilité de tous les formats incompatibles des médias déjà prévus à cette
               époque. La TEI précédait le Web, le DVD, le téléphone portable, la télévision câblée, et
               Microsoft Word. Or, vu que les technologies informatiques qui survivent plus de 5 ans sont
               assez rares, la question qui s’impose aujourd’hui est : pourquoi et comment la TEI a-t-elle
               survécu plus de 30 ans ? J’essaie de répondre à cette question en conclusion, mais je commence
               avec un point sur les circonstances de sa naissance. </p>
            <p>Du point de vue historique, la TEI est le produit d’une rarissime conjonction d’intérêts de
               plusieurs communautés scientifiques. Les chercheurs littéraires, les stylométriciens, les
               critiques de l’école <soCalled>close reading</soCalled> de même que les historiens, les
               archivistes, et les éditeurs; les bibliographes, les bibliothécaires; et bien sûr les
               linguistes, notamment, mais pas exclusivement, de corpus; sans parler des informaticiens ...
               toutes ces communautés scientifiques se sentaient concernées par le passage au numérique des
               textes écrits ou oraux à grande échelle. À la fin des années 80 apparaîssaient déjà sous forme
               numérique des fonds essentiels aux sciences humaines et sociales (par exemple de grands
               dictionnaires comme le Oxford English Dictionary, ou des corpus textuels comme le Thesaurus
               Linguae Graecae), et cela dans des formats très divers. Au moment de la naissance de ce que
               nous appelons de nos jours les Humanités numériques, les scientifiques se sont déjà aperçus de
               la risque d’une nouvelle confusion des langues avec l’arrivée de l’informatique dans la
               représentation des données textuelles !</p>
            <p>En même temps, la TEI prétendait fournir une réponse pratique aux deux oppositions typiques des
                  <soCalled>Humanités numériques</soCalled> : c’est-à-dire, premièrement l’opposition entre
               les besoins des débutants et ceux des experts; et deuxièmement l’opposition entre les besoins
               et les intérêts des scientifiques et ceux des ingénieurs. </p>
            <p>En ce qui concerne l’opposition entre experts et novices, la TEI essayait de satisfaire les
               deux. D’un côté, elle cherchait à présenter et soutenir des solutions déjà connues,
               consensuelles, bien établies: les topoï sur lesquels <q>tout le monde s’est mis d’accord</q>
               &#x2014; et que les débutants devaient donc arriver à comprendre. De l’autre, elle cherchait à
               soutenir la recherche, et donc la découverte des solutions aux questions pas encore posées, ou
               même formulables &#x2014; permettant ainsi aux experts de partager leur expertise. De cette
               tension sont nés les efforts de la TEI pour permettre à la fois une certaine rigueur dans ces
               propositions, sans fermer la porte à des modifications assez fondamentales de ces mêmes
               propositions. </p>
            <p>Par rapport aux tensions voire incompréhensions entre les informaticiens et les
               non-techniciens, la TEI proposait (et propose toujours) aux ingénieurs un système bien adapté à
               l’implantation des outils informatiques courants, tout en essayant de s’exprimer dans une
               langue compréhensible aux non-techniciens, et dérivée des concepts bien établis dans les
               sciences humaines. Le but était d’assurer une compréhension mutuelle: que les techniciens
               arrivent à comprendre le modèle de base des SHS, et que les chercheurs arrivent à s’exprimer en
               profitant d’un modèle plus ou moins formalisé. C’est pour cela que la documentation du système
               TEI est aussi importante, ressemblant à la fois à un dictionnaire savant du dix-neuvième siècle
               et à un manuel d’encodage du vingtième. </p>
            <p>De plus, et en dépit de son nom, la TEI ne s’adressait pas uniquement au texte proprement dit.
               Même dans la P1 (la version initiale) se trouvaient déjà des propositions assez complètes pour
               les métadonnées bibliographiques, pour l’encodage des transcriptions orales, et même pour les
               analyses linguistiques abstraites en termes de structures de traits, en complément des
               propositions pour l’encodage des structures traditionnelles du livre et leurs composants
               typiques. Néanmoins, à l’origine, la TEI ne s’intéressait pas tellement au web (qui n’existait
               pas), ni à la mise en page (les outils bureautiques existaient déjà). Elle laissait de côté
               l’intégration des pages-images/fac-similés numérisés (trop onéreux) et la représentation des
               faits ou des objets (c’est l’enjeu des bases de données). Et elle n’était pas du tout concernée
               par la production des outils ou des logiciels (pas notre affaire). Dans un premier temps elle
               se focalisait sur : les métadonnées, les textes, les analyses textuelles et linguistiques. Bien
               sûr, nous avons changé tout cela... </p>
            <p>La TEI actuelle facilite un balisage <soCalled>intelligent</soCalled> d’une énorme variété de
               types de documents, à plusieurs niveaux de complexité. Elle s’applique forcément à l’encodage
               des composants structuraux et fonctionnels d’un texte et aux transcriptions diplomatiques des
               sources historiques, des images, et des annotations. Elle soutient la représentation et gestion
               des liens, des correspondances, et des alignements de fragments textuels. Elle propose une
               manière standardisée d’encoder les informations non-textuelles concernant les <soCalled>entités
                  nommés</soCalled> : par exemple des personnes, des lieux ou des événements. Elle est l’outil
               de préférence pour tous ceux concernés par les annotations para-textuelles et méta-textuelles
               (corrections, suppressions, ajouts). Elle permet la représentation d’analyses linguistiques, et
               de métadonnées de plusieurs types, y compris la définition formelle d’un schéma XML. Bref, elle
               fournit une encyclopédie de balisages adaptés à tout ce qui pourrait être d’intérêt pour les
               sciences humaines et sociales. Elle répond aux besoins des éditeurs de sources primaires, aux
               attentes des historiens et des linguistes, et aux problématiques des bibliothécaires et des
               archivistes. Et pour gérer ces richesses, la TEI a dû construire un modèle et des mécanismes de
               gestion très génériques, permettant son évolution bien au delà du noyau dur des utilisateurs
               typiques. </p>
         </div>
         <div>
            <head>Organisation et utilisation</head>
            <p>La TEI peut ainsi être considérée comme un des plus grands efforts d’interdisciplinarité de son
               époque : d’où deux principes de son architecture. D’abord, à cause de son envergure
               encyclopédique, sa construction impliquait l’application systématique du rasoir d’Ockham ; et
               ensuite son utilisation nécessitait l’usage de quelques mécanismes de personnalisation. </p>
            <p>L’importance du rasoir est manifeste dès qu’on considère combien de fois il arrive que les
               mêmes objets portent des noms différents, et que des objets différents soient désignés par le
               même nom. En souhaitant éviter une multiplication ingérable de concepts, la TEI fournit
               typiquement une proposition générique, par exemple <gi>div</gi> pour tout type de division, au
               lieu de <q>chapitre</q>, <q>section</q>, <q>partie</q> etc. De la même façon, elle propose un
               élément générique <gi>q</gi> pour tout type de discours, mais cet élément est aussi complété
               pas d’autres plus spécifiques. L’encodeur peut distinguer, par exemple, le discours direct en
               utilisant la balise <gi>said</gi> et la citation en utilisant la balise <gi>quote</gi>. Et,
               pour ceux qui souhaitent des distinctions encore plus fines, la TEI fournit aussi la balise
                  <gi>mentioned</gi> pour les méta-discours, et la balise <gi>soCalled</gi> pour les
               expressions pour lesquelles l’auteur ou le narrateur renonce à toute responsabilité. Il faut
               souligner que de telles subtilités casuistiques ne sont pas obligatoires, elles sont simplement
               mises à la disposition des chercheurs qui souhaitent les utiliser. La TEI ne va pas vous dire
                  <q>il faut baliser cela</q>; elle dit <q>si vous souhaitez distinguer cela, voici une balise
                  précise pour le faire.</q></p>
            <p>En conséquence, le système TEI ressemble un peu à un énorme buffet où il faut bien réfléchir
               avant de remplir son plateau. Il faut d’abord comprendre le gabarit avant de construire son
               propre système d’encodage. Sans cela, l’utilisateur n’arrivera pas à bien adapter ce kit lego à
               ses besoins, en restant en même temps compréhensible par d’autres personnes ou systèmes et en
               manifestant clairement les modifications éventuelles qu’on a effectuées. L’outil de description
               des grammaires TEI, qui s’appelle ODD, facilite ce travail, et devient donc une partie
               essentielle du système. ODD est une abréviation de l’expression <q>One Document Does it all</q>
               (un document fait tout). Conçu comme un vocabulaire XML spécialisé pour la description des
               vocabulaires XML, l’ODD sert aussi à décrire une personnalisation de la TEI. Son nom dérive du
               fait qu’on peut générer à partir d’un seul document TEI XML, à la fois un schéma formel (un
               DTD) destiné à l’attention d’un parseur ou d’autres logiciels, et une documentation destinée à
               l’attention d’un lecteur humain. </p>
            <p>En effet, il n’y a pas de DTD TEI unique car la TEI est un système <emph>modulaire</emph>. Nous
               nous en servons pour créer un système d’encodage selon ses propres besoins, en sélectionnant
               des <term>modules</term> spécifiques de l’ensemble fourni par la TEI. Chacun de ces modules
               définit une brique contenant un groupe d’éléments (et leurs attributs). Nous pouvons
               sélectionner dans cette brique les éléments souhaités, et même en changer des propriétés. Nous
               pouvons y mélanger des éléments nouveaux, natifs ou émanant d’autres standards. </p>
            <p>Dans les 1 400 pages imprimées des TEI Guidelines, vous trouverez : un lexique des 564 éléments
               ; une grammaire comprenant des règles d’usage et des contraintes exprimées en langue naturelle
               et en langages formels ; et <emph>beaucoup</emph> de discussions à propos, notamment, de
               plusieurs exemples d’utilisation. Ce que vous ne trouverez pas est un guide <q>one size fits
                  all</q> pour les débutants qui expliquerait comment, en pratique, profiter de ces richesses,
               un type de <title>Guide pour les égarés</title>. Inutile d’approcher la TEI pour cela: les
               Guidelines furent conçus comme manuel de référence générique, non pas comme tutoriel explicatif
               adapté aux novices d’une ou plusieurs disciplines spécifiques. La création de tels tutoriels
               reste une tâche pour les spécialistes, puisqu’il faut toujours adapter la TEI aux besoins et
               aux préconceptions d’une discipline spécifique. Nous citons comme exemplaires le tutoriel TEI
               Lite, et sa version plus récente simplePrint, <note>Voir
                  http://www.tei-c.org/release/doc/tei-p5-exemplars/html/tei_simplePrint.doc.html</note> bien
               adapté aux besoins de ceux qui travaillent sur la numérisation des livres imprimés, ou la
               documentation du collaboratif Epidoc,<note>Voir https://sourceforge.net/projects/epidoc/</note>
               spécialisée pour les épigraphistes, et quelques autres.</p>
            <p>Si les buts de votre projet ne sont pas très loin des enjeux de ceux qui profitent d’un de ces
               tutoriels déjà existants, tant mieux. Dans le cas contraire, ou si vous souhaitez vraiment
               modifier et adapter les propositions de la TEI (je note en passant que le <q>P</q> des versions
               de TEI &#x2014; P1, P2, jusqu’à l’actuelle P5 &#x2014; correspond au mot
                  <mentioned>proposals</mentioned>), je vous conseille de suivre une procédure un peu
               formelle, pour laquelle je propose le titre <title>le chemin de l’Éveil TEI</title>. Il y a
               cinq étapes distinctes sur ce chemin : <list rend="ordered">
                  <item>La modélisation des buts et des objets de votre projet ; </item>
                  <item>L’orientation de ces objets par rapport aux objets déjà reconnus par la TEI ; </item>
                  <item>La déclaration formelle de votre spécification conforme à la TEI ; </item>
                  <item>La documentation de vos pratiques TEI ; </item>
                  <item>Et la validation de vos corpus par rapport à la spécification ainsi construite.
                  </item>
               </list>
            </p>
            <p>La modélisation initiale de vos données est un préalable essentiel. Que vous vous serviez
               d’UML, de RDBMS, de SKOS, ou quoi que ce soit d’autre, si vous n’avez pas un modèle explicite
               des objets et concepts que vous espérez gérer, vous aurez de grandes difficultés. Pour les
               projets TEI, tout comme les projets de bases de données classiques, il faut passer par une
               étape plus ou moins formelle d’identification des <term>objets d’intérêt</term> et de leurs
               attributs et propriétés ; suivie d’une reconnaissance des relations entre objets. Il faut aussi
               prendre en compte les procédures et les traitements essentiels envisagés pour votre corpus.
               Aussi fastidieux ou onéreux qu’il puisse paraître, ce travail reste essentiel pour tout projet
               d’informatisation, et surtout pour un projet espérant profiter d’un système formalisé comme la
               TEI. </p>
            <p>Les projets de numérisation bien menés prennent aussi en compte un autre axe: la précision et
               la cohérence avec lesquelles un objet particulier peut être identifié et donc traité dans
               l’ensemble des matériaux des sources. Je reviendrai sur ce point. </p>
            <p>Lors de la deuxième étape, vous devez essayer d’orienter votre modèle par rapport à celui de la
               TEI. Comment s’y retrouver dans la séquence des 22 chapitres des Guidelines,<note>Disponible
                  sur http://www.tei-c.org/release/doc/tei-p5-doc/en/html/</note> chacun correspondant à un
               module de définitions, ou dans les listes alphabétiques de définitions exhaustives de classes
               (183), d’éléments (546), d’attributs (470), de macros(8), et même de types de données (28) ?
               Comment savoir quel élément (etc) choisir pour telle ou telle entité identifiée dans votre
               analyse préalable ? Comment savoir que vous avez besoin d’une licorne &#x2014; un élément pas
               encore reconnu par la TEI? </p>
            <p>Il ne faut pas cacher une triste vérité : il n’y a aucune méthode scientifique ; aucun
               raccourci pour cela... Il faut étudier les exemples et les définitions pour savoir si tel
               élément TEI qui semble prometteur s’applique effectivement à votre cas. Il est totalement
               impossible d’échapper à ce problème de traduction entre modèles. Pour chacun(e) des
               entités/concepts identifiés dans votre modèle, il faut donc décider s’il existe un objet TEI
               qui lui corresponde parfaitement; ou, sinon, quel objet TEI lui ressemble et quelles petites
               modifications seraient nécessaires pour qu’il lui corresponde parfaitement. Ou même, quelle
               lacune TEI votre analyse vous permettra de corriger (car, oui, elles existent les licornes !) </p>
            <p>Considérons un cas concret. Supposons que l’on ait obtenu un financement ANR pour un projet de
               numérisation et de transcription d’une collection gigantesque de cartes postales. Comment
               va-t-on créer un système TEI apte à gérer des centaines (peut-être des milliers) de cartes
               postales numérisées ? Supposons que nous nous sommes décidés à faire un peu plus que de mettre
               à disposition des images numériques des deux cotés de chaque carte, il faut au moins trouver un
               moyen d’identifier chaque carte et de lui associer des métadonnées. La variété des métadonnées
               que l’on pourrait souhaiter ajouter reste vaste, et a priori il est très difficile d’identifier
               celles qui sont les plus signifiantes. Un focus par exemple sur des propriétés physiques et
               objectives (la taille de la carte, sa méthode de production...) est envisageable ; mais en bon
               historien/nes nous pourrions souhaiter noter le nom et l’adresse de son éditeur, le sujet
               représenté sur la carte, les informations sur l’expédition ou la réception de la carte
               (oblitérée à tel endroit à telle date, destinée à cette autre endroit...). Supposons par
               ailleurs que l’on soit motivé pour transcrire soigneusement les mots écrits sur chaque carte,
               en les distinguant bien sûr des mots éventuellement imprimés ou tamponnés, qui auraient un
               statut différent. En ce cas, les cartes sont de petits documents d’archives, avec des
               variations linguistiques de grand intérêt (des formules de politesse, des mentions de lieux et
               de personnes), sans parler des annotations para-textuelles ou méta-textuelles éventuelles (des
               ratures, des corrections, des ajouts, des changements d’écriture...). </p>
            <p>En choisissant entre ces possibilités il y aura une tendance naturelle à donner priorité aux
               distinctions qui sont faciles à implémenter, et à laisser de coté celles qui sont difficile à
               effectuer avec cohérence ou à coût raisonnable. Par exemple, il serait assurément d’intérêt de
               distinguer les écrivains des cartes postales selon leur sexe ou leur classe sociale. Pourtant,
               il faut se demander jusqu’à quel point cette distinction peut se faire correctement et avec
               cohérence dans une masse de textes écrits par des inconnu(e)s et pas forcément signés d’une
               manière non-ambiguë. De la même façon, il y a des propriétés des cartes très facile à
               identifier mais d’un intérêt scientifique minimal (couleur d’encre, taille d’écriture, position
               du timbre par rapport à l’adresse...). Tout projet de numérisation doit forcément trouver un
               bel équilibre entre le faisable et l’utile car la liste des notions balisables, chacune
               d’importance pour un type d’analyse quelconque, risque de devenir ingérable. Voici une bonne
               raison d’avoir au préalable bien fait son analyse! </p>
            <p>Supposons enfin que nous ayons bel et bien discuté des cartes, et nous voilà avec notre liste
               du top 10 (ou top 20 ou top 50) des catégories de métadonnées essentielle. Nous passons
               maintenant à la deuxième étape. Nous regardons bien dans les TEI Guidelines, et nous constatons
               que même si hélas il n’y a rien de spécifique sur les cartes postales, il y a des propositions
               très complètes pour quelques aspects qui nous intéressent : par exemple, il y a des balises
               conçues pour l’encodage des métadonnées qui concernent l’expédition des lettres (la balise
                  <gi>correspDesc</gi> et Cie) que nous pouvons adapter. Il y a tout une gamme de balises pour
               l’encodage des manuscrits d’une richesse telle que nous risquons de nous y noyer. Il y a des
               propositions très utiles pour la représentation de noms (de lieu, de personne etc.) et des
               entités nommées associées à ces noms. Il y a des balises pour représenter les graphies qui font
               partie intégrante d’un document, et des mécanismes pour associer un fragment de texte transcrit
               avec sa représentation graphique. Bien sûr il y a aussi des mécanismes pour faciliter
               l’indexation des documents selon un classement sémantique, topologique, analytique etc etc. Il
               y a même une balise <gi>stamp</gi> qui peut-être nous servira pour l’encodage des timbres
               postes. </p>
            <p>Un peu rassurés, nous faisons le bilan des éléments TEI qui nous semblent utiles, avec leurs
               attributs, et nous passons aux troisième et quatrième étapes : la construction d’une
               spécification TEI adaptée à nos besoins, et de sa documentation en forme de d’ODD. C’est une
               procédure technique, moins difficile que la construction d’un schéma de base de données, mais
               qui lui ressemble un peu. La TEI fournit un outil online (http://www.tei-c.org/Roma/) pour
               faciliter cette tâche, et elle héberge également des tutoriels. Notre objectif sera de générer
               un schéma formel pour valider nos données TEI XML, exprimé en langue informatique tel que DTD,
               RELAXNG, W3C Schema, Schematron. Cette grammaire va contrôler l’essentiel en déterminant
               quelles balises seront disponibles dans quels contextes, avec quels attributs et avec quelles
               valeurs, et en respectant quelles contraintes. </p>
            <p>L’un des intérêts d’ODD est de nous permettre de définir toutes ces contraintes d’une manière
               standardisée et indépendante de toute langue formelle de schéma. Un autre, peut-être plus
               significatif, est qu’il nous permet aussi d’intégrer cette définition avec une documentation
               complète pour expliquer nos principes éditoriaux, nos principes de choix de balises,
               l’organisation de notre schéma etc. Ces explications seront très précieuses pour les
               utilisateurs de nos données et pour les développeurs de notre système, ainsi que pour nous-même
               d’ici quelques jours quand nous aurons oublié pourquoi nous avons pris telle ou telle décision.
               Cette documentation d’ailleurs (comme les TEI Guidelines) peut s’exprimer en plusieurs langues
               naturelles et peut se présenter en plusieurs formats bureautiques (PDF, Word, HTML, epub...) </p>
            <p>En ce qui concerne la sélection des éléments, la TEI est conçue pour soutenir une variété
               d’approches, résumée dans cette figure: <figure>
                  <graphic url="../Graphics/oddFlavours.png" height="420px" width="420px"/>
                  <head type="legend">Variétés de personnalisation TEI</head>
               </figure></p>
            <p>Un projet peut tout simplement utiliser un sous-ensemble des éléments, attributs etc proposés
               (TEI subset). Une fois la sélection faite, la tâche est complète. Il peut arriver de temps en
               temps que quelques légères (ou pas si légères) modifications soient souhaitables : de
               contraindre, par exemple, les valeurs d’un attribut qui, dans sa version canonique permettrait
               n’importe quoi : apres précision de ces modifications, éventuellement completées par des
               contraintes supplémentaires, le projet aura donc besoin d’un sous-ensemble personnalisé
               (customized subset). Ces contraintes et ces personnalisations s’expriment dans la même langue
               ODD. Et si finalement un projet ajoute des composants pas du tout prévus par la TEI, (des
               licornes peut-être), modifiant un objet TEI jusqu’à le rendre méconnaissable, c’est-à-dire
               qu’il n’est plus valide selon le schéma TEI All, le projet a affaire avec une extension de la
               TEI (extended subset). Dans ce cas, tout à fait légitime, il faut distinguer les composants
               non-TEI en les faisant appartenir à un autre espace de noms. </p>
            <p>Plus concrètement, examinons cet ODD adapté aux besoins d’un projet imaginaire ayant besoin
               d’un schéma très réduit et simple: </p>
            <egXML xmlns="http://www.tei-c.org/ns/Examples"><div>
                  <head>Une personnalisation TEI pour la transcription collaborative</head>
                  <p>Cette personnalisation propose un schéma minimal pour la transcription collaborative des
                     documents d’archives. </p>
                  <schemaSpec ident="transMin" start="TEI text div" docLang="fr">
                     <moduleRef key="tei"/>
                     <moduleRef key="header"
                        include="teiHeader fileDesc titleStmt 
                     publicationStmt sourceDesc"/>
                     <moduleRef key="textstructure" include="TEI text body div"/>
                     <elementRef key="ab"/>
                     <elementRef key="pb"/>
                     <elementRef key="unclear"/>
                     <elementRef key="hi"/>
                     <elementRef key="name"/>
                     <elementRef key="title"/>
                     <classSpec type="atts" ident="att.declaring" mode="delete"/>
                     <classSpec type="atts" ident="att.fragmentable" mode="delete"/>
                     <classSpec type="atts" ident="att.edition" mode="delete"/>
                     <classSpec type="atts" ident="att.editLike" mode="delete"/>
                     <classRef key="att.global.rendition" except="rendition style"/>
                  </schemaSpec>
               </div>
            </egXML>
            <p>Notons d’abord que ce fragment est lui-même un document TEI XML très simple: il contient les
               éléments classiques TEI <gi>div</gi>, <gi>head</gi> et <gi>p</gi>, utilisés par presque tout
               document TEI pour signaler respectivement une division de texte, un titre, et un paragraphe.
               L’élément <gi>schemaSpec</gi> et ses attributs servent à définir le schéma formel qu’on
               souhaite générer à partir de cette spécification. L’attribut <att>transMin</att> fournit le nom
               du schéma, l’attribut <att>start</att> indique les éléments qui seront capable d’agir comme
               racine d’un document conforme à ce schéma, et l’attribut <att>docLang</att> précise la langue
               naturelle dans laquelle la documentation du schéma sera générée, si possible. Au sein de cet
               élément <gi>schemaSpec</gi> se trouvent les composants désirés pour le schéma, qui sera un
               simple sous-ensemble. Ces composants sont spécifiés à l’aide des éléments <gi>moduleRef</gi>,
               qui précise le nom d’un module TEI que nous souhaitons intégrer par moyen de son attribut
                  <att>key</att>. Dans ce cas, nous souhaitons intégrer tous les objets fournis par le module
               infra-structural qui s’appelle <ident>tei</ident> (c’est typique pour un schéma TEI), mais nous
               ne souhaitons sélectionner qu’un petit nombre d’éléments des deux autres modules référencés
               ici, à savoir, dans le module <ident>header</ident> seront sélectionnés que les éléments
                  <gi>teiHeader</gi>, <gi>fileDesc</gi>, <gi>titleStmt</gi>, <gi>publicationStmt</gi>, et
                  <gi>sourceDesc</gi> ; et dans le module <ident>textstructure</ident> sont choisis que les
               éléments <gi>TEI</gi>, <gi>text</gi>, <gi>body</gi> et <gi>div</gi>. Cette méthode précise le
               module d’où un élément est dérivé, ce qui n’est pas toujours nécessaire : nous aurions pu
               également spécifier seulement le nom de l’élément souhaité en utilisant l’élément
                  <gi>elementRef</gi>, ce qui est le cas ici pour les éléments <gi>ab</gi>. <gi>pb</gi>,
                  <gi>unclear</gi>, <gi>hi</gi> et <gi>name</gi>. </p>
            <p>Pour comprendre cette redondance de méthodes, il faut savoir qu’un module peut aussi définir
               des <term>classes</term>, qui seront automatiquement incluses dans le schéma indépendamment de
               la suppression (ou inclusion) des éléments. Une des deux fonctions d’une classe est de fournir
               des attributs, qui deviendront ainsi disponible sur tous les éléments de notre schéma
               appartenant aux classes concernées, ce qui n’est pas toujours souhaitable surtout dans un cas
               comme le nôtre où nous souhaitons minimiser les composants du schéma. C’est pour cette raison
               que notre petit ODD conclut en supprimant quatre classes déjà fournies par les modules
               sélectionnés, et en réduisant le nombre d’attributs fourni par le cinquième. Mais là nous
               entrons peut-être trop dans les détails techniques du système. </p>
            <p>Continuons donc de personnaliser notre schéma. La TEI propose pour l’élément <gi>div</gi> un
               attribut <att>type</att> dont les valeurs sont par défaut indéfinies: ce qui implique que toute
               valeur sera permise. Supposons que dans notre projet par contre nous envisagions d’utiliser cet
               attribut pour distinguer entre des types d’unités structurantes (par ex: section, sous-section,
               etc.) ou pour distinguer les divisions en termes de fonction (par ex: préliminaire, question,
               réponse, etc.) ou selon n’importe quelle autre taxonomie. Il est donc très probable que nous
               préférions contraindre les valeurs possibles de cet attribut. Un ODD nous permet de faire cela
               aisément. Il suffira d’ajouter une redéfinition de l’élément <gi>div</gi>, comme ceci:
               <egXML xmlns="http://www.tei-c.org/ns/Examples">
                  <elementSpec ident="div" mode="change">
                     <attList>
                        <attDef ident="type" mode="replace">
                           <valList>
                              <valItem ident="prelim"><desc>préliminaire</desc></valItem>
                              <valItem ident="quest"><desc>questionnement</desc></valItem>
                              <valItem ident="rep"><desc>réponse</desc></valItem>
                              <valItem ident="autre"><desc>autre type de division</desc></valItem>
                           </valList>
                        </attDef>
                     </attList>
                  </elementSpec></egXML>
                Notez bien d’abord qu’il s’agit d’ajouter un élément <gi>elementSpec</gi> et non pas un
                  <gi>elementRef</gi>. Pourquoi? parce que nous souhaitons ajouter de nouvelles informations,
               pour compléter celles déjà fournies pour l’élément <gi>div</gi> que nous avons trouvé dans le
               module <ident>textstructure</ident>. La valeur <ident>change</ident> pour l’attribut
                  <att>mode</att> de cet élément <gi>elementSpec</gi> indique qu’il faut combiner les deux
               ensembles d’informations, et non pas tout remplacer. Par contre, la définition de l’attribut
                  <att>type</att> déjà existant est à remplacer entièrement : c’est pour cela que l’attribut
                  <att>mode</att> de l’élément <gi>attDef</gi> porte la valeur <ident>replace</ident>. </p>
            <p>La remplacement consiste à fournir une liste complète des valeurs autorisées pour cet attribut
               sous la forme d’un élément <gi>valList</gi>. Chacune des valeurs possibles est documentée par
               un élément <gi>valItem</gi>, dont l’attribut <att>ident</att> précise la valeur elle-même, et
               par un élément facultatif <gi>desc</gi> qui fournit une documentation plus élaborée. </p>
            <p>Cet exemple démontre aussi à quel point la documentation, lisible par des êtres humains, et la
               spécification d’une grammaire formelle, validable par un automate, sont liées dans une
               spécification ODD.</p>
         </div>
         <div>
            <head>Pourquoi continuer de s’intéresser à la TEI ?</head>
            <p>Il y a au moins deux raisons pour lesquelles les standards échouent le plus souvent. Ou bien
               ils sont basés sur une théorie pas encore mûre; ou bien la communauté envisagée est trop
               diverse ou trop fragmentée pour en profiter. Le secret de la réussite de la TEI et de sa
               longévité serait-il dans ses capacités d’évolution, qui lui auraient permis d’échapper à ces
               deux écueils ? </p>
            <p>Une personnalisation TEI peut faire presque tout pour modifier les propositions standardisées.
               Elle permet non seulement une sélection explicite des éléments et des attributs considérés
               comme utiles, mais aussi la limitation plus ou moins stricte des valeurs possibles d’un
               attribut. À cela s’ajoutent des règles Schematron pour contrôler le contenu d’un élément (p.e.
               co-dependency) plus strictement que la TEI ne le permet. Une personnalisation peut même se
               permettre l’ajout de nouveaux éléments (ou classes d’éléments), labellisés dans votre propre
               espace de noms, mais appartenant aux classes sémantiques prédéfinies par la TEI. Cette
               architecture permet donc d’évoluer et de tester sa théorie, en restant toujours conforme à la
               TEI. </p>
            <p>L’architecture TEI est également construite sur des principes ouverts, évidents, par exemple,
               dans ses très importantes capacités d’internationalisation. Editées en anglais, les parties
               essentielles des Guidelines ont été depuis longtemps mises à disposition en plusieurs autres
               langues (y compris l’allemand, l’espagnol, le français, le chinois, le japonais...), et leur
               système de gestion est conçu pour faciliter la traduction en d’autres langues. Outre cette
               position ouverte envers les langues humaines, le système TEI peut également accueillir d’autres
               langages informatiques. Comme tout autre système XML, il héberge volontairement d’autres
               espaces de noms, et facilite l’inclusion des autres schémas existants. Par exemple, un document
               TEI XML peut intégrer des fragments SVG pour les graphiques, des fragments MathML pour les
               maths, des fragments MEI pour la musique annotée etc. La définition d’un élément TEI peut aussi
               inclure un mapping avec d’autres ontologies, formalisé par un élément <gi>equiv</gi>
               (équivalent). Ainsi le transfert automatique de la sémantique d’un encodage TEI vers une autre
               représentation (utilisant une autre ontologie) est-elle envisageable. </p>
            <p>Toutes ces possibilités de modification et cette flexibilité pourraient bien mettre en cause le
               statut normatif de la TEI. En fin de compte, qu’est-ce que cela veut dire : « être conforme » à
               la TEI ? Durant sa longue existence, la TEI a vu évoluer une pratique de balisage consensuelle
               profitant d’un lexique commun, et basé sur un respect de l’autonomie de ses utilisateurs. Comme
               déjà noté, la standardisation façon TEI ne signifie pas « fais comme moi » ; elle veut dire
               plutôt « explique-moi ce que tu fais. » À mon avis c’est précisément cette flexibilité qui lui
               aurait conféré sa pérennité : tout comme prévu par la théorie d’évolution darwinienne, ce sont
               les êtres rigides et sans possibilité d’adaptation qui risquent de disparaître. </p>
            <p>La TEI continue donc de changer et de se modifier selon les besoins et les priorités de sa
               communauté d’utilisateurs: là où elle devient ou apparaît mal adaptée, l’utilisateur est
               toujours libre de la modifier, d’abord dans son propre espace de noms. La documentation de ces
               modifications dans un ODD qui s’impose permet ainsi une discussion informée des propositions de
               modification par toute la communauté intéressée, par exemple sur la liste TEI-L, sur le site
               github du Conseil Scientifique de la TEI, ou dans un groupe de travail autonome. Les
               modifications efficaces dérivées de ces discussions peuvent être ainsi intégrées à l’ensemble
               des recommandations de la TEI, contribuant donc à son évolution progressive, et à son
               enrichissement. Depuis l’an 2000, une version nouvelle de TEI P5 est apparu au moins deux fois
               par an; le plus souvent contenant des corrections, de nouveaux exemples, etc. mais aussi des
               élargissements importants des sujets traités ou des améliorations de l’infrastructure;
               témoignant ainsi à la vitalité continue de cet ancien standard qui se modifie pour perdurer.
            </p>
         </div>
      </body>
    <back/>
   </text>
</TEI>
