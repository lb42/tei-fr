<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title>La TEI pour les corpus linguistiques: un standard qui se renouvelle</title>
         </titleStmt>
         <publicationStmt>
            <p>Publication information</p>
         </publicationStmt>
         <sourceDesc>
            <p>Hacked from various other talks</p>
         </sourceDesc>
      </fileDesc>
      <revisionDesc>
         <change when="2016-06-06">Finalising</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <body>
         <!-- 65000 chars plus spaces -->
         <div>
            <head>Combien de standards faut-il dans le monde ?</head>
            <p>Pour bien fonctionner, un standard de metadonnées devrait être capable de décrire
               tous les autres standards et ainsi d'interagir avec eux. Il y a donc une tendance de
               construire des standards de plus en plus méta, de plus en plus ambitieux. Face aux
               complexités et fragmentation du monde scientifique, on voit une croissance inévitable
               des standards, chacun bien adapté aux besoins et aux priorités d'un communauté
               quelconque, mais inutile, incompréhensible, voire nuisible aux interêts d'un autre.
               On a donc tendence à élaborer des politiques globales, des standards génériques,
               capable de gérer tous les points de vues des particuliers, tout en permettant leur
               continuité. En plus, les standards naissent et évoluent et se multiplient dans un
               paysage complexe. En somme, ce n'est guere difficile de retrouver des standards. La
               probleme reste comment choisir entre eux.</p>
            <p>On peut les distinguer nettement par rapport aux agences responsable de leur creation
               et maintenance. Par exemple, les standards ressortant des agence officielles de
               standardisation, au niveau national (l'AFNOR, l'ANSI, le BSI, ou le DIN en europe) ou
               internationales ( ISO, IEC, W3C, OASIS ...) sont forcement elabores et geres d'une
               autre maniere des standards ressortant des industries interessees (LISA, MPEG ...) ;
               les politiques d'acces aux standards seront aussi different dans les deux cas. Et
               pour le monde scientifique, on rencontre souvent des projets ayant des enjeux
               pré-normatifs, tels que les projets francais Cahier, Ortolang etc. en meme temps que
               des agences (DARIAH, CLARIN...) ayant comme mission la promotion des standards et des
               bonne pratiques qui y sont associes. Et (mais peut etre un peu moins qu'avant) les
               enjeux des agences appartenant au monde scientifique risquent toujours de se
               distinguer de ceux propres aux societies prives. </p>
            <p>On peut aussi positioner les standards selon leur maniere de repondre a la question
               "Combien de standards faut-il au monde ?", pour gerer les complexites deja evoques de
               leur environnement. Le plus simple des reponses serait de dire "un seul": il fait
               trouver une solution centralisee et dirigiste, qu'on pourrait caricaturiser avec
               l'acronyme WKWBFY (We Know What's Best For You). A l'autre extreme on pourrait
               repondre "aucun" et rester content des "standards" entierement anarchiste, en
               supposant que chacun des utilisateurs aurait ses propres besoins, meme ses propres
               perceptions, jusqu'au point qu'aucun standard serait possible parce que (encore un
               acronyme) NWEUMP (Nobody Will Ever Understand My Problems). Et entre ces deux
               extremes on peut repondre "autant qu'il en arrive" : la solution pragmatique ou
               laissez-faire, qui suivrait betement les voix qui crient le plus fort: la solution
               FTH (Follow The Herd).</p>
            <p>Si ces remarques ont l'air un peu cynique, c'est peut etre a cause du fait que les
               normes ne s'imposent pas dans la vie intellectuelle. Soit elles émergent d'un besoin
               de la communauté; soit leur usage dérive de la nécessité d'utiliser une technologie
               particulière, mais on ne renonce pas volontairement à son indépendance scientifique !
               Quelques uns de nos collegues ont toujours tendence de s'imaginer qu'on pourrait se
               passer des standards. Pour ces collegues, les standards pourraient constituer un
               inconvénient majeur : ce n'est pas forcement souhaitable de figer un état de la
               connaissance, mais c'est necessaire pour la standardisation. Ceux qui sont en train
               de formuler de nouveaux hypotheses et de revoir constamment la structuration d'une
               probleme, ont bien raison de rester sceptique sur la necessite d'une standardisation
               jugee prematuree et etouffante. D'ailleurs, la production des standards est toujours
               chronophage, nécessitant des compétences interdisciplinaires qui ne sont pas
               forcement disponible a tout scientifique. De meme, l'apprentisage et l'utilisation
               des standards peut être également chronophage. </p>
            <p rend="box">Quand même, il y a des avantages qu'il faut souligner a ces collegues
               sceptiques. En l'absence de standards numeriques, comment sur le web identifier et
               retrouver des ressources numériques ayant un intérêt linguistique ? Comment valider
               les résultats scientifiques obtenus par d'autres personnes ? comment enrichir ou
               intégrer les ressources existantes avec ses propres idées ? Comment séparer les
               ressources des outils qui les gèrent/analysent ? Pour tout cela, les standards
               restent essentiels. Il repondent aussi a plusieurs besoins techniques, que tout
               scientifique devrait reconnaitre : par exemple, la possibilité de recombiner ou de
               réutiliser les systèmes existants; l'évolution modulaire des logiciels ; la réduction
               des coûts de formation ; et la possibilite de profiter de l'existence de
                  <q>frequently answered questions</q> &#x2014; des solutions qui s'appliquent dans
               plusieurs domaines. Les standards donc offrent des possibilités a ne pas minimiser !
            </p>
         </div>
         <div>
            <head>Origines et enjeux de la TEI</head>
            <!--   <div xml:lang="fr">
        <head>Lire, c’est encoder... </head>
        <list>
          <item>L’interprétation des mots d’un texte n’est pas aléatoire : elle
            est guidée par les signes de ponctuation, par les changements de
            police, par leur disposition spatiale etc !</item>
          <item>Pour indiquer les même choses (et d’autres) dans un texte
            numérique, une balisage devient essentiel</item>
          <item>Le balisage sert ainsi à exprimer nos lectures préalables</item>
          <item>Le balisage rend possible une polyvalence des ressources
            textuelles et induit des réflexions profondes sur la matérialité des
            textes qu’elles impliquent</item>
        </list>
      </div>
      <div xml:lang="fr">
        <head>Concrètement la Text Encoding Initiative (TEI) c’est quoi ?</head>
        <p> Une <soCalled>Initiative pour l’Encodage Textuel</soCalled>....</p>
        <list>
          <item rend="pause">un ensemble de <soCalled>recommandations</soCalled>
            pour l’encodage des ressources numériques avec XML</item>
          <item rend="pause">un infrastructure internationale responsable de la
            maintenance, de l’évolution, et de la distribution de ces
            recommandations</item>
          <item rend="pause">une communauté internationale d’utilisateurs de ces
            recommandations</item>
        </list>
        <p rend="box">Plutôt un cadre permettant de réflechir sur ce que c’est
          qu’un texte numérisé qu’un "standard" fixe.</p>
      </div>
      <div rend="slide">
        <head>Les enjeux de la TEI</head>
        <p><hi>"Text Encoding for Interchange"</hi></p>
        <list>
          <item>faciliter la <hi>création</hi>, l’<hi>échange</hi>, et
              l’<hi>intégration</hi> des données textuelles informatisées <list>
              <item>toute sorte de textes</item>
              <item>toutes les langues </item>
              <item>toute origine temporelle ou culturelle</item>
            </list></item>
          <item>La TEI s’adresse également ...<list>
              <item>aux débutants, cherchant des solutions bien connues et
                consensuelles</item>
              <item>aux experts, cherchant à créer de nouvelles solutions</item>
            </list></item>
        </list>
      </div>
      <div xml:lang="fr">
        <head>Les buts de la TEI</head>
        <list>
          <item>faire des <hi>recommandations</hi> qui se basent sur un
            consensus existant</item>
          <item>préférer les <hi>solutions générales</hi> à celles spécifiques à
            une discipline</item>
          <item>en même temps permettre la <hi>spécialisation</hi> et
              <hi>l’extension</hi></item>
        </list> -->

            <p> Dès sa conception initiale en 1987, la Text Encoding Initiative s'est proposée comme
               methode de faciliter la construction, la description, la structuration, et
               l'annotation des corpus linguistiques et littéraires -- de tous types, de toutes
               périodes, dans toutes les langues. Elle etait concue comme format pivot, son but
               etant de rendre faisable l'interchange, voire l'interoperabilite de tous les formats
               incompatibles des media deja prevus a cette epoque, La TEI précèdait le Web, le DVD,
               le téléphone portable, la télévision cablée, et Microsoft Word. Alord, vu que les
               technologies informatiques qui survivent plus de 5 ans sont assez rares, la question
               qui s’impose autour d'elle aujourd'hui est : pourquoi et comment la TEI a-t-elle
               survécu plus de 30 ans ? J'essaie de repondre a cette question en conclusion, mais je
               commence avec un focus sur les circonstances de sa naissance. </p>
            <p>Du point de vue historique, la TEI est un produit d'une rarissime conjonction
               d'interêts parmi plusieurs communautés scientifiques. Les chercheurs littéraires, les
               stylométriciens, les critiques de l'école <soCalled>close reading</soCalled> de meme
               que les historiens, les archivistes, et les éditeurs; les bibliographes, les
               bibliothécaires; et bien sur les linguistes, notamment, mais pas exclusivement, de
               corpus; a ne rien dire des informaticiens ... tous ces communautés scientifiques se
               sentaient concernés par le passage au numérique des textes écrits ou oraux à grande
               échelle. A la fin des annees 80 on voyait deja apparaitre sous forme numerique des
               fonds essentiels aux SHS (par ex de grands dictionnaires comme le Oxford English
               Dictionary, ou de corpus textuels comme le Thesaurus Linguae Graecae), et ca dans des
               formats tres varies. Au moment de naissance de ce que nous appellons de nos jours les
               humanites numeriques on s’est aperçu deja qu’on risquait une nouvelle confusion des
               langues avec l’arrivée de l'informatique dans la représentation des données
               textuelles !</p>
            <p>En même temps, la TEI prétendait fournir une réponse pratique aux deux oppositions
               typiques des <soCalled>humanités numériques</soCalled> : c'est a dire, primo
               l'opposition entre les besoins des débutants et ceux des experts; et secundo
               l'opposition entre les besoins et les interêts des scientifiques et ceux des
               ingénieurs </p>
            <p>En ce qui concerne l'opposition entre expert et novices, la TEI essayait de plaire a
               tous les deux D'un côté, elle cherchait de présenter et de soutenir des solutions
               préconnues, consensuelles, bien établies: les topoï sur lesquels <q>tout le monde
                  s'est mis d'accord</q> -- et que les débutants devraient donc arriver à
               comprendre. De l'autre, elle cherchait de soutenir la recherche, et donc la
               découverte des solutions aux questions pas encore posées, ou posables -- ainsi
               permettant aux experts de partager leur expertise. De cette tension sont nees les
               efforts de la TEI pour permettre a la fois un certain rigeur dans ces propositions,
               sans cloture de la porte sur des modifications assez fondamontales de ces memes
               propositions. </p>
            <p>Par rapport aux tensions voire mecomprehensions entre les informaticiens et les
               non-techniciens, la TEI proposait (et propose toujours) aux ingénieurs un système
               bien adapté à l'implantation avec des outils informatiques courants, tout en essayant
               de s'exprimer dans une langue compréhensible aux non-techniciens, et derivee des
               conceptes bien comprises dans les sciences humaines. Le but etait d'assurer une
               comprehension mutuelle: que les techniciens arrivent a comprendre le modèle de base
               des SHS, et que les chercheurs arrivent a s'exprimer en profitant d'une modele plus
               ou moins formalisee. C'est pour cela que la documentation du systeme TEI est
               tellement extensive, ressemblant a la fois a une dictionnaire savante du 19eme siecle
               et un manuel d'encodage du 20eme. </p>
            <p> En plus, et en dépit de son nom, la TEI ne s'adressait pas uniquement au texte
               proprement dit. Même dans P1 (la version initiale) on trouve déjà des propositions
               assez complètes pour les métadonnées bibliographiques, pour l'encodage des
               transcriptions orales, et meme pour les analyses linguistiques abstraites en termes
               de structures des traits en complément des propositions pour l'encodage des
               structures traditionnelles du livre et leurs composants typiques. Neanmoins, a
               l’origine, la TEI ne s’intéressait pas tellement au web (ça n’existait pas), ni a la
               mise en page (les outils de desktop publishing existaient deja). Elle laissait a cote
               l’intégration des pages-images/facsimilés numérisés (trop expensif) et du coup la
               représentations des faits ou des objets (c'est l'enjeu des bases de données). Et elle
               n'etait pas de tout concernee par la production des outils ou de logiciels (pas notre
               boulot). Dans un premier temps elle se focalisait sur : les métadonnées, les textes,
               les analyses textuelles et linguistiques. Bien sur, nous avons changé tout cela... </p>
            <p>La TEI actuelle facilite un balisage <soCalled>intelligent</soCalled> d'une enorme
               variete de types de documents, a plusieurs niveaux de complexite. Elle s'applique
               forcement à l'encodage des composants structuraux et fonctionnels d'un texte et aux
               transcriptions diplomatiques des sources historiques, des images, et des annotations.
               Elle soutient la representation et gestion des liens, des correspondances, et des
               alignements de fragments textuels. Elle propose une maniere standardisee d'encoder
               les informations non-textuelles concernant les "entités nommes" : par exemple des
               personnes, des lieux ou des événements. Elle est l'outil de preference pour tous ceux
               concernes par les annotations péritextuelles et métatextuelles (correction,
               suppression, ajouts). Elle permet la representation d'analyses linguistiques, et les
               métadonnées de plusieurs types, y compris la définition formelle d'une schéma XML.
               Bref, elle fournit une encyclopedie de balisage adaptee a tout ce qui pourrait etre
               d'interet aux sciences humaines et sociales. Elle repond aux besoins des editeurs des
               textes primaires, aux attentes des historiens et des linguistes, et aux necessites
               des bibliothecaires et des archivistes. Et pour gerer ces richesses, la TEI a du
               construire un modele et des mechanismes de gestion tres generique, permettant son
               evolution bien au dela du noyau de concernes typiques. </p>
         </div>
         <div>
            <head>Organisation et utilisation</head>
            <p> La TEI peut ainsi être considérée comme un des plus grands efforts
               d'interdisciplinarité de son époque: d'où deux principes de son architecture.
               D'abord, a cause de son envergure encylopedique, sa construction necessitait
               l'application systematique du rasoir d'Ockham ; et ensuite son utilisation necessite
               l'usage de quelques mécanismes de personnalisation. </p>
            <p> L'importance du rasoir est manifeste des qu'on considere combien de fois il arrive
               que les mêmes objets portent de noms divers et que des objets divers ne sont pas
               toujours distingués par le nom. En souhaitant éviter une multiplication ingérable de
               concepts, la TEI fournit typiquement une proposition générique, par exemple
                  <gi>div</gi> pour tout type de division, au lieu de <q>chapitre</q>,
                  <q>section</q>, <q>partie</q> etc. De meme facon, elle propose un element
               generique <gi>q</gi> pour tout type de discours, mais cet element est aussi complete
               pas d'autres plus spécifiques. Par exemple, on peut distinguer le discours direct en
               utilisant la balise <gi>said</gi> et la citation en utilisant la balise
                  <gi>quote</gi>. Et, pour ceux qui souhaient des distinctions encore plus fines, la
               TEI fournit aussi la balise <gi>mentioned</gi> pour les meta-discours, et la balise
                  <gi>soCalled</gi> pour les expressions pour lesquelles l'auteur ou le narrateur
               renonce à toute responsabilité. Il faut souligner que de telles distinctions
               jesuitiques ne sont pas obligatoires, simplement elles sont mises a la disposition
               des chercheurs qui souhaient les utiliser. La TEI ne va pas vous dire "il faut
               baliser cela"; elle dit "si vous souhaitez distinguer cela, voici une balise precise
               pour le faire."</p>
            <p>En consequence, le système TEI ressemble un peu a un enorme buffet ou il faut bien
               reflechir avant de remplir son plateau. Il faut d'abord comprendre le gabarit avant
               de construire son propre système d'encodage. Sans cela, on n'arrivera pas a bien
               adapter ce kit lego aux besoins de l'utilisateur, restant en même temps
               compréhensible par d'autres personnes ou systèmes, manifestant clairement les
               modifications éventuelles qu'on a effectuees. L'outil des description des grammaires
               TEI, qui s'appelle ODD, facilite ce travail, et devient donc une partie essentielle
               du systeme. ODD ("One Document Does it all"), concu comme vocabulaire XML specialisee
               pour la description des vocabulaires XML, sert aussi a decrire une personnalisation
               de la TEI. Son nom derive du fait qu'on peut generer a partir d'un seul document TEI
               XML, a la fois un schema formel (un DTD) destine a l'attention d'un parseur ou autre
               logiciel, et de documentation destinee a l'attention d'un lecteur humain. </p>
            <p>En effet, il n'y a pas de &#x201C;TEI dtd&#x201D; car la TEI est un système
                  <emph>modulaire</emph>. On s'en sert pour créer un système d'encodage selon ses
               propres besoins, en sélectionnant des <term>modules</term> spécifiques de l'ensemble
               fourni par la TEI. Chacun de ces modules définit une brique contenant un groupe
               d'éléments (et leurs attributs). On peut séléctionner dans cette brique les éléments
               souhaités, et même en changer des propriétés. On peut y mélanger des éléments
               nouveaux, ou bien natifs ou bien d'autres standards. </p>
            <!--
               <head>Organisation logique de la TEI</head>
               <p><graphic url="../Graphics/class-system-FR.png"/></p>-->
            <p>Dans les 1 400 pages imprimées des TEI Guidelines, vous trouverez : un lexique de 564
               éléments ; une grammaire comprenant des règles d'usage et des contraintes exprimées
               en langue naturelle et s en langages formels ; et <emph>beaucoup</emph> de
               discussions notamment de plusieurs exemples d'utilisation. Ce que vous ne trouverez
               pas est un guide "one size fits all" pour les debutants qui expliquera comment en
               pratique profiter de ces richesses, un type de "Guide for the Perplexed". Inutile de
               rapprocher la TEI pour cela: les Gudelines furent concus comme manuel de reference
               generique, non pas comme tutoriel explicatif adapte aux novices d'un ou plusieurs
               disciplines specifiques. La creation de telles tutoriels est une tache pour les
               specialistes, puisqu'il faut toujours adapter la TEI aux besoins et aux
               preconceptions d'une discipline specifique. On peut par exemple citer le tutoriel TEI
               Lite, et sa version plus recente simplePrint, bioen adapte aux besoins de ceux qui
               travaillent avec la numerisation des livres imprimes, ou a la documentation du
               collaboratif Epidoc, specialisee pour les epigraphistes, et quelques autres.</p>
            <p>Si les buts de votre projet ne sont pas tres loin des enjeux de ceux qui profitent
               d'un de ces tutoriels deja existant, tant mieux. Mais sinon, ou si vous souhaitez
               vraiment modifier and adapte les propositions de la TEI (je note en passant que la
               "P" des versions de TEI -- P1, P2, jusqu'a l'actuel P5 -- correspond au mot
               "proposals"), vous etes bien avise de suivre un procedure un peu formel, pour lequel
               je propose le titre "le chemin de l'Eveil TEI". Il y a cinq etapes distinctes sur ce
               chemin: <list>
                  <item>La modelisation des buts et des objets de votre projet; </item>
                  <item>L'orientation de ces objets par rapport aux objets déjà reconnus par la TEI; </item>
                  <item>La declaration formelle de votre specification TEI-conforme; </item>
                  <item>La documentation de vos pratiques TEI ; </item>
                  <item>Et la validation de vos corpus par rapport a la specification ainsi
                     construite. </item>
               </list>
            </p>
            <p> La modelisation initiale de vos données est un préalable essentiel. Que vous vous
               servez de UML, de RDBMS, de SKOS, ou quoique ça soit d'autre, si vous n'avez pas un
               modèle explicite des objets et concepts que vous espérez gérer, vous aurez de grands
               difficultés. Pour les projets TEI, tout comme les projets de base de donnees
               classique, il fait passer par une etape plus ou moins formelle d'identifier (par
               exemple) les "objets d'interêt" ; leurs attributs et propriétés ; les relations entre
               objets ; et les procédures/traitements essentiels envisagés qui dependeront de leur
               presence dans votre corpus. Fastidieux ou oneureux qu'il puisse paraitre, ce travail
               reste essentiel pour tout projet d'informatisation, et surtout pour un projet
               esperant de profiter d'un systeme formalise comme l'est la TEI. </p>
            <p>Les projets de numerisation bien reussis prennent aussi en compte une autre axe: la
               precision et la coherence avec lesquelles un objet particulier peut etre identifie et
               donc traite dans l'ensemble des materiaux de sources. Je reviens sur ce point. </p>
            <p>Au deuxieme etape, vous devez essayer d'orienter votre modele par rapport a celui de
               la TEI. Dans la séquence des 22 chapitres des Guidelines, chacun correspondant à un
               module de definitions, ou dans les listes alphabétiques de définitions exhaustives de
               classes (183), d'éléments (546), d'attributs (470), de macros(8), et meme de types de
               données (28), comment se retrouver? Comment savoir quel élément (etc) choisir pour
               tel ou tel entité identifiée dans votre analyse préalable ? Comment savoir que vous
               avez besoin d'une licorne -- un element pas encore reconnu a la TEI? </p>
            <p>Il faut ne pas cacher une triste vérité: il n'y a aucune méthode scientifique ; aucun
               raccourci pour cela... Il faut étudier les exemplaires et les définitions pour savoir
               si cet élément TEI si prometteur s'applique en effet à votre cas comme. En effet,
               c'est le cas pour d'autres types de mapping egalement... Pour chacun(e) des
               entités/concepts identifiés dans votre modèle, il faut donc décider : s'il existe un
               objet TEI qui lui correspond parfaitement; ou, sinon, quel objet TEI lui ressemble et
               quelles petites modifications seraient nécessaires pour qu'il lui corresponde. Ou
               meme, quelle lacune TEI votre analyse vous permettra de corriger (car, oui, elles
               existent les licornes !) </p>
            <p>Considerons un cas concret. Supposons que l'on ait obtenu un financement ANR pour un
               projet de numérisation et de transcription d'une collection gigantesque de cartes
               postales. Comment va-t-on créer un systeme TEI apte à gérer des centaines (peut etre
               des milliers) de cartes postales numerisees ? Supposons que nous nous sommes decides
               de faire un peu plus que mettre a disposition des images numeriques des deux cotes de
               chaque carte, Il faut au moins trouver moyen d'identifier chaque carte et de lui
               associer des metadonnees. Mais l'etendu des metadonnees qu'on pourrait souhaiter
               ajouter est vaste, et a priori il est tres difficile de choisir celles qui sont les
               plus signifiantes. On pourrait focaliser par exemple sur des propretes physiques et
               objectives (la taille de la carte, sa methode de production...); en bon historien/ne
               on pourrait souhaiter noter le nom et l'adresse de son editeur, le sujet represente
               sur la carte, les informations sur l'expedition ou la reception de la carte (tamponee
               a tel endroit a telle date, destinee a cette autre endroit...). Supposons d'ailleurs
               que l'on soit motive de transcrire les mots ecrits sur chaque carte, en les
               distinguant bien sur des mots eventuels imprimes ou tamponnees, qui auraient un
               statut different. En ce cas, les cartes sont de petits documents archivales, avec des
               variations linguistique de grand interet (des formules de politesse, des mentions de
               lieux et de personnes) a ne rien dire des annotations paratextuelle ou metatextuelles
               eventuelles (des ratures, des corrections, des ajouts, des changements
               d'ecriture...). </p>
            <p>En choissisant entre ces possibilites on aura tendence naturel de prioritiser les
               distinctions qui sont facile a implementer, et laisser a cote celles qui sont
               difficile a effectuer avec coherence ou a prix raisonnable. Par exemple, assurement
               il serait d'interet de distinguer les ecrivains des cartes postales selon leur sexe
               ou leur classe sociale. Mais il faut se demander jusqu'a quel point on peut faire
               cette distinction avec coherence dans une masse de textes ecrits par des inconnu/es
               et pas forcement signes d'une maniere non-ambigue. De meme facon, il y a des
               propretes de cartes tres facile a identifier mais d'un interet scientifique minimale
               (couleur d'encre, taille d'ecriture, position du timbre par rapport a l'addresse...).
               Tout projet de numerisation doit forcement trouver un bel equilibre entre le faisable
               et l'utile car la liste des notions balisables, chacune d'importance pour un type
               d'analyse quelconque, risque de devenir ingerables. En voici une bonne raison d'avoir
               bien fait son analyse au prealable! </p>
            <p>Supposons enfin que nous avons bel et bien discute des cartes, et nous voila avec
               notre bilan du top ten (ou top twenty ou top fifty) categories de metadonnees
               essentielle. Maintenant on passe au deuxieme etape. On regarde bien dans les TEI
               Guidelines, et helas il n y a rien sure les cartes postales. Mais il y a des
               propositions tres completes pour des aspects qui nous interessent: par exemple, il y
               a des balises concues pour l'encodage des metadonnees concernant l'expedition des
               lettres (la balise <gi>correspDesc</gi> et cie) que nous pouvons adaptes. Il y a tout
               une gamme de balises pour l'encodage des manuscrits ou nous risquons de nous fair
               etouffer par ses richesses. Il y a des propositions tres utiles pour la
               representation de nominations (de lieu, de personne etc.) et des entites nommes
               associes (ou pas) avec ces noms. Il y a des balises pour representer les graphies qui
               sont partie constitutif d'un doccument, et des mecanism pour associer un fragment de
               texte transcrit avec sa representation graphique. Bien sur il y a des mecanismes
               aussi pour faciluter l'indexation des documents selon des classement semantiquesw,
               topologiques, analytique etc etc. Il y a meme une balise <gi>stamp</gi> qui peut etre
               nous servira pour l'encodage des timbres postes. </p>


            <p>Voici une spécification typique online <ref
                  target="http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/ref-particDesc.html">
                  http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/ref-particDesc.html </ref></p>
            <p>Il y a une version nouvelle de TEI P5 au moins 2 fois par an; le plus souvent
               contenant des fautes corrigées, de nouveaux exemples, etc. </p>
            <p>La plus recente contient deux modifications importantes des possibilités fournies par
               le langage ODD de personnalisation. On peut désormais utiliser de nouveaux éléments
               TEI pour la définition des modèles de contenu en TEI ; pour la documentation des
               modéles de traitement envisages. Le dossier d'exemplaires contient maintenant
                  <ident>TEI simplePrint</ident> un nouveau schéma réduit <soCalled>adapté aux
                  besoins de 90% des utilisateurs TEI</soCalled>, qui est censé remplacer le
               vénérable <ident>TEI Lite</ident>
            </p>
         </div>
         <div>
            <head>Pourquoi continuer de s’intéresser à la TEI ?</head>
            <p>Il y a peut etre (au moins) deux raisons pour lesquelles les standards échouent le
               plus souvent. Ou bien ils sont basés sur une théorie pas encore mûre; ou bien la
               communauté envisagée est trop diverse ou trop fragmentée pour en profiter. Le secret
               de la réussite de la TEI et de sa longévité serait-il dans ses capacités d'évolution,
               qui l'aurait permise a echapper a ces deux defis ? </p>
            <p>Une personnalisation TEI peut faire presque tout pour modifier les propositions
               standardisees. Il permet non seulement une sélection explicite des éléments et des
               attributs considérés comme utiles, mais aussi la limitation des valeurs possibles
               d’un attribut plus ou moins strictement; la proposition des règles Schematron pour
               controller le contenu d'un element (p.e. co-dependency) plus strictement que la TEI
               ne permet. Il permet l'ajout de nouveaux éléments (ou classes d'élément), labellisés
               dans votre propre espace de noms, mais appartenant aux classes sémantiques
               prédéfinies par la TEI. Cet architecture permet donc d'évoluer et de tester sa
               théorie, en restant toujours TEI-conforme. </p>
            <p>L'architecture TEI est egalement construit sur des principes ouverts, evident par
               exemple dans ces possibilités d'internationalisation très extensives. Edites en
               anglais, les parties essentielles des Guidelines ont ete disponible en plusieurs
               autres langues (y compris l'allemand, l'espagnol, le francais, le chinois, le
               japonais...) depuis longtemps, et leur systeme de gestion est concu pour faciliter la
               traduction en d'autres. A part cette position ouverte envers les langues humaines, le
               systeme TEI est egalement acceuillant aux autres langues informatiques. Comme tout
               autre systeme XML, il héberge volontairement d’autres espaces de noms, et facilite
               l'inclusion des autres schémas existants. Par exemple, un document TEI XML peut
               integrer des fragments SVG pour les graphiques, des fragments MathML pour les maths,
               des fragments ML pour la musique annotee etc. La définition d’un élément TEI peut
               inclure (s’il y en a) un mapping avec d’autres ontologies, formalisé par un élément
                  <gi>equiv</gi> (équivalent). Donc le transfer automatique du semantique d'un
               encodage TEI vers une autre representation (utilisant unm autre ontologie) est
               envisageable. </p>
            <!-- <div xml:lang="fr">
            <head>Un standard existe pour qu'on s'y conforme, non ?</head>
            <figure>
               <graphic url="../Graphics/1991-TEI-commandments.png" height="80%"/>
            </figure>
         </div>-->
            <p>Tous ces possibilites de modification et cette flexibilite pourraient bien mettre en
               cause le statut normatif de la TEI. En fin de compte, qu’est-ce que cela veut dire :
               « être conforme » à la TEI ? Pendant sa longue periode d'evolution, la TEI a vu
               evoluer une pratique de balisage consensuelle profitant d'un lexique commun, et base
               sur un respect de l’autonomie de ces utilisdateurs. On peut dire que la
               standardisation facon TEI ne signifie pas « fais comme moi » ; elle veut dire
               « explique-moi ce que tu fais. »</p>
            <!-- </div>
         <div xml:lang="fr">
            <head>L’évolution darwinienne, ça marche…</head>
            <list>
               <item>faites vos modifications dans votre espace de nom</item>
               <item>documentez-les dans un ODD</item>
               <item>faites discuter vos propositions sur la liste TEI-L, ou dans un SIG !</item>
               <item>proposez les modifications efficaces au Conseil Scientifique de la TEI, en
                  faisant une "feature request" sur sourceforge</item>
               <item>Il y a une version nouvelle de TEI P5 deux fois par an…</item>
            </list>
            <p rend="box">... et n'oubliez pas de vous abonner au Consortium !</p>-->
         </div>
      </body>
   </text>
</TEI>
