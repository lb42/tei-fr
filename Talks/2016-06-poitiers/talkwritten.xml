<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml"
	schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main"> La TEI pour les corpus linguistiques: un standard qui se
               renouvelle</title>
            <author>
               <name>
                  <forename>Lou</forename>
                  <surname>Burnard</surname>
               </name><affiliation/>
               <email>lou.burnard@gmail.com</email>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>TEI Consortium</publisher>
            <date/>
            <availability>
               <p>Creative Commons Attribution 4.0 International</p>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>No source, born digital.</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="fr">fr</language>
         </langUsage>
         <textClass>
            <keywords xml:lang="en">
               <term/>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change when="2017-01-26">More or less complete</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div  type="abstract">
            <!-- <front>
         <p> Votre contribution devrait reprendre les éléments de votre communication « La TEI (Text
            Encoding Initiative) pour les corpus langagiers : un standard qui se renouvelle » en
            tenant compte, au moins dans l’introduction et la discussion des points signalés
            ci-dessous. La longueur de cette contribution devrait être de 65000 signes (espaces
            compris) et suivre les contraintes éditoriales qui sont indiquées dans le fichier joint.
            Nous fixons comme date limite de transmission le 5 Février 2017. Dans un premier temps
            nous avons besoin de connaître rapidement votre accord. Ceci nous permettra de
            répertorier les réponses favorables, et en cas de réponses défavorables, de réviser
            immédiatement les longueurs imposées. Il serait donc important que nous ayons votre
            accord ou désaccord avant le 3 janvier. Nous indiquerons les éventuelles modifications
            de longueurs le 5 janvier, laissant donc 1 mois pour la rédaction finale. Le comité de
            publication se trouve, comme toujours, face à l’exigence éditoriale qui consiste à
            donner à un volume un maximum de cohérence. Il a estimé tout d’abord qu’une restriction
            du champ pouvait y contribuer. En conséquence nous avons décidé de centrer ce volume sur
            les objets de langage, écrit ou oral. Une autre façon de faire converger des apports
            multiples est d’éviter l’écueil voyant que serait une pure juxtaposition d’exposés
            monographiques (au demeurant tout à fait estimables intrinsèquement). Or il est
            souhaitable qu’un livre qui porte sur un sujet actuellement crucial offre des repérages,
            des considérations prospectives, pour éclairer de plus haut les opérations actuelles
            d’annotation. C’est pourquoi il nous semble intéressant de vous inviter à écrire votre
            texte avec à l’esprit quelques « points vigiles » dont ils peuvent assez librement tirer
            profit et qui pourront donner aux diverses entreprises une sorte d’horizon commun. Il
            nous semblerait utile d’inclure, autant que possible, dans l’article des considérations,
            même assez succinctes, de type « méta-métadonnées ». Ces considérations peuvent par
            exemple passer par un préliminaire génétique qui montre comment s’est élaboré puis
            développé l’appareil d’annotation adopté. Il serait utile que, au moins dans 
            l’introduction et dans la discussion de votre contribution, vous abordiez la perspective
            adoptée par votre travail en vous inspirant des points indiqués dans la section
            ci-dessous en italiques. 
            
            Si l’on prend un peu de hauteur par rapport aux entreprises de
            métadonnées, on s’aperçoit en effet qu’elles obéissent à des logiques génétiques
            différentes. Et l’histoire de cette élaboration en conditionne les limites et la
            fécondité. Ainsi certaines sont au départ centrées sur un objet limité dont elles
            épousent finement les caractéristiques dans l’étiquetage. Mais au fur et à mesure, elles
            peuvent viser un spectre plus large d’objets, donc revoir leur appareil par
            confrontation avec des entreprises voisines. Leur cinétisme est de type « bottom up ».
            Elles acquièrent alors une fonctionnalité large, au risque de s’adapter moins aisément à
            la diversité des situations précises. D’autres, au contraire, visent d’emblée une
            couverture très large d’objets dont elles voudraient pourtant étiqueter finement le
            contenu. Au risque qu’elles ne puissent pas épouser toutes les situations singulières
            rencontrées. Elles sont alors plutôt « top down ». Certaines tentent d’adapter un
            standard existant, d’autres se lancent dans l’invention d’un logiciel-maison. Il n’y a
            pas forcément de bonne ou de mauvaise formule mais le choix conditionne en partie les
            avantages et les inconvénients à venir. Certaines offrent une interface conviviale,
            intuitive, d’autres en revanche sont hérissées de difficultés, par manque de tutoriel
            par exemple. Eclairer un peu chacune des contributions à la lumière de considérations de
            ce genre ( et il ne s’agit pas d’être exhaustif ici) , c’est offrir au lecteur , outre
            une fenêtre sur une entreprise particulière , une meilleure perception des écoles ou
            plutôt des orientations actuellement en présence. Ce bénéfice nous semble important
            lorsqu’un sujet comme celui-ci est au cœur d’une des révolutions les plus déterminantes
            des sciences et de l’avenir de nos sociétés. Nous souhaitons donc vous inviter
            cordialement à donner à votre exposé ce surcroît de largeur de vue qui donnera à
            l’ouvrage des traits communs. </p>
      </front>-->
            <p>Nous considérons le cas de la Text Encoding Initiative (TEI) comme standard pour
               l’encodage des ressources textuelles et des metadonnées dans les science humaines,
               notamment linguistiques et littéraires. Après considération des variétés possibles
               des efforts de standardisation (top-down et bottom-up, générique et spécifique) nous
               évoquons le contexte historique d’où est ressorti l’Initiative, et ses effets sur son
               architecture, notamment sur la flexibilité et modifiabilité du système. Nous
               discutons les étapes typiques d’une application réussie de la TEI, en considérant
               quelques cas spécifiques, et nous terminons avec la proposition que la longévité du
               standard TEI serait en partie signifiante due à ces capacités de mutation et sa
               flexibilité.</p>
         </div>
      </front>
      <body>
         <div>
            <head>Combien de standards faut-il dans le monde ?</head>
            <p>Face aux complexités et à la fragmentation du monde scientifique actuel, on voit une
               croissance inévitable des standards, chacun bien adapté aux besoins et aux priorités
               d’un communauté quelconque, mais inutile, incompréhensible, voire nuisible aux
               interêts d’un autre. Pour bien fonctionner, tout standard de metadonnées devrait être
               capable de co-exister avec tout autre, et ainsi d’interagir avec eux. Par
               consequence, il y a une tendance de construire des standards de plus en plus méta, de
               plus en plus ambitieux. On a tendence à élaborer des politiques globales, des
               standards génériques, capable de gérer tous les points de vues des particuliers, tout
               en permettant leur continuité, et en meme temps d’élaborer des standards de plus en
               plus minutieux, specialisés pour les contextes de plus en plus précises. Et les
               standards naissent et évoluent et se multiplient dans un paysage complexe. En somme,
               ce n’est guère difficile de retrouver des standards. La problème reste comment
               choisir parmi eux.</p>
            <p>On peut les distinguer nettement par rapport aux agences responsable de leur création
               et de leur maintenance. Par exemple, les standards ressortant des agences officielles
               de standardisation, au niveau national (l’AFNOR, l’ANSI, le BSI, ou le DIN en europe)
               ou internationales (ISO, IEC, W3C, OASIS ...) sont forcément élaborés et gérés d’une
               autre manière des standards ressortissant des industries intéressées (LISA, MPEG
               ...); les politiques d’accès aux standards seront assez différents dans ces deux cas.
               Et pour le monde scientifique, on rencontre souvent des projets ayant des enjeux
               pré-normatifs, tels que les projets français du Consortium Cahier, Ortolang
                  etc.<note>Pour Cahier voir https://cahier.hypotheses.org/, pour Ortolang
                  https://www.ortolang.fr/</note> en même temps que des agences (DARIAH,
                  CLARIN...)<note>Pour ces agences infrastructurales voir http://www.dariah.eu/ et
                  https://www.clarin.eu/</note> ayant comme mission la promotion des standards et
               des bonne pratiques qui y sont associés. Et (mais peut être un peu moins qu’avant)
               les enjeux des agences appartenant au monde scientifique risquent toujours de se
               différencier de ceux qui sont nés au monde d’affaires ou aux sociétés privés. </p>
            <p>On peut aussi positionner les standards selon leur manière de répondre à la question
                  <q>Combien de standards faut-il au monde ?</q>, pour gérer les complexités
               d’origine et d’environnement déjà évoqués. Le plus simple des réponses serait de dire
                  <q>un seul</q>: il faut trouver une solution centralisée et dirigiste, qu’on
               pourrait caricaturiser avec l’acronyme WKWBFY (We Know What’s Best For You). A
               l’autre extrème on pourrait répondre <q>aucun</q> et rester content des
                  <soCalled>standards</soCalled> entièrement anarchiste, en supposant que chacun des
               utilisateurs aurait ses propres besoins, même ses propres perceptions, jusqu’au point
               qu’aucun standard ne serait possible parce que (encore un acronyme) NWEUMP (Nobody
               Will Ever Understand My Problems). Et entre ces deux extrèmes on peut répondre
                  <q>autant qu’il en arrive</q>: la solution pragmatique ou laissez-faire, qui
               suivrait bêtement les voix qui crient le plus fort: la solution FTH (Follow The
               Herd).</p>
            <p>Si ces remarques ont l’air un peu cynique, c’est peut être à cause du fait que les
               normes ne s’imposent pas aisément dans la vie intellectuelle. Soit elles émergent
               d’un besoin de la communauté; soit leur usage dérive de la nécessité d’utiliser une
               technologie particulière, mais on ne renonce pas volontairement à son indépendance
               scientifique ! Quelques uns de nos collègues ont mëme tendence de s’imaginer qu’on
               pourrait se passer des standards. Pour ces collègues, les standards constituent un
               inconvénience majeur : ce n’est pas forcément souhaitable de figer un état de la
               connaissance, mais c’est necessaire pour la standardisation. Ceux qui sont en train
               de formuler de nouveaux hypotheses et de revoir constamment la structuration d’une
               problème, ont bien raison de rester sceptique en ce qui concerne la nécessité d’une
               standardisation jugée prématurée et étouffante. D’ailleurs, la production des
               standards est toujours chronophage, nécessitant des compétences interdisciplinaires
               qui ne sont pas forcément disponible à tout scientifique. De même, l’apprentisage et
               l’utilisation des standards peut être également chronophage. </p>
            <p>Néanmoins, les standards disposent de plusieurs avantages qu’il faut souligner à ces
               collegues sceptiques. En l’absence de standards numériques, comment sur le web
               identifier et retrouver des ressources numériques ayant un intérêt linguistique ?
               Comment valider les résultats scientifiques obtenus par d’autres personnes ? comment
               enrichir ou intégrer les ressources existantes avec ses propres idées ? Comment
               séparer les ressources des outils qui les gèrent/analysent ? Pour tout cela, les
               standards restent essentiels. Ils répondent aussi à plusieurs besoins techniques, que
               tout scientifique devrait reconnaitre : par exemple, la possibilité de recombiner ou
               de réutiliser les systèmes existants; l’évolution modulaire des logiciels ; la
               réduction des coûts de formation ; et la possibilité de profiter de l’existence de
                  <q>frequently answered questions</q> &#x2014; des solutions qui s’appliquent dans
               plusieurs domaines. Les standards donc offrent des possibilités à ne pas minimiser !
            </p>
         </div>
         <div>
            <head>Origines et enjeux de la TEI</head>

            <p>Dans le domaine des humanites numériques, la Text Encoding Initiative (TEI) <note>Le
                  site du Consortium TEI se trouve à www.tei-c.org: parmi plusieurs textes
                  introductifs, nous citons celui du présent auteur <title>Qu’est-ce que la
                     TEI?</title> (Open Edition Press; 2015
                  http://books.openedition.org/oep/1237)</note> est responsable de l’un des
               standards scientifiques le plus établi, et le plus discuté, meme par les gens qui ne
               s’en servent pas, et cela pour de bonnes raison. D’abord, la lecture est au coeur des
               études humanistiques, et lire, c’est encoder. L’interprétation des mots d’un objet
               écrit n’est pas aléatoire : elle est guidée par les signes de ponctuation, par les
               changements de police, par leur disposition spatiale etc ! Pour indiquer les même
               choses (et d’autres) dans un texte numérique, une balisage devient essentiel, car
               c’est le balisage qui sert à exprimer nos lectures préalables, et qui rend possible
               une polyvalence des ressources textuelles. Le balisage induit egalement des
               réflexions profondes sur la matérialité des textes qu’elles impliquent.</p>
            <p> Plus précisement, on emploie le terme TEI (Initiative pour l’Encodage Textuel) pour
               identifier trois choses différentes: <list>
                  <item> un ensemble de recommandations pour l’encodage des ressources numériques
                     avec XML </item>
                  <item>un infrastructure internationale responsable de la maintenance, de
                     l’évolution, et de la distribution de ces recommandations </item>
                  <item>une communauté internationale d’utilisateurs de ces recommandations</item>
               </list> Il serait peut etre mieux donc de considerer la TEI comme plutôt un cadre
               permettant de réflechir sur ce que c’est qu’un texte numérisé qu’un standard fixe. </p>
            <p> Dès sa conception initiale en 1987, la Text Encoding Initiative s’est proposée comme
               méthode de faciliter la construction, la déscription, la structuration, et
               l’annotation des corpus linguistiques et littéraires &#x2014; de tous types, de
               toutes périodes, dans toutes les langues. Elle etait conçue comme format pivot, son
               but étant de rendre faisable l’interchange, voire l’interoperabilité de tous les
               formats incompatibles des media déjà prévus à cette epoque, La TEI précèdait le Web,
               le DVD, le téléphone portable, la télévision cablée, et Microsoft Word. Alors, vu que
               les technologies informatiques qui survivent plus de 5 ans sont assez rares, la
               question qui s’impose autour d’elle aujourd’hui est : pourquoi et comment la TEI
               a-t-elle survécu plus de 30 ans ? J’essaie de répondre à cette question en
               conclusion, mais je commence avec un focus sur les circonstances de sa naissance. </p>
            <p>Du point de vue historique, la TEI est un produit d’une rarissime conjonction
               d’interêts parmi plusieurs communautés scientifiques. Les chercheurs littéraires, les
               stylométriciens, les critiques de l’école <soCalled>close reading</soCalled> de même
               que les historiens, les archivistes, et les éditeurs; les bibliographes, les
               bibliothécaires; et bien sûr les linguistes, notamment, mais pas exclusivement, de
               corpus; à ne rien dire des informaticiens ... tous ces communautés scientifiques se
               sentaient concernés par le passage au numérique des textes écrits ou oraux à grande
               échelle. A la fin des années 80 on voyait déjà apparaitre sous forme numérique des
               fonds essentiels aux sciences humaines et sociaux (par ex de grands dictionnaires
               comme le Oxford English Dictionary, ou de corpus textuels comme le Thesaurus Linguae
               Graecae), et ça dans des formats très divers. Au moment de naissance de ce que nous
               appellons de nos jours les humanités numériques on s’est aperçu déjà qu’on risquait
               une nouvelle confusion des langues avec l’arrivée de l’informatique dans la
               représentation des données textuelles !</p>
            <p>En même temps, la TEI prétendait fournir une réponse pratique aux deux oppositions
               typiques des <soCalled>humanités numériques</soCalled> : c’est à dire, primo
               l’opposition entre les besoins des débutants et ceux des experts; et secundo
               l’opposition entre les besoins et les interêts des scientifiques et ceux des
               ingénieurs </p>
            <p>En ce qui concerne l’opposition entre expert et novices, la TEI essayait de plaire a
               tous les deux D’un côté, elle cherchait de présenter et de soutenir des solutions
               préconnues, consensuelles, bien établies: les topoï sur lesquels <q>tout le monde
                  s’est mis d’accord</q> &#x2014; et que les débutants devraient donc arriver à
               comprendre. De l’autre, elle cherchait de soutenir la recherche, et donc la
               découverte des solutions aux questions pas encore posées, ou posables &#x2014; ainsi
               permettant aux experts de partager leur expertise. De cette tension sont nees les
               efforts de la TEI pour permettre à la fois un certain rigeur dans ces propositions,
               sans cloture de la porte sur des modifications assez fondamontales de ces mêmes
               propositions. </p>
            <p>Par rapport aux tensions voire mécomprehensions entre les informaticiens et les
               non-techniciens, la TEI proposait (et propose toujours) aux ingénieurs un système
               bien adapté à l’implantation avec des outils informatiques courants, tout en essayant
               de s’exprimer dans une langue compréhensible aux non-techniciens, et dérivée des
               conceptes bien comprises dans les sciences humaines. Le but était d’assurer une
               compréhension mutuelle: que les techniciens arrivent à comprendre le modèle de base
               des SHS, et que les chercheurs arrivent à s’exprimer en profitant d’une modèle plus
               ou moins formalisee. C’est pour cela que la documentation du système TEI est
               tellement extensive, ressemblant à la fois à une dictionnaire savante du dix-neuvième
               siecle et à un manuel d’encodage du vingtième. </p>
            <p> En plus, et en dépit de son nom, la TEI ne s’adressait pas uniquement au texte
               proprement dit. Même dans P1 (la version initiale) on trouve déjà des propositions
               assez complètes pour les métadonnées bibliographiques, pour l’encodage des
               transcriptions orales, et même pour les analyses linguistiques abstraites en termes
               de structures de traits en complément des propositions pour l’encodage des structures
               traditionnelles du livre et leurs composants typiques. Néanmoins, a l’origine, la TEI
               ne s’intéressait pas tellement au web (ça n’éxistait pas), ni à la mise en page (les
               outils de desktop publishing éxistaient déjà). Elle laissait à coté l’intégration des
               pages-images/facsimilés numérisés (trop expensif) et du coup la représentations des
               faits ou des objets (c’est l’enjeu des bases de données). Et elle n’était pas de tout
               concernée par la production des outils ou de logiciels (pas notre boulot). Dans un
               premier temps elle se focalisait sur : les métadonnées, les textes, les analyses
               textuelles et linguistiques. bien sûr, nous avons changé tout cela... </p>
            <p>La TEI actuelle facilite un balisage <soCalled>intelligent</soCalled> d’une énorme
               variété de types de documents, à plusieurs niveaux de complexité. Elle s’applique
               forcément à l’encodage des composants structuraux et fonctionnels d’un texte et aux
               transcriptions diplomatiques des sources historiques, des images, et des annotations.
               Elle soutient la représentation et gestion des liens, des correspondances, et des
               alignements de fragments textuels. Elle propose une manière standardisee d’encoder
               les informations non-textuelles concernant les <soCalled>entités nommés</soCalled> :
               par exemple des personnes, des lieux ou des événements. Elle est l’outil de
               préférence pour tous ceux concernés par les annotations péritextuelles et
               métatextuelles (correction, suppression, ajouts). Elle permet la représentation
               d’analyses linguistiques, et les métadonnées de plusieurs types, y compris la
               définition formelle d’un schéma XML. Bref, elle fournit une encyclopédie de balisage
               adaptée à tout ce qui pourrait être d’interêt aux sciences humaines et sociales. Elle
               répond aux besoins des éditeurs des textes primaires, aux attentes des historiens et
               des linguistes, et aux nécessités des bibliothècaires et des archivistes. Et pour
               gérer ces richesses, la TEI a du construire un modèle et des mécanismes de gestion
               très génériques, permettant son évolution bien au dela du noyau de concernes
               typiques. </p>
         </div>
         <div>
            <head>Organisation et utilisation</head>
            <p> La TEI peut ainsi être considérée comme un des plus grands efforts
               d’interdisciplinarité de son époque: d’où deux principes de son architecture.
               D’abord, à cause de son envergure encylopedique, sa construction necessitait
               l’application systematique du rasoir d’Ockham ; et ensuite son utilisation necessite
               l’usage de quelques mécanismes de personnalisation. </p>
            <p> L’importance du rasoir est manifeste des qu’on considere combien de fois il arrive
               que les mêmes objets portent de noms divers et que des objets divers ne sont pas
               toujours distingués par le nom. En souhaitant éviter une multiplication ingérable de
               concepts, la TEI fournit typiquement une proposition générique, par exemple
                  <gi>div</gi> pour tout type de division, au lieu de <q>chapitre</q>,
                  <q>section</q>, <q>partie</q> etc. De même facon, elle propose un élément
               generique <gi>q</gi> pour tout type de discours, mais cet élément est aussi complete
               pas d’autres plus spécifiques. Par exemple, on peut distinguer le discours direct en
               utilisant la balise <gi>said</gi> et la citation en utilisant la balise
                  <gi>quote</gi>. Et, pour ceux qui souhaient des distinctions encore plus fines, la
               TEI fournit aussi la balise <gi>mentioned</gi> pour les meta-discours, et la balise
                  <gi>soCalled</gi> pour les expressions pour lesquelles l’auteur ou le narrateur
               renonce à toute responsabilité. Il faut souligner que de telles distinctions
               jésuitiques ne sont pas obligatoires, simplement elles sont mises à la disposition
               des chercheurs qui souhaient les utiliser. La TEI ne va pas vous dire <q>il faut
                  baliser cela</q>; elle dit <q>si vous souhaitez distinguer cela, voici une balise
                  precise pour le faire.</q></p>
            <p>En consequence, le système TEI ressemble un peu à un énorme buffet où il faut bien
               réfléchir avant de remplir son plateau. Il faut d’abord comprendre le gabarit avant
               de construire son propre système d’encodage. Sans cela, on n’arrivera pas à bien
               adapter ce kit lego aux besoins de l’utilisateur, restant en même temps
               compréhensible par d’autres personnes ou systèmes, manifestant clairement les
               modifications éventuelles qu’on à effectuees. L’outil de déscription des grammaires
               TEI, qui s’appelle ODD, facilite ce travail, et devient donc une partie essentielle
               du système. ODD est un abbréviation de la phrase <q>One Document Does it all</q> (un
               document fait tout), conçu comme vocabulaire XML spécialisée pour la déscription des
               vocabulaires XML, sert aussi à décrire une personnalisation de la TEI. Son nom dérive
               du fait qu’on peut générer à partir d’un seul document TEI XML, à la fois un schéma
               formel (un DTD) destiné à l’attention d’un parseur ou d’autre logiciel, et de
               documentation destinée à l’attention d’un lecteur humain. </p>
            <p>En effet, il n’y a pas de TEI dtd unique car la TEI est un système
                  <emph>modulaire</emph>. On s’en sert pour créer un système d’encodage selon ses
               propres besoins, en sélectionnant des <term>modules</term> spécifiques de l’ensemble
               fourni par la TEI. Chacun de ces modules définit une brique contenant un groupe
               d’éléments (et leurs attributs). On peut séléctionner dans cette brique les éléments
               souhaités, et même en changer des propriétés. On peut y mélanger des éléments
               nouveaux, ou bien natifs ou bien d’autres standards. </p>
            <p>Dans les 1 400 pages imprimées des TEI Guidelines, vous trouverez : un lexique de 564
               éléments ; une grammaire comprenant des règles d’usage et des contraintes exprimées
               en langue naturelle et s en langages formels ; et <emph>beaucoup</emph> de
               discussions notamment de plusieurs exemples d’utilisation. Ce que vous ne trouverez
               pas est un guide <q>one size fits all</q> pour les debutants qui expliquera comment
               en pratique profiter de ces richesses, un type de <title>Guide pour les
                  égarés</title>. Inutile de rapprocher la TEI pour cela: les Guidelines furent
               conçus comme manuel de référence générique, non pas comme tutoriel explicatif adapté
               aux novices d’un ou plusieurs disciplines spécifiques. La création de telles
               matériaux tutoriels reste une tâche pour les spécialistes, puisqu’il faut toujours
               adapter la TEI aux besoins et aux préconceptions d’une discipline spécifique. On peut
               par exemple citer le tutoriel TEI Lite, et sa version plus récente simplePrint,
                  <note>Voir
                  http://www.tei-c.org/release/doc/tei-p5-exemplars/html/tei_simplePrint.doc.html</note>
               bien adapté aux besoins de ceux qui travaillent avec la numérisation des livres
               imprimes, ou à la documentation du collaboratif Epidoc,<note>voir
                  https://sourceforge.net/projects/epidoc/</note> specialisée pour les
               epigraphistes, et quelques autres.</p>
            <p>Si les buts de votre projet ne sont pas très loin des enjeux de ceux qui profitent
               d’un de ces tutoriels déjà existant, tant mieux. Mais sinon, ou si vous souhaitez
               vraiment modifier and adapter les propositions de la TEI (je note en passant que la
                  <q>P</q> des versions de TEI &#x2014; P1, P2, jusqu’à l’actuel P5 &#x2014;
               correspond au mot <mentioned>proposals</mentioned>), je vous conseille de suivre
               une procédure un peu formelle, pour laquelle je propose le titre <title>le chemin de
                  l’Eveil TEI</title>. Il y a cinq étapes distinctes sur ce chemin: <list>
                  <item>La modelisation des buts et des objets de votre projet; </item>
                  <item>L’orientation de ces objets par rapport aux objets déjà reconnus par la TEI; </item>
                  <item>La déclaration formelle de votre spécification TEI-conforme; </item>
                  <item>La documentation de vos pratiques TEI ; </item>
                  <item>Et la validation de vos corpus par rapport à la specification ainsi
                     construite. </item>
               </list>
            </p>
            <p> La modélisation initiale de vos données est un préalable essentiel. Que vous vous
               servez de UML, de RDBMS, de SKOS, ou quoique ça soit d’autre, si vous n’avez pas un
               modèle explicite des objets et concepts que vous espérez gérer, vous aurez de grands
               difficultés. Pour les projets TEI, tout comme les projets de base de donnees
               classique, il fait passer par une étape plus ou moins formelle d’identification des
                  <term>objets d’interêt</term> et de leurs attributs et propriétés ; suivi d’une
               reconnaissance des relations entre objets. Il faut aussi prendre en compte les
               procédures et les traitements essentielles envisagés pour votre corpus. Fastidieux ou
               oneureux qu’il puisse paraître, ce travail reste essentiel pour tout projet
               d’informatisation, et surtout pour un projet espérant profiter d’un système formalisé
               comme l’est la TEI. </p>
            <p>Les projets de numérisation bien réussis prennent aussi en compte une autre axe: la
               précision et la cohérence avec lesquelles un objet particulier peut être identifié et
               donc traité dans l’ensemble des materiaux de sources. Je reviens sur ce point. </p>
            <p>Au deuxième étape, vous devez essayer d’orienter votre modèle par rapport à celui de
               la TEI. Dans la séquence des 22 chapitres des Guidelines,<note>disponible a
                  http://www.tei-c.org/release/doc/tei-p5-doc/en/html/</note> chacun correspondant à
               un module de définitions, ou dans les listes alphabétiques de définitions exhaustives
               de classes (183), d’éléments (546), d’attributs (470), de macros(8), et même de types
               de données (28), comment se retrouver? Comment savoir quel élément (etc) choisir pour
               tel ou tel entité identifiée dans votre analyse préalable ? Comment savoir que vous
               avez besoin d’une licorne &#x2014; un élément pas encore reconnu à la TEI? </p>
            <p>Il faut ne pas cacher une triste vérité: il n’y a aucune méthode scientifique ; aucun
               raccourci pour cela... Il faut étudier les exemplaires et les définitions pour savoir
               si cet élément TEI si prometteur s’applique en effet à votre cas. Il est carrément
               impossible d’échapper à cette problème de traduction entre modèles. Pour chacun(e)
               des entités/concepts identifiés dans votre modèle, il faut donc décider s’il existe
               un objet TEI qui lui correspond parfaitement; ou, sinon, quel objet TEI lui ressemble
               et quelles petites modifications seraient nécessaires pour qu’il lui corresponde
               parfaitement. Ou même, quelle lacune TEI votre analyse vous permettra de corriger
               (car, oui, elles existent les licornes !) </p>
            <p>Considérons un cas concret. Supposons que l’on ait obtenu un financement ANR pour un
               projet de numérisation et de transcription d’une collection gigantesque de cartes
               postales. Comment va-t-on créer un système TEI apte à gérer des centaines (peut être
               des milliers) de cartes postales numérisees ? Supposons que nous nous sommes décidés
               de faire un peu plus que de mettre à disposition des images numeriques des deux cotés
               de chaque carte, Il faut au moins trouver un moyen d’identifier chaque carte et de
               lui associer des metadonnées. Mais l’étendu des metadonnées qu’on pourrait souhaiter
               ajouter est vaste, et a priori il est très difficile d’identifier celles qui sont les
               plus signifiantes. On pourrait focaliser par exemple sur des propretés physiques et
               objectives (la taille de la carte, sa méthode de production...); en bon historien/ne
               on pourrait souhaiter noter le nom et l’adresse de son editeur, le sujet représenté
               sur la carte, les informations sur l’expédition ou la réception de la carte (tamponée
               à tel endroit à telle date, destinée à cette autre endroit...). Supposons d’ailleurs
               que l’on soit motivé de transcrire soigneusement les mots écrits sur chaque carte, en
               les distinguant bien sûr des mots eventuels imprimés ou tamponnés, qui auraient un
               statut different. En ce cas, les cartes sont de petits documents archivales, avec des
               variations linguistique de grand interet (des formules de politesse, des mentions de
               lieux et de personnes) à ne rien dire des annotations paratextuelles ou
               metatextuelles éventuelles (des ratures, des corrections, des ajouts, des changements
               d’écriture...). </p>
            <p>En choissisant entre ces possibilités on aura tendence naturel de prioritiser les
               distinctions qui sont facile à implementer, et de laisser à coté celles qui sont
               difficile à effectuer avec cohérence ou à cout raisonnable. Par exemple, assurément
               il serait d’interet de distinguer les écrivains des cartes postales selon leur sexe
               ou leur classe sociale. Mais il faut se demander jusqu’à quel point on peut faire
               cette distinction avec cohérence dans une masse de textes écrits par des inconnu/es
               et pas forcément signés d’une manière non-ambigue. De même facon, il y a des
               propretés de cartes très facile à identifier mais d’un interet scientifique minimale
               (couleur d’encre, taille d’ecriture, position du timbre par rapport à l’addresse...).
               Tout projet de numérisation doit forcément trouver un bel equilibre entre le faisable
               et l’utile car la liste des notions balisables, chacune d’importance pour un type
               d’analyse quelconque, risque de devenir ingérables. En voici une bonne raison d’avoir
               bien fait son analyse au préalable! </p>
            <p>Supposons enfin que nous avons bel et bien discuté des cartes, et nous voilà avec
               notre bilan du top ten (ou top twenty ou top fifty) catégories de metadonnées
               essentielle. Maintenant on passe au deuxieme étape. On regarde bien dans les TEI
               Guidelines, et helas il n y a rien sur les cartes postales. Mais il y a des
               propositions très complètes pour quelques aspects qui nous intéressent: par exemple,
               il y a des balises conçues pour l’encodage des metadonnées concernant l’expédition
               des lettres (la balise <gi>correspDesc</gi> et cie) que nous pouvons adapter. Il y a
               tout une gamme de balises pour l’encodage des manuscrits où nous risquons de nous
               noyer par ses richesses. Il y a des propositions très utiles pour la représentation
               de nominations (de lieu, de personne etc.) et des entités nommés associés avec ces
               noms. Il y a des balises pour représenter les graphies qui sont parties constitutives
               d’un document, et des mécanismes pour associer un fragment de texte transcrit avec sa
               représentation graphique. bien sûr il y a aussi des mécanismes pour faciliter
               l’indexation des documents selon un classement semantique, topologique, analytique
               etc etc. Il y a même une balise <gi>stamp</gi> qui peut être nous servira pour
               l’encodage des timbres postes. </p>
            <p>Un peu rassuré, nous faisons le bilan des elements TEI qui nous semblent utiles, avec
               leurs attributs, et nous passons au troisième et quatrième étapes : la construction
               d’une spécification TEI adaptée à nos besoins, et de sa documentation en forme de
               ODD. C’est une procédure technique, moins difficile que la construction d’un schéma de
               base de données, mais qui lui ressemble un peu. La TEI fournit un outil online
               (http://www.tei-c.org/Roma/) pour faciliter cette tâche, et elle héberge également
               des matériaux tutoriaux. Notre objectif sera de générer un schéma formel pour valider
               nos données TEI XML, exprimé en langue informatique tel que DTD, RELAXNG, W3C Schema,
               Schematron. Ce grammaire va contrôler l’essentiel en déterminant quelles balises
               seront disponibles dans quels contextes, avec quels attributs et avec quelles
               valeurs, et en respectant quelles contraintes. </p>
            <p>L’interêt de ODD est en partie qu’il nous permet de définir toutes ces contraintes
               d’une manière standardisée et indépendente de tout langue formel de schéma. Mais peut
               être plus signifiant, il nous permet aussi d’intégrer cette définition avec une
               documentation complète pour expliquer nos principes éditoriaux, nos principes de
               choix de balises, l’organisation de notre schéma etc. Ces explications seront très
               précieux pour les utilisateurs de nos données et aux developpeurs de notre système,
               et aussi à nous même d’ici quelques jours quand nous aurons oublié pourquoi nous
               avons prise telle ou telle décision. Cette documentation d’ailleurs (comme le TEI
               Guidelines) peut s’exprimer en plusieurs langues naturelles et peut se présenter en
               plusieurs formats bureautiques (PDF, Word, HTML, epub...) </p>
            <p>En ce qui concerne la séléction des éléments, la TEI est conçue pour soutenir une
               variété d’approches, sommarisée dans cette figure: <figure>
                  <graphic url="../Graphics/oddFlavours.png" height="42px" width="42px"/>
                  <head type="legend">Variétés de personnalisation TEI</head>
               </figure></p>
            <p>On peut tout simplement utiliser un sous-ensemble des éléments, attributs etc
               proposés (TEI subset). On fait sa selection et la tâche est complète. Mais il arrive
               souvent qu’on souhaite faire quelques legères (ou pas si legères) modifications, par
               exemple de contraindre les valeurs d’un attribut qui dans sa version canonique
               permettrait nimporte quoi: donc on précise ses modifications en ajoutant des
               contraintes supplémentaires (customized subset). Ces contraintes s’expriment dans la
               meme langue ODD. Et si eventuellement on ajoute de composants pas de tout prévus par
               la TEI 9des licornes peut être0, ou si on arrive à modifier un objet TEI jusqu’à ce
               que cet objet devienne méconnaissable cest à dire il n’est plus valide selon le
               schéma TEI All on a affaire avec un extension de la TEI (extended subset). Dans ce
               cas, tout à fait legitime, il faut distinguer les composants nonTEI en les faisant
               appartenir à une autre espace de noms. </p>
            <p>Plus concretement, examinons cet ODD adapté aux besoins d’un projet imginaire ayant
               besoin d’un schéma très réduit et simple: </p>
            <egXML xmlns="http://www.tei-c.org/ns/Examples"><div>
                  <head>Une personalisation TEI pour la transcription collaborative</head>
                  <p>Cette personalisation propose un schéma minimal pour la transcription
                     collaborative des documents archivals. </p>
                  <schemaSpec ident="transMin" start="TEI text div" docLang="fr">
                     <moduleRef key="tei"/>
                     <moduleRef key="header"
                        include="teiHeader fileDesc titleStmt 
                     publicationStmt sourceDesc"/>
                     <moduleRef key="textstructure" include="TEI text body div"/>
                     <elementRef key="ab"/>
                     <elementRef key="pb"/>
                     <elementRef key="unclear"/>
                     <elementRef key="hi"/>
                     <elementRef key="name"/>
                     <elementRef key="title"/>
                     <classSpec type="atts" ident="att.declaring" mode="delete"/>
                     <classSpec type="atts" ident="att.fragmentable" mode="delete"/>
                     <classSpec type="atts" ident="att.edition" mode="delete"/>
                     <classSpec type="atts" ident="att.editLike" mode="delete"/>
                     <classRef key="att.global.rendition" except="rendition style"/>
                  </schemaSpec>
               </div>
            </egXML>
            <p>Notons d’abord que ce fragment est lui-même un document TEI XML très simple: il
               contient les éléments classiques TEI <gi>div</gi>, <gi>head</gi> et <gi>p</gi>,
               utilisés par presque tout document TEI pour signaler une division de texte, un titre,
               et une paragraphe respectivement. L’élément <gi>schemaSpec</gi> et ses attributs
               servent à définir le schéma formel qu’on souhaite générer à partir de cette
               spécification. L’attribut <att>transMin</att> fournit le nom du schéma, l’attribut
                  <att>start</att> indique les éléments qui seront capable d’agir comme racine d’un
               document conforme à ce schéma, et l’attribut <att>docLang</att> précise la langue
               naturelle dans laquelle la documentation du schéma sera générée, si possible. Au sein
               de cet élément <gi>schemaSpec</gi> on trouve les composants désirés pour le schema,
               qui sera un simple sous-ensemble. Ces composants sont spécifiés à l’aide des éléments
                  <gi>moduleRef</gi>, qui précise le nom d’un module TEI qu’on souhaite intégrer par
               moyen de son attribut <att>key</att>. Dans ce cas, on souhaite intégrer tous les
               objets fournis par le module infrastructurale qui s’appelle <ident>tei</ident> (c’est
               typique pour un schéma TEI), mais on souhaite sélectionner qu’un petit nombre
               d’éléments des deux autres modules référenciés ici, à savoir, dans le module
                  <ident>header</ident> on ne sélectionne que les éléments <gi>teiHeader</gi>,
                  <gi>fileDesc</gi>, <gi>titleStmt</gi>, <gi>publicationStmt</gi>, et
                  <gi>sourceDesc</gi> ; et dans le module <ident>textstructure</ident> on a choisi
               que les elements <gi>TEI</gi>, <gi>text</gi>, <gi>body</gi> et <gi>div</gi>. Cette
               méthode précise le module d’où un élément est dérivé, ce qui n’est pas toujours
               nécessaire: on peut également spécifier seul le nom de l’élément souhaité en
               utilisant l’élément <gi>elementRef</gi>, ce qui est le cas ici pour les elements
                  <gi>ab</gi>. <gi>pb</gi>, <gi>unclear</gi>, <gi>hi</gi> et <gi>name</gi>. </p>
            <p>Pour comprendre cette redondance de méthodes, il faut savoir qu’un module peut aussi
               définir des <term>classes</term>, qui seront automatiquement inclus dans le schéma
               indépendemment de la suppression (ou inclusion) des éléments. Une des deux fonctions
               d’une classe est de fournir des attributs, qui deviendront ainsi disponible sur tous
               les éléments de notre schéma appartenant aux classes concernées. Ce qui n’est pas
               toujours souhaitable surtout dans un cas comme le notre où on souhaite minimiser les
               composants du schéma. C’est pour cette raison que notre petit ODD conclut en
               supprimant quatre classes déjà fournies par les modules selectionnés, et en reduisant
               le nombre d’attributs fourni par le cinquieme. Mais là nous entrons peut être trop
               dans les détails techniques du système. </p>
            <p>Continuons donc de personnaliser notre schéma. La TEI propose pour l’élément
                  <gi>div</gi> un attribut <att>type</att> dont les valeurs sont par defaut
               indéfinies: ce qui implique que toute valeur sera permise. Mais supposon que dans
               notre projet nous envisageons utiliser cet attribut pour distinguer entre des types
               d’unité structurant (par ex section, sous-section, etc.) ou pour distinguer les
               divisions en terme de leur fonction (par ex preliminaire, question, reponse, etc.) ou
               selon n’importe quel autre taxinomie. Il est donc très probable que nous préférions
               de contraindre les valeures possibles de cet attribut. Un ODD nous permet de faire
               cela aisément. Il suffira d’ajouter une redéfinition de l’élément <gi>div</gi>, comme
               ceci: <egXML xmlns="http://www.tei-c.org/ns/Examples">
                  <elementSpec ident="div" mode="change">
                     <attList>
                        <attDef ident="type" mode="replace">
                           <valList>
                              <valItem ident="prelim"><desc>preliminaire</desc></valItem>
                              <valItem ident="quest"><desc>questionnement</desc></valItem>
                              <valItem ident="rep"><desc>reponse</desc></valItem>
                              <valItem ident="autre"><desc>autre type de division</desc></valItem>
                           </valList>
                        </attDef>
                     </attList>
                  </elementSpec></egXML> Notez bien d’abord qu’il s’agit d’ajouter un élément
                  <gi>elementSpec</gi> et non pas un <gi>elementRef</gi>. Pourquoi? parce que nous
               souhaitons ajouter de nouvelle information, pour compléter les informations déjà
               fourni pour l’élément <gi>div</gi>, que nous avons retrouvé du module
                  <ident>textstructure</ident>. La valeur <ident>change</ident> pour l’attribut
                  <att>mode</att> de cet élément <gi>elementSpec</gi> indique qu’il faut combiner
               les deux ensembles d’informations, et non pas tout remplacer. Par contre, la
               définition de l’attribut <att>type</att> déjà existant est à remplacer entièrement :
               c’est pour cela que l’attribut <att>mode</att> de l’élément <gi>attDef</gi> porte la
               valeur <ident>replace</ident>. </p>
            <p>La remplacement consiste en fournissant une liste complète des valeurs legales pour
               cet attribut en forme d’un élément <gi>valList</gi>. Chacun des valeurs possibles est
               documenté par un élément <gi>valItem</gi>, dont l’attribut <att>ident</att> précise
               la valeur elle-même, et un élément facultatif <gi>desc</gi> fournit une documentation
               plus elaborée. </p>
            <p>Cet exemple démontre aussi jusqu’à quel point la documentation, lisible par des êtres
               humaines, et la spécification d’une grammaire formelle validable par un automate,
               sont liés ensemble dans une spécification ODD.</p>
         </div>
         <div>
            <head>Pourquoi continuer de s’intéresser à la TEI ?</head>
            <p>Il y a peut être (au moins) deux raisons pour lesquelles les standards échouent le
               plus souvent. Ou bien ils sont basés sur une théorie pas encore mûre; ou bien la
               communauté envisagée est trop diverse ou trop fragmentée pour en profiter. Le secret
               de la réussite de la TEI et de sa longévité serait-il dans ses capacités d’évolution,
               qui l’aurait permise à echapper à ces deux defis ? </p>
            <p>Une personnalisation TEI peut faire presque tout pour modifier les propositions
               standardisees. Il permet non seulement une sélection explicite des éléments et des
               attributs considérés comme utiles, mais aussi la limitation des valeurs possibles
               d’un attribut plus ou moins strictement; la proposition des règles Schematron pour
               controller le contenu d’un élément (p.e. co-dependency) plus strictement que la TEI
               ne permet. Il permet l’ajout de nouveaux éléments (ou classes d’élément), labellisés
               dans votre propre espace de noms, mais appartenant aux classes sémantiques
               prédéfinies par la TEI. Cet architecture permet donc d’évoluer et de tester sa
               théorie, en restant toujours TEI-conforme. </p>
            <p>L’architecture TEI est également construit sur des principes ouvertes, évidentes par
               exemple dans ces possibilités d’internationalisation très extensives. Editées en
               anglais, les parties essentielles des Guidelines ont été mises à disposition en
               plusieurs autres langues (y compris l’allemand, l’espagnol, le francais, le chinois,
               le japonais...) depuis longtemps, et leur système de gestion est conçu pour faciliter
               la traduction en d’autres. à part cette position ouverte envers les langues humaines,
               le système TEI est egalement acceuillant aux autres langues informatiques. Comme tout
               autre système XML, il héberge volontairement d’autres espaces de noms, et facilite
               l’inclusion des autres schémas existants. Par exemple, un document TEI XML peut
               intégrer des fragments SVG pour les graphiques, des fragments MathML pour les maths,
               des fragments ML pour la musique annotee etc. La définition d’un élément TEI peut
               inclure (s’il y en a) un mapping avec d’autres ontologies, formalisé par un élément
                  <gi>equiv</gi> (équivalent). Donc le transfer automatique du semantique d’un
               encodage TEI vers une autre représentation (utilisant un autre ontologie) est
               envisageable. </p>

            <p>Tous ces possibilités de modification et cette flexibilité pourraient bien mettre en
               cause le statut normatif de la TEI. En fin de compte, qu’est-ce que cela veut dire :
               « être conforme » à la TEI ? Pendant sa longue période d’éxistence, la TEI à vu
               évoluer une pratique de balisage consensuelle profitant d’un lexique commun, et basé
               sur un respect de l’autonomie de ces utilisateurs. Comme déjà noté, on peut dire que
               la standardisation facon TEI ne signifie pas « fais comme moi » ; elle veut dire
               plutot « explique-moi ce que tu fais. » A mon avis c’est précisement cette
               flexibilité qui aurait lui conféré sa perennité: tout commme prévu par la théorie
               d’évolution darwinienne, ce sont les êtres rigides et sans possibilité de
               modification qui risquent de disparaître. </p>
            <p>La TEI continue donc de changer et de se modifier selon les besoins et les priorités
               de sa communauté d’utilisateurs: La où elle devient ou apparait maladaptée, on est
               toujours libre de la modifier, d’abord dans son propre espace de noms. On est obligé
               de documenter ces modifications dans un ODD qui permet ainsi une discussion informée
               des propositions de modification par toute la communaute interesse, par exemple sur
               la liste TEI-L, sur le site github du Conseil Scientifique de la TEI, ou dans une
               groupe de travail autonome. Les modifications efficaces derivées de ces discussions
               peuvent etre ainsi intégrées à l’ensemble des recommendations de la TEI, contribuant
               aisi à son évolution progressive, et à son enrichissement. Et depuis 2000, on a vu
               sortir une version nouvelle de TEI P5 au moins 2 fois par an; le plus souvent
               contenant des fautes corrigées, de nouveaux exemples, etc. mais aussi des
               élargissements importants des topiques traités ou des améliorations
               infrastructurales. </p>
         </div>
      </body>
      <back>
         <div type="bibliography">
            <listBibl>
               <bibl xml:id="bloggs13"/>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
