<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml"
	schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main"> La TEI pour les corpus linguistiques: un standard qui se
               renouvelle</title>

            <author>
               <name>
                  <forename>Lou</forename>
                  <surname>Burnard</surname>
               </name><affiliation/>
               <email>lou.burnard@gmail.com</email>
            </author>
         </titleStmt>
         <publicationStmt>
            <publisher>TEI Consortium</publisher>
            <date/>
            <availability>
               <p>Creative Commons Attribution 4.0 International</p>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>No source, born digital.</p>
         </sourceDesc>
      </fileDesc>

      <profileDesc>
         <langUsage>
            <language ident="en">en</language>
         </langUsage>
         <textClass>
            <keywords xml:lang="en">

               <term/>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change/>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract" xml:id="abstract"/>
      </front>

      <body>
         <!-- 65000 chars plus spaces -->
         <div>
            <head>Combien de standards faut-il dans le monde ?</head>
            <p>Pour bien fonctionner, un standard de metadonnées devrait être capable de décrire
               tous les autres standards et ainsi d’interagir avec eux. Il y a donc une tendance de
               construire des standards de plus en plus méta, de plus en plus ambitieux. Face aux
               complexités et fragmentation du monde scientifique, on voit une croissance inévitable
               des standards, chacun bien adapté aux besoins et aux priorités d’un communauté
               quelconque, mais inutile, incompréhensible, voire nuisible aux interêts d’un autre.
               On a donc tendence à élaborer des politiques globales, des standards génériques,
               capable de gérer tous les points de vues des particuliers, tout en permettant leur
               continuité. En plus, les standards naissent et évoluent et se multiplient dans un
               paysage complexe. En somme, ce n’est guère difficile de retrouver des standards. La
               problème reste comment choisir parmi eux.</p>
            <p>On peut les distinguer nettement par rapport aux agences responsable de leur création
               et de leur maintenance. Par exemple, les standards ressortant des agences officielles
               de standardisation, au niveau national (l’AFNOR, l’ANSI, le BSI, ou le DIN en europe)
               ou internationales (ISO, IEC, W3C, OASIS ...) sont forcément élaborés et gérés d’une
               autre manière des standards ressortissant des industries intéressées (LISA, MPEG ...)
               ; les politiques d’acces aux standards seront assez différents dans ces deux cas. Et
               pour le monde scientifique, on rencontre souvent des projets ayant des enjeux
               pré-normatifs, tels que les projets francais Cahier, Ortolang etc. en même temps que
               des agences (DARIAH, CLARIN...) ayant comme mission la promotion des standards et des
               bonne pratiques qui y sont associés. Et (mais peut être un peu moins qu’avant) les
               enjeux des agences appartenant au monde scientifique risquent toujours de se
               différencier de ceux qui sont nés au monde d’affaires aux sociétés privés. </p>
            <p>On peut aussi positioner les standards selon leur manière de répondre à la question
                  <q>Combien de standards faut-il au monde ?</q>, pour gérer les complexités
               d’origine et d’environnement déjà évoqués. Le plus simple des réponses serait de dire
                  <q>un seul</q>: il faut trouver une solution centralisée et dirigiste, qu’on
               pourrait caricaturiser avec l’acronyme WKWBFY (We Know What’s Best For You). A
               l’autre extreme on pourrait répondre <q>aucun</q> et rester content des
                  <soCalled>standards</soCalled> entièrement anarchiste, en supposant que chacun des
               utilisateurs aurait ses propres besoins, même ses propres perceptions, jusqu’au point
               qu’aucun standard ne serait possible parce que (encore un acronyme) NWEUMP (Nobody
               Will Ever Understand My Problems). Et entre ces deux extrèmes on peut répondre
                  <q>autant qu’il en arrive</q> : la solution pragmatique ou laissez-faire, qui
               suivrait bêtement les voix qui crient le plus fort: la solution FTH (Follow The
               Herd).</p>
            <p>Si ces remarques ont l’air un peu cynique, c’est peut être à cause du fait que les
               normes ne s’imposent pas dans la vie intellectuelle. Soit elles émergent d’un besoin
               de la communauté; soit leur usage dérive de la nécessité d’utiliser une technologie
               particulière, mais on ne renonce pas volontairement à son indépendance scientifique !
               Quelques uns de nos collegues ont toujours tendence de s’imaginer qu’on pourrait se
               passer des standards. Pour ces collegues, les standards pourraient constituer un
               inconvénient majeur : ce n’est pas forcément souhaitable de figer un état de la
               connaissance, mais c’est necessaire pour la standardisation. Ceux qui sont en train
               de formuler de nouveaux hypotheses et de revoir constamment la structuration d’une
               problème, ont bien raison de rester sceptique en ce qui concerne la nécessité d’une
               standardisation jugée prématurée et étouffante. D’ailleurs, la production des
               standards est toujours chronophage, nécessitant des compétences interdisciplinaires
               qui ne sont pas forcément disponible à tout scientifique. De même, l’apprentisage et
               l’utilisation des standards peut être également chronophage. </p>
            <p>Quand même, il y a des avantages qu’il faut souligner à ces collegues sceptiques. En
               l’absence de standards numeriques, comment sur le web identifier et retrouver des
               ressources numériques ayant un intérêt linguistique ? Comment valider les résultats
               scientifiques obtenus par d’autres personnes ? comment enrichir ou intégrer les
               ressources existantes avec ses propres idées ? Comment séparer les ressources des
               outils qui les gèrent/analysent ? Pour tout cela, les standards restent essentiels.
               Ils répondent aussi à plusieurs besoins techniques, que tout scientifique devrait
               reconnaitre : par exemple, la possibilité de recombiner ou de réutiliser les systèmes
               existants; l’évolution modulaire des logiciels ; la réduction des coûts de formation
               ; et la possibilité de profiter de l’existence de <q>frequently answered
                  questions</q> &#x2014; des solutions qui s’appliquent dans plusieurs domaines. Les
               standards donc offrent des possibilités à ne pas minimiser ! </p>
         </div>
         <div>
            <head>Origines et enjeux de la TEI</head>
            <!--   <div xml:lang="fr">
        <head>Lire, c’est encoder... </head>
        <list>
          <item>L’interprétation des mots d’un texte n’est pas aléatoire : elle
            est guidée par les signes de ponctuation, par les changements de
            police, par leur disposition spatiale etc !</item>
          <item>Pour indiquer les même choses (et d’autres) dans un texte
            numérique, une balisage devient essentiel</item>
          <item>Le balisage sert ainsi à exprimer nos lectures préalables</item>
          <item>Le balisage rend possible une polyvalence des ressources
            textuelles et induit des réflexions profondes sur la matérialité des
            textes qu’elles impliquent</item>
        </list>
      </div>
      <div xml:lang="fr">
        <head>Concrètement la Text Encoding Initiative (TEI) c’est quoi ?</head>
        <p> Une <soCalled>Initiative pour l’Encodage Textuel</soCalled>....</p>
        <list>
          <item rend="pause">un ensemble de <soCalled>recommandations</soCalled>
            pour l’encodage des ressources numériques avec XML</item>
          <item rend="pause">un infrastructure internationale responsable de la
            maintenance, de l’évolution, et de la distribution de ces
            recommandations</item>
          <item rend="pause">une communauté internationale d’utilisateurs de ces
            recommandations</item>
        </list>
        <p rend="box">Plutôt un cadre permettant de réflechir sur ce que c’est
          qu’un texte numérisé qu’un "standard" fixe.</p>
      </div>
      <div rend="slide">
        <head>Les enjeux de la TEI</head>
        <p><hi>"Text Encoding for Interchange"</hi></p>
        <list>
          <item>faciliter la <hi>création</hi>, l’<hi>échange</hi>, et
              l’<hi>intégration</hi> des données textuelles informatisées <list>
              <item>toute sorte de textes</item>
              <item>toutes les langues </item>
              <item>toute origine temporelle ou culturelle</item>
            </list></item>
          <item>La TEI s’adresse également ...<list>
              <item>aux débutants, cherchant des solutions bien connues et
                consensuelles</item>
              <item>aux experts, cherchant à créer de nouvelles solutions</item>
            </list></item>
        </list>
      </div>
      <div xml:lang="fr">
        <head>Les buts de la TEI</head>
        <list>
          <item>faire des <hi>recommandations</hi> qui se basent sur un
            consensus existant</item>
          <item>préférer les <hi>solutions générales</hi> à celles spécifiques à
            une discipline</item>
          <item>en même temps permettre la <hi>spécialisation</hi> et
              <hi>l’extension</hi></item>
        </list> -->

            <p> Dès sa conception initiale en 1987, la Text Encoding Initiative s’est proposée comme
               méthode de faciliter la construction, la déscription, la structuration, et
               l’annotation des corpus linguistiques et littéraires &#x2014; de tous types, de
               toutes périodes, dans toutes les langues. Elle etait conçue comme format pivot, son
               but étant de rendre faisable l’interchange, voire l’interoperabilité de tous les
               formats incompatibles des media déjà prévus à cette epoque, La TEI précèdait le Web,
               le DVD, le téléphone portable, la télévision cablée, et Microsoft Word. Alors, vu que
               les technologies informatiques qui survivent plus de 5 ans sont assez rares, la
               question qui s’impose autour d’elle aujourd’hui est : pourquoi et comment la TEI
               a-t-elle survécu plus de 30 ans ? J’essaie de répondre à cette question en
               conclusion, mais je commence avec un focus sur les circonstances de sa naissance. </p>
            <p>Du point de vue historique, la TEI est un produit d’une rarissime conjonction
               d’interêts parmi plusieurs communautés scientifiques. Les chercheurs littéraires, les
               stylométriciens, les critiques de l’école <soCalled>close reading</soCalled> de même
               que les historiens, les archivistes, et les éditeurs; les bibliographes, les
               bibliothécaires; et bien sur les linguistes, notamment, mais pas exclusivement, de
               corpus; à ne rien dire des informaticiens ... tous ces communautés scientifiques se
               sentaient concernés par le passage au numérique des textes écrits ou oraux à grande
               échelle. à la fin des annees 80 on voyait déjà apparaitre sous forme numerique des
               fonds essentiels aux SHS (par ex de grands dictionnaires comme le Oxford English
               Dictionary, ou de corpus textuels comme le Thesaurus Linguae Graecae), et ca dans des
               formats tres varies. Au moment de naissance de ce que nous appellons de nos jours les
               humanites numeriques on s’est aperçu déjà qu’on risquait une nouvelle confusion des
               langues avec l’arrivée de l’informatique dans la représentation des données
               textuelles !</p>
            <p>En même temps, la TEI prétendait fournir une réponse pratique aux deux oppositions
               typiques des <soCalled>humanités numériques</soCalled> : c’est à dire, primo
               l’opposition entre les besoins des débutants et ceux des experts; et secundo
               l’opposition entre les besoins et les interêts des scientifiques et ceux des
               ingénieurs </p>
            <p>En ce qui concerne l’opposition entre expert et novices, la TEI essayait de plaire a
               tous les deux D’un côté, elle cherchait de présenter et de soutenir des solutions
               préconnues, consensuelles, bien établies: les topoï sur lesquels <q>tout le monde
                  s’est mis d’accord</q> &#x2014; et que les débutants devraient donc arriver à
               comprendre. De l’autre, elle cherchait de soutenir la recherche, et donc la
               découverte des solutions aux questions pas encore posées, ou posables &#x2014; ainsi
               permettant aux experts de partager leur expertise. De cette tension sont nees les
               efforts de la TEI pour permettre à la fois un certain rigeur dans ces propositions,
               sans cloture de la porte sur des modifications assez fondamontales de ces mêmes
               propositions. </p>
            <p>Par rapport aux tensions voire mécomprehensions entre les informaticiens et les
               non-techniciens, la TEI proposait (et propose toujours) aux ingénieurs un système
               bien adapté à l’implantation avec des outils informatiques courants, tout en essayant
               de s’exprimer dans une langue compréhensible aux non-techniciens, et dérivée des
               conceptes bien comprises dans les sciences humaines. Le but était d’assurer une
               compréhension mutuelle: que les techniciens arrivent à comprendre le modèle de base
               des SHS, et que les chercheurs arrivent à s’exprimer en profitant d’une modèle plus
               ou moins formalisee. C’est pour cela que la documentation du système TEI est
               tellement extensive, ressemblant à la fois à une dictionnaire savante du 19ème siecle
               et un manuel d’encodage du 20ème. </p>
            <p> En plus, et en dépit de son nom, la TEI ne s’adressait pas uniquement au texte
               proprement dit. Même dans P1 (la version initiale) on trouve déjà des propositions
               assez complètes pour les métadonnées bibliographiques, pour l’encodage des
               transcriptions orales, et même pour les analyses linguistiques abstraites en termes
               de structures de traits en complément des propositions pour l’encodage des structures
               traditionnelles du livre et leurs composants typiques. Néanmoins, a l’origine, la TEI
               ne s’intéressait pas tellement au web (ça n’éxistait pas), ni à la mise en page (les
               outils de desktop publishing éxistaient déjà). Elle laissait à coté l’intégration des
               pages-images/facsimilés numérisés (trop expensif) et du coup la représentations des
               faits ou des objets (c’est l’enjeu des bases de données). Et elle n’était pas de tout
               concernée par la production des outils ou de logiciels (pas notre boulot). Dans un
               premier temps elle se focalisait sur : les métadonnées, les textes, les analyses
               textuelles et linguistiques. Bien sur, nous avons changé tout cela... </p>
            <p>La TEI actuelle facilite un balisage <soCalled>intelligent</soCalled> d’une énorme
               variété de types de documents, à plusieurs niveaux de complexité. Elle s’applique
               forcément à l’encodage des composants structuraux et fonctionnels d’un texte et aux
               transcriptions diplomatiques des sources historiques, des images, et des annotations.
               Elle soutient la représentation et gestion des liens, des correspondances, et des
               alignements de fragments textuels. Elle propose une manière standardisee d’encoder
               les informations non-textuelles concernant les <soCalled>entités nommes</soCalled> :
               par exemple des personnes, des lieux ou des événements. Elle est l’outil de
               preference pour tous ceux concernes par les annotations péritextuelles et
               métatextuelles (correction, suppression, ajouts). Elle permet la représentation
               d’analyses linguistiques, et les métadonnées de plusieurs types, y compris la
               définition formelle d’une schéma XML. Bref, elle fournit une encyclopedie de balisage
               adaptee à tout ce qui pourrait être d’interet aux sciences humaines et sociales. Elle
               répond aux besoins des editeurs des textes primaires, aux attentes des historiens et
               des linguistes, et aux necessites des bibliothecaires et des archivistes. Et pour
               gérer ces richesses, la TEI a du construire un modèle et des mechanismes de gestion
               tres generique, permettant son evolution bien au dela du noyau de concernes typiques.
            </p>
         </div>
         <div>
            <head>Organisation et utilisation</head>
            <p> La TEI peut ainsi être considérée comme un des plus grands efforts
               d’interdisciplinarité de son époque: d’où deux principes de son architecture.
               D’abord, à cause de son envergure encylopedique, sa construction necessitait
               l’application systematique du rasoir d’Ockham ; et ensuite son utilisation necessite
               l’usage de quelques mécanismes de personnalisation. </p>
            <p> L’importance du rasoir est manifeste des qu’on considere combien de fois il arrive
               que les mêmes objets portent de noms divers et que des objets divers ne sont pas
               toujours distingués par le nom. En souhaitant éviter une multiplication ingérable de
               concepts, la TEI fournit typiquement une proposition générique, par exemple
                  <gi>div</gi> pour tout type de division, au lieu de <q>chapitre</q>,
                  <q>section</q>, <q>partie</q> etc. De même facon, elle propose un élément
               generique <gi>q</gi> pour tout type de discours, mais cet élément est aussi complete
               pas d’autres plus spécifiques. Par exemple, on peut distinguer le discours direct en
               utilisant la balise <gi>said</gi> et la citation en utilisant la balise
                  <gi>quote</gi>. Et, pour ceux qui souhaient des distinctions encore plus fines, la
               TEI fournit aussi la balise <gi>mentioned</gi> pour les meta-discours, et la balise
                  <gi>soCalled</gi> pour les expressions pour lesquelles l’auteur ou le narrateur
               renonce à toute responsabilité. Il faut souligner que de telles distinctions
               jesuitiques ne sont pas obligatoires, simplement elles sont mises à la disposition
               des chercheurs qui souhaient les utiliser. La TEI ne va pas vous dire <q>il faut
                  baliser cela</q>; elle dit <q>si vous souhaitez distinguer cela, voici une balise
                  precise pour le faire.</q></p>
            <p>En consequence, le système TEI ressemble un peu à un enorme buffet ou il faut bien
               réfléchir avant de remplir son plateau. Il faut d’abord comprendre le gabarit avant
               de construire son propre système d’encodage. Sans cela, on n’arrivera pas à bien
               adapter ce kit lego aux besoins de l’utilisateur, restant en même temps
               compréhensible par d’autres personnes ou systèmes, manifestant clairement les
               modifications éventuelles qu’on à effectuees. L’outil de description des grammaires
               TEI, qui s’appelle ODD, facilite ce travail, et devient donc une partie essentielle
               du système. ODD (One Document Does it all), conçu comme vocabulaire XML specialisee
               pour la description des vocabulaires XML, sert aussi à decrire une personnalisation
               de la TEI. Son nom derive du fait qu’on peut generer à partir d’un seul document TEI
               XML, à la fois un schema formel (un DTD) destine à l’attention d’un parseur ou autre
               logiciel, et de documentation destinee à l’attention d’un lecteur humain. </p>
            <p>En effet, il n’y a pas de TEI dtd unique car la TEI est un système
                  <emph>modulaire</emph>. On s’en sert pour créer un système d’encodage selon ses
               propres besoins, en sélectionnant des <term>modules</term> spécifiques de l’ensemble
               fourni par la TEI. Chacun de ces modules définit une brique contenant un groupe
               d’éléments (et leurs attributs). On peut séléctionner dans cette brique les éléments
               souhaités, et même en changer des propriétés. On peut y mélanger des éléments
               nouveaux, ou bien natifs ou bien d’autres standards. </p>
            <!--
               <head>Organisation logique de la TEI</head>
               <p><graphic url="../Graphics/class-system-FR.png"/>-->
            <p>Dans les 1 400 pages imprimées des TEI Guidelines, vous trouverez : un lexique de 564
               éléments ; une grammaire comprenant des règles d’usage et des contraintes exprimées
               en langue naturelle et s en langages formels ; et <emph>beaucoup</emph> de
               discussions notamment de plusieurs exemples d’utilisation. Ce que vous ne trouverez
               pas est un guide <q>one size fits all</q> pour les debutants qui expliquera comment
               en pratique profiter de ces richesses, un type de <title>Guide pour les
                  egares</title>. Inutile de rapprocher la TEI pour cela: les Guidelines furent
               conçus comme manuel de reference generique, non pas comme tutoriel explicatif adapte
               aux novices d’un ou plusieurs disciplines specifiques. La creation de telles
               tutoriels est une tache pour les specialistes, puisqu’il faut toujours adapter la TEI
               aux besoins et aux preconceptions d’une discipline specifique. On peut par exemple
               citer le tutoriel TEI Lite, et sa version plus recente simplePrint, bioen adapte aux
               besoins de ceux qui travaillent avec la numérisation des livres imprimes, ou à la
               documentation du collaboratif Epidoc, specialisee pour les epigraphistes, et quelques
               autres.</p>
            <p>Si les buts de votre projet ne sont pas tres loin des enjeux de ceux qui profitent
               d’un de ces tutoriels déjà existant, tant mieux. Mais sinon, ou si vous souhaitez
               vraiment modifier and adapte les propositions de la TEI (je note en passant que la
                  <q>P</q> des versions de TEI &#x2014; P1, P2, jusqu’a l’actuel P5 &#x2014;
               correspond au mot <mentioned>proposals</mentioned>, vous etes bien avise de suivre un
               procedure un peu formel, pour lequel je propose le titre <title>le chemin de l’Eveil
                  TEI</title>. Il y a cinq étapes distinctes sur ce chemin: <list>
                  <item>La modelisation des buts et des objets de votre projet; </item>
                  <item>L’orientation de ces objets par rapport aux objets déjà reconnus par la TEI; </item>
                  <item>La declaration formelle de votre specification TEI-conforme; </item>
                  <item>La documentation de vos pratiques TEI ; </item>
                  <item>Et la validation de vos corpus par rapport à la specification ainsi
                     construite. </item>
               </list>
            </p>
            <p> La modelisation initiale de vos données est un préalable essentiel. Que vous vous
               servez de UML, de RDBMS, de SKOS, ou quoique ça soit d’autre, si vous n’avez pas un
               modèle explicite des objets et concepts que vous espérez gérer, vous aurez de grands
               difficultés. Pour les projets TEI, tout comme les projets de base de donnees
               classique, il fait passer par une étape plus ou moins formelle d’identifier (par
               exemple) les <term>objets d’interêt</term> ; leurs attributs et propriétés ; les
               relations entre objets ; et les procédures/traitements essentiels envisagés qui
               dependeront de leur presence dans votre corpus. Fastidieux ou oneureux qu’il puisse
               paraitre, ce travail reste essentiel pour tout projet d’informatisation, et surtout
               pour un projet esperant de profiter d’un système formalise comme l’est la TEI. </p>
            <p>Les projets de numérisation bien reussis prennent aussi en compte une autre axe: la
               précision et la cohérence avec lesquelles un objet particulier peut être identifié et
               donc traité dans l’ensemble des materiaux de sources. Je reviens sur ce point. </p>
            <p>Au deuxieme étape, vous devez essayer d’orienter votre modèle par rapport à celui de
               la TEI. Dans la séquence des 22 chapitres des Guidelines, chacun correspondant à un
               module de definitions, ou dans les listes alphabétiques de définitions exhaustives de
               classes (183), d’éléments (546), d’attributs (470), de macros(8), et même de types de
               données (28), comment se retrouver? Comment savoir quel élément (etc) choisir pour
               tel ou tel entité identifiée dans votre analyse préalable ? Comment savoir que vous
               avez besoin d’une licorne &#x2014; un élément pas encore reconnu à la TEI? </p>
            <p>Il faut ne pas cacher une triste vérité: il n’y a aucune méthode scientifique ; aucun
               raccourci pour cela... Il faut étudier les exemplaires et les définitions pour savoir
               si cet élément TEI si prometteur s’applique en effet à votre cas comme. En effet,
               c’est le cas pour d’autres types de mapping egalement... Pour chacun(e) des
               entités/concepts identifiés dans votre modèle, il faut donc décider : s’il existe un
               objet TEI qui lui correspond parfaitement; ou, sinon, quel objet TEI lui ressemble et
               quelles petites modifications seraient nécessaires pour qu’il lui corresponde
               parfaitement. Ou même, quelle lacune TEI votre analyse vous permettra de corriger
               (car, oui, elles existent les licornes !) </p>
            <p>Considerons un cas concret. Supposons que l’on ait obtenu un financement ANR pour un
               projet de numérisation et de transcription d’une collection gigantesque de cartes
               postales. Comment va-t-on créer un système TEI apte à gérer des centaines (peut être
               des milliers) de cartes postales numérisees ? Supposons que nous nous sommes decidés
               de faire un peu plus que mettre à disposition des images numeriques des deux cotés de
               chaque carte, Il faut au moins trouver moyen d’identifier chaque carte et de lui
               associer des metadonnées. Mais l’étendu des metadonnées qu’on pourrait souhaiter
               ajouter est vaste, et a priori il est tres difficile d’identifier celles qui sont les
               plus signifiantes. On pourrait focaliser par exemple sur des propretés physiques et
               objectives (la taille de la carte, sa méthode de production...); en bon historien/ne
               on pourrait souhaiter noter le nom et l’adresse de son editeur, le sujet représenté
               sur la carte, les informations sur l’expédition ou la reception de la carte (tamponée
               à tel endroit à telle date, destinée à cette autre endroit...). Supposons d’ailleurs
               que l’on soit motivé de transcrire les mots écrits sur chaque carte, en les
               distinguant bien sur des mots eventuels imprimés ou tamponnés, qui auraient un statut
               different. En ce cas, les cartes sont de petits documents archivales, avec des
               variations linguistique de grand interet (des formules de politesse, des mentions de
               lieux et de personnes) à ne rien dire des annotations paratextuelles ou
               metatextuelles éventuelles (des ratures, des corrections, des ajouts, des changements
               d’écriture...). </p>
            <p>En choissisant entre ces possibilités on aura tendence naturel de prioritiser les
               distinctions qui sont facile à implementer, et de laisser à coté celles qui sont
               difficile à effectuer avec cohérence ou à cout raisonnable. Par exemple, assurément
               il serait d’interet de distinguer les écrivains des cartes postales selon leur sexe
               ou leur classe sociale. Mais il faut se demander jusqu’à quel point on peut faire
               cette distinction avec cohérence dans une masse de textes écrits par des inconnu/es
               et pas forcément signés d’une manière non-ambigue. De même facon, il y a des
               propretés de cartes tres facile à identifier mais d’un interet scientifique minimale
               (couleur d’encre, taille d’ecriture, position du timbre par rapport à l’addresse...).
               Tout projet de numérisation doit forcément trouver un bel equilibre entre le faisable
               et l’utile car la liste des notions balisables, chacune d’importance pour un type
               d’analyse quelconque, risque de devenir ingérables. En voici une bonne raison d’avoir
               bien fait son analyse au préalable! </p>
            <p>Supposons enfin que nous avons bel et bien discuté des cartes, et nous voilà avec
               notre bilan du top ten (ou top twenty ou top fifty) catégories de metadonnées
               essentielle. Maintenant on passe au deuxieme étape. On regarde bien dans les TEI
               Guidelines, et helas il n y a rien sur les cartes postales. Mais il y a des
               propositions tres complètes pour des aspects qui nous interessent: par exemple, il y
               a des balises conçues pour l’encodage des metadonnées concernant l’expédition des
               lettres (la balise <gi>correspDesc</gi> et cie) que nous pouvons adapter. Il y a tout
               une gamme de balises pour l’encodage des manuscrits où nous risquons de nous noyer
               par ses richesses. Il y a des propositions tres utiles pour la représentation de
               nominations (de lieu, de personne etc.) et des entités nommés associés avec ces noms.
               Il y a des balises pour représenter les graphies qui sont parties constitutives d’un
               document, et des mécanismes pour associer un fragment de texte transcrit avec sa
               représentation graphique. Bien sur il y a des mécanismes aussi pour faciliter
               l’indexation des documents selon un classement semantique, topologique, analytique
               etc etc. Il y a même une balise <gi>stamp</gi> qui peut être nous servira pour
               l’encodage des timbres postes. </p>
            <p>Un peu rassure/e, nous faisons le bilan des elements TEI qui nous semblent utiles,
               avec leurs attributs, et nous passons au troiseme et quatrieme etapes : la
               construction d’une specification TEI adaptee a nos besoins, et sa documentation en
               forme de ODD. C’est un procedure technique, moins difficile que la constrution d’un
               schema de base de donnees, mais qui lui ressemble un peu. La TEI fournit un outil
               online (http://www.tei-c.org/Roma/) pour faciliter cette tache, et heberge egalement
               des materiaux tutoriaux. L’essentiel sera de generer un schema formel pour valider
               nos donnees TEI XML, exprime un langue informatique tel que DTD, RELAXNG, W3C Schema,
               Schematron. Ce grammaire va contrôler l’essentiel en determinant quelles balises
               seront disponibles ? dans quels contextes ? avec quels attributs ? avec quelles
               valeurs ? et en respectant quelles contraintes ? </p>
            <p>L’interet de ODD est en partie qu’il nous permet de definir ces contraites d’une
               maniere standardisee et independente de tout langue formel de schema. Mais peut etre
               plus signifiant, il nous permet d’integrer cela avec une documentation complete pour
               expliquer nos principes éditoriaux, nos principes de choix de balises, etc. aux
               utilisateurs, aux developpeurs, et a nous meme d’ici quelques jours. Cette
               documentation d’ailleurs (comme le TEI Guidelines) peut s’exprimer en plusieurs
               langues naturelles et peut se presenter en plusieurs formats bureautiques (PDF, Word,
               HTML, epub...) </p>
            <p>En ce qui concerne la selection des elements, la TEI est conçue pour soutenir une
               variété d’approches, sommarize dans ge graphie: <figure>
                  <graphic url="../Graphics/oddFlavours.png" height="42px" width="42px"/>
                  <head type="legend">Varietes de personnalisations TEI</head>
               </figure></p>
            <p>Le plus simple: on peut simplement utiliser un sous-ensemble de ses propositions (TEI
               subset). On fait une selection et la tache est complete. Mais il arrive souvent qu’on
               souhaite faire des legeres (ou pas legeres) modification, par exemple d’ajouter des
               contraintes supplémentaires (customized subset). Ceux ci s’expriment dans la meme
               langue ODD. Et on pourrait eventuellement souhaiter y ajouter de nouveaux composants
               (extended subset). Dans ce cas, bien sur, il faut distikbguer ces composants non TEI
               en les precisant un namespace different. </p>
            <p>Plus concretement, examinons cet ODD adapte a un projet imginaire ayant besoin d’un
               schema tres reduit et simple: </p>
            <egXML xmlns="http://www.tei-c.org/ns/Examples"><div>
                  <head>Une personalisation TEI pour la transcription collaborative</head>
                  <p>Cette personalisation propose un schéma minimal pour la transcription
                     collaborative des documents archivals. </p>
                  <schemaSpec ident="transMin" start="TEI text div" docLang="fr">
                     <moduleRef key="tei"/>
                     <moduleRef key="header"
                        include="teiHeader fileDesc titleStmt 
                     publicationStmt sourceDesc"/>
                     <moduleRef key="textstructure" include="TEI text body div"/>
                     <elementRef key="ab"/>
                     <elementRef key="pb"/>
                     <elementRef key="unclear"/>
                     <elementRef key="hi"/>
                     <elementRef key="name"/>
                     <elementRef key="title"/>
                     <classSpec type="atts" ident="att.declaring" mode="delete"/>
                     <classSpec type="atts" ident="att.fragmentable" mode="delete"/>
                     <classSpec type="atts" ident="att.edition" mode="delete"/>
                     <classSpec type="atts" ident="att.editLike" mode="delete"/>
                     <classRef key="att.global.rendition" except="rendition style"/>
                  </schemaSpec>
               </div>
            </egXML>
            <p>Notons d’abord que ce fragment est lui-meme un TEI document tres simple: il contient
               les elements TEI <gi>div</gi>, <gi>head</gi> et <gi>p</gi>, utilises pafrtout dans la
               TEI pour une division de texte, un titre, et une paragraphe respectivement. L’element
                  <gi>schemaSpec</gi> et ses attributs servent a definir le schema formel qu’on
               souhaite generer a [partir de cette specificagtion. L’sattribut <att>transMin</att>
               fournit le nom du schema, l’attrubut <att>start</att> indique les elements qui seront
               capable d’agir comme racine d’un doc conforme a ce schema, et l’attribut
                  <att>docLang</att> precise la langue naturelle dans laquelle la doc sera generee,
               si possible. Au sein de cet element <gi>schemaSpec</gi> on trouve les composants
               desires pour le schema, qjui sera un simple sojus-ensemble. Ces composants sont
               specifies a l’aide des elements <gi>moduleRef</gi>, qui precise le nom d’un module
               TEI qu’on souhaite integrer avec son attribut <att>key</att>. Dans ce cas, on
               souhaite integrer tous les objets definis par le module infrastriucturale qui
               s’appelle <ident>tei</ident> (c’est mormal pour un schema TEI), mais on souhaite
               selectionbner qu’un petit nombre d’elements des deux autres modules referencies ici,
               a savoir, dands le module <ident>header</ident> pon ne selectionne que ;les elements
               teiHerader, fileDesc, titleStmt, publicationStmt, et sourceDesc; dansd le module
                  <ident>textstructure</ident> on a chjoisi que .les elements <gi>TEI</gi>,
                  <gi>text</gi>, <gi>body</gi> et <gi>div</gi>. Cette methode precise le module
               d’ou un delement est derive, mais kil n’est pas toujours necessaire: on peut
               egalement specifier que le nom de l’element souhaite en jutilisant l’element
                  <gi>elementRef</gi>, ce qui est le cas ici pour ;es elements <gi>ab</gi>.
                  <gi>pb</gi>, <gi>unclear</gi>, <gi>hi</gi> et <gi>name</gi>. </p>
            <!--<p>Voici une spécification typique online <ref
                  target="http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/ref-particDesc.html">
                  http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/ref-particDesc.html </ref></p>
            -->
            <p>Il y a une version nouvelle de TEI P5 au moins 2 fois par an; le plus souvent
               contenant des fautes corrigées, de nouveaux exemples, etc. </p>
            <p>La plus recente contient deux modifications importantes des possibilités fournies par
               le langage ODD de personnalisation. On peut désormais utiliser de nouveaux éléments
               TEI pour la définition des modèles de contenu en TEI ; pour la documentation des
               modéles de traitement envisages. Le dossier d’exemplaires contient maintenant
                  <ident>TEI simplePrint</ident> un nouveau schéma réduit <soCalled>adapté aux
                  besoins de 90% des utilisateurs TEI</soCalled>, qui est censé remplacer le
               vénérable <ident>TEI Lite</ident>
            </p>
         </div>
         <div>
            <head>Pourquoi continuer de s’intéresser à la TEI ?</head>
            <p>Il y a peut être (au moins) deux raisons pour lesquelles les standards échouent le
               plus souvent. Ou bien ils sont basés sur une théorie pas encore mûre; ou bien la
               communauté envisagée est trop diverse ou trop fragmentée pour en profiter. Le secret
               de la réussite de la TEI et de sa longévité serait-il dans ses capacités d’évolution,
               qui l’aurait permise à echapper à ces deux defis ? </p>
            <p>Une personnalisation TEI peut faire presque tout pour modifier les propositions
               standardisees. Il permet non seulement une sélection explicite des éléments et des
               attributs considérés comme utiles, mais aussi la limitation des valeurs possibles
               d’un attribut plus ou moins strictement; la proposition des règles Schematron pour
               controller le contenu d’un élément (p.e. co-dependency) plus strictement que la TEI
               ne permet. Il permet l’ajout de nouveaux éléments (ou classes d’élément), labellisés
               dans votre propre espace de noms, mais appartenant aux classes sémantiques
               prédéfinies par la TEI. Cet architecture permet donc d’évoluer et de tester sa
               théorie, en restant toujours TEI-conforme. </p>
            <p>L’architecture TEI est également construit sur des principes ouvertes, evidentes par
               exemple dans ces possibilités d’internationalisation très extensives. Editées en
               anglais, les parties essentielles des Guidelines ont été mises à disposition en
               plusieurs autres langues (y compris l’allemand, l’espagnol, le francais, le chinois,
               le japonais...) depuis longtemps, et leur système de gestion est conçu pour faciliter
               la traduction en d’autres. à part cette position ouverte envers les langues humaines,
               le système TEI est egalement acceuillant aux autres langues informatiques. Comme tout
               autre système XML, il héberge volontairement d’autres espaces de noms, et facilite
               l’inclusion des autres schémas existants. Par exemple, un document TEI XML peut
               integrer des fragments SVG pour les graphiques, des fragments MathML pour les maths,
               des fragments ML pour la musique annotee etc. La définition d’un élément TEI peut
               inclure (s’il y en a) un mapping avec d’autres ontologies, formalisé par un élément
                  <gi>equiv</gi> (équivalent). Donc le transfer automatique du semantique d’un
               encodage TEI vers une autre représentation (utilisant un autre ontologie) est
               envisageable. </p>
            <!-- <div xml:lang="fr">
            <head>Un standard existe pour qu’on s’y conforme, non ?</head>
            <figure>
               <graphic url="../Graphics/1991-TEI-commandments.png" height="80%"/>
            </figure>
         </div> -->
            <p>Tous ces possibilités de modification et cette flexibilité pourraient bien mettre en
               cause le statut normatif de la TEI. En fin de compte, qu’est-ce que cela veut dire :
               « être conforme » à la TEI ? Pendant sa longue periode d’evolution, la TEI à vu
               evoluer une pratique de balisage consensuelle profitant d’un lexique commun, et base
               sur un respect de l’autonomie de ces utilisdateurs. On peut dire que la
               standardisation facon TEI ne signifie pas « fais comme moi » ; elle veut dire
               « explique-moi ce que tu fais. »</p>
            <!-- </div>
         <div xml:lang="fr">
            <head>L’évolution darwinienne, ça marche…</head>
            <list>
               <item>faites vos modifications dans votre espace de nom</item>
               <item>documentez-les dans un ODD</item>
               <item>faites discuter vos propositions sur la liste TEI-L, ou dans un SIG !</item>
               <item>proposez les modifications efficaces au Conseil Scientifique de la TEI, en
                  faisant une "feature request" sur sourceforge</item>
               <item>Il y a une version nouvelle de TEI P5 deux fois par an…</item>
            </list>
            <p rend="box">... et n’oubliez pas de vous abonner au Consortium !</p>-->
         </div>
      </body>


      <back>
         <div type="bibliography">

            <listBibl>
               <bibl xml:id="bloggs13"/>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
