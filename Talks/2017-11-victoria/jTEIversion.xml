<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="../../../TEI/P5/Exemplars/tei_jtei.rnc" type="application/relax-ng-compact-syntax"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title type="main">What is TEI conformance, and why should you care?</title>
            <author>
               <name><forename>Lou</forename>
                  <surname>Burnard</surname></name>
               <affiliation>Independent Consultant</affiliation>
               <email>lou.burnard@retired.ox.ac.uk</email>
            </author>
         </titleStmt>
         <publicationStmt>
            <p>Revised for publication in TEI Journal, following presentation at <title>TEI MM
                  2017</title> (University of Victoria, Nov 11 to 13, 2017)</p>
         </publicationStmt>
         <sourceDesc>
            <p>Lightly revised version of the presentation given at <title>Digital Classics III:
                  Re-thinking Text Analysis</title> (Heidelberg, May 11 to 13, 2017)</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <langUsage>
            <language ident="en">en</language>
         </langUsage>
         <textClass>
            <keywords xml:lang="en">
               <term>one</term>
               <term>two</term>
               <term>three</term>
            </keywords>
         </textClass>
      </profileDesc>
      <revisionDesc>
         <change when="2018-05-05">Stopped pumping up for publication</change>
         <change when="2017-10-29">Cutting down for presentation</change>
         <change when="2017-10-22">Revising for Victoria</change>
         <change when="2017-05-10">Pretty much complete</change>
      </revisionDesc>
   </teiHeader>
   <text>
      <front>
         <div type="abstract" xml:id="abstract">
            <p>The recommendations of the Text Encoding Initiative (TEI) seem to have become a
               defining feature of the methodological framework of the Digital Humanities, despite
               recurrent concerns that the system they define is at the same time both too rigorous
               for the manifold variability of humanistic text, and not precise enough to guarantee
               interoperability of resources defined using it. In this paper I question the utility
               of standardization in a scholarly context, proposing however that documentation of
               formal encoding practice is an essential part of scholarship. After discussion of the
               range of information such documentation entails, I explore the notion of conformance
               proposed by the TEI Guidelines, suggesting that this must operate at both a technical
               syntactic level, and a less easily verifiable semantic level. One of the more
               noticeable features of the Guidelines is their desire to have (as the French say)
               both the butter and the money for the butter; I will suggest that this polymorphous
               multiplicity is an essential component of the system, and has been a key factor in
               determining the TEI&#8217;s continued relevance. </p>
         </div>
      </front>
      <body>
         <div n="1">
            <head>What are encoding standards actually for?</head>
            <p>As the old joke says, the good thing about standards is that there are so many to
               choose from. You can choose to follow a dictatorial, centrally-imposed,
               we-know-what&#8217;s-best-for-you encoding method, like Microsoft Word. You can
               choose to follow a hand-crafted, idiosyncratic, we-know-what-we&#8217;re-doing kind
               of encoding standard made up and maintained by the leading lights of a particular
               research community, like Epidoc. Or you can just go ahead and do your own encoding
               thing, which I like to characterize as the nobody-understands-my-problems kind of
               standard. In academia, there&#8217;s a good argument for each of these flavours;
               indeed it has been suggested that different components of the TEI itself accord
               differing priority to each of these. The TEI Header, for example, can be used in a
               highly prescriptive WKWBFY manner, while the user of the TEI proposals for
               feature-structure analysis must be assumed to Know What is Best For Them. And every
               customizer of the TEI faced with a large amount of ambiguously encoded legacy data,
               or an intransigent user community, must be grateful that in some aspects it permits a
               NUMPty approach (the survival of both vanilla and <soCalled>flavoured</soCalled>
               <gi>div</gi> elements being a notable example). For each approach to standardization
               has its merits. WKWBFY saves a lot of time and effort reinventing the wheel and
               ensures that your work will be processable and usable in at least one application
               environment: the downside is that you may not want or like the world view that the
               system embodies, but you can&#8217;t change it. WKWWD probably means you are dealing
               with congenial and familiar views and are guaranteed respect within your community,
               but no-one outside that community will know what to do with your stuff, and you may
               be a bit limited if you want to push the boundaries of knowledge or praxis within it.
               And, of course, NUMP guarantees you the luxury of making all your own decisions,
               getting everything just the way you want, but consequently not only risking isolation
               from your peers but also having to spend lots of time and effort doing tecchie things
               that have nothing to do with your real scholarly preoccupations. </p>
            <p>When the choice is so hard to make, it may be a good idea to reconsider the
               motivation for making it in the first place. What do we actually gain from adopting
               an explicit encoding standard? What scholarly advantage is there in formally defining
               the formats of our digital re-presentations of cultural artefacts? We may do it
               simply in order to be seen to be ticking the right boxes in a funding agency&#8217;s
               list of criteria; we may do it because our elders and betters have told us we should;
               we may do it because we know no better. Such considerations, though intellectually
               less persuasive, may play a more significant part in enlarging the community of
               standards-conforming users than motivations derived from a consideration of scholarly
               utility. But it still seems useful to ask the question: how does the use of explicit
               standards in the markup of digital resources contribute to the success or failure of
               a scholarly enterprise? </p>
            <p>Firstly, I suggest, we should not forget that the application of markup is an
               inherently scholarly action which, since the goal is to express a scholarly
               interpretation, is an inherently hermeneutic activity. The choice of markup
               vocabulary is not an arbitrary one, but one with consequences. It may make it harder
               to express a truth about a document or a document&#8217;s intentions; it may make it
               easier to say something which is convenient, but false. To dismiss as <q>mere
                  semantics</q> concerns about the proper application of markup is thus to embark
               upon a very dangerous path, if of course you share my belief that every scholarly
               encoding should truthfully represent without convenient distortion a scholarly
               reading. </p>
            <p>Secondly, if the function of markup is to express an interpretation, then the markup
               language itself should as far as possible eschew ambiguity. Markup defines and
               determines the interface between human interpretation and algorithmic processing. It
               determines what an algorithm has at its disposal to work on yet it is frequently (if
               not necessarily) the product of a non-algorithmic human interpretation. Life is
               complicated enough without introducing additional fuzziness and inconsistency into
               the processing stack. We would like to live in a world where two equally well
               informed observers looking at the same encoding will reach similar or identical
               conclusions as to the interpretations which occasioned that encoding. We would also
               like to be confident that two equally well-informed encoders, considering the same
               textual phenomenon, and having the same interpretation of it, will encode that
               interpretation in the same way. (This is not, of course, the same as wishing that all
               well-informed encoders should reach the same interpretative conclusions about a given
               text. Quite the contrary.) Consequently we desire the claims embodied by a marked up
               document to be formally verifiable in some way, even though there may be limits to
               the extent to which that can be achieved. Verifiability implies the existence of some
               formal definition for the markup language, against which instances of it can be
               checked, preferably automatically. Talking solely of XML documents, we would prefer
               them to be not just <q>well-formed</q> but also <q>valid</q>. If two documents are
               both valid with respect to the same XML schema, we can at least have some confidence
               that they express comparable interpretations: we have reason to believe they will
               talk about the same things in the same terms. </p>
            <p>The full validation of scholarly markup however requires more than simple XML
               validity since a marked up document has intention beyond what an XML schema can
               express. A typical XML schema will allow me to say that the XML element <gi>p</gi>
               must appear within the XML element <gi>div</gi> and not the reverse, but it will not
               easily let me say that the content of my <gi>p</gi> elements corresponds with a
               paragraph of text rather than, say, a page or a potato. For that information, the
               user must consult project-specific documentation, which should spell out how exactly
               the intentions behind this set of encoded documents are realised by its surface
               components (the start and end tags, the attribute value pairs etc.) In the absence of
               that documentation, all there is to fall back on are expectations based on knowledge
               of habitual practice. </p>
            <p>Thirdly, therefore, we need to complement the automatic validation of our markup with
               semantic checks which, in our present state of knowledge, are not automatable, and
               require human judgement. It is no coincidence that SGML, the ancestor of XML, was
               produced by a lawyer: the rules embodied by an SGML DTD, like those in the statute
               book, must be interpreted to be used. In the field of the law, the statute book is
               completed by precedents; in the case of an XML schema used by a broad community such
               as the TEI, the rules incarnated in the TEI Guidelines are completed by the practice
               of those using them, whether we are thinking about the Guidelines as a whole, or the
               customizations of them used by individual projects. As discussed further below, a TEI
               customization expresses how a given project has chosen to interpret the general
               principles enumerated by the Guidelines, as well as formally specifying which
               particular components of the Guidelines it uses. It also provides ample opportunity,
               through documentation and exemplification, to guide a human judgement as to the way
               in which the markup should be understood, and therefore the extent to which different
               datasets using it can be integrated or rendered interoperable. </p>
         </div>
         <div n="2">
            <head>How are encoding standards to be documented?</head>
            <p>As a minimum, the documentation of an encoding language has to be able to specify the
               same things as a schema does: the names of the elements and attributes used, their
               possible contents, how elements may be validly combined, what kinds of values are
               permitted for their attributes, and so on. Currently available schema languages do
               not provide an entirely identical range of facilities of this kind, nor do they
               conceptualise the validation of documents in exactly the same way, but they are in
               sufficiently broad agreement for it to be possible to model the information they
               require using a simple XML language, which now forms a part of the TEI tagset
               documentation system, referred to here and elsewhere as ODD: an abbreviation for
                  <soCalled>One Document Does it all</soCalled>; see further <ref type="bibl"
                  target="#rahtzBurnard2013">Rahtz and Burnard 2013</ref>; <ref type="bibl"
                  target="#rahtzBurnard2004">Burnard and Rahtz 2004</ref>). </p>
            <p>Of course, if schema models were all that ODD supported, it would be hard to persuade
               anyone to use it. The full ODD language provides for much more than the basic
               information required to create a schema model. For example, a full TEI element
               specification may contain: <list rend="ordered">
                  <item>a <hi>canonical name</hi> for the element, together with explanatory glosses
                     for the name in various languages; alternative names in other languages;
                     equivalents in other markup schemes; </item>
                  <item>at least one summary <hi>description</hi> of the meanings and usages
                     intended for the element; </item>
                  <item>information about the element and attribute <hi>classes</hi> to which the
                     element belongs; </item>
                  <item>information about the element&#8217;s <hi>content model</hi>; </item>
                  <item>formal specifications for any <hi>constraints</hi> additional to those
                     expressed by the content model;</item>
                  <item>a list of specifications for any <hi>attributes</hi> defined as local to the
                     element rather than being inherited from an attribute class; </item>
                  <item>formal specifications for the recommended <hi>processing model</hi>
                     applicable to the element;</item>
                  <item>annotated <hi>examples</hi> of usage; </item>
                  <item>additional <hi>commentary</hi> or usage notes; </item>
                  <item>a list of <hi>references</hi> to the chapter of the Guidelines text where
                     the element is discussed more fully.</item>
               </list></p>
            <p>Without going into too much detail, it should be evident that a TEI specification
               therefore potentially provides data which can be used to facilitate many different
               markup-related processes in a more productive way, making it possible for example to
               provide context sensitive help in different languages, to generate formal schema
               specifications in different schema languages automatically, to provide user-oriented
               tutorial manuals, to develop more intelligent data entry and validation systems, or
               simply to act as a point of entry into the canonical TEI documentation. </p>
            <p>A criticism sometimes made of XML schemas in general and the TEI in particular is
               that they encourage an excessively reductionist perspective. <ref type="bibl"
                  target="#robinson2009">Robinson 2009</ref> is not alone in asserting that <q>the
                  concept of what <soCalled>text</soCalled> is, upon which (for instance) the Text
                  Encoding Initiative principles are based ... is positivist, overconfident,
                  simplistic and neglects the materiality of actual text instances</q>. TEI markup
               is believed to convey what a text <soCalled>really is</soCalled> (<ref type="bibl"
                  target="#deRose1990">De Rose et al, 1990</ref>), discarding as secondary
               distractions all the rugosities of real text such as choice of typeface or
               accidentals of printing. But when choosing and defining a mark up scheme, different
               projects will legitimately disagree as to which aspects are distractions, and which
               are essential. It may after all be that typographic accidentals are precisely the
               focus of scholarly attention, as for example when transcribing early print editions,
               to say nothing of manuscripts. Comparatively recent developments of the TEI have
               attempted to address this concern by enriching the available element set, enabling it
               to represent (for example) digital facsimiles, detailed manuscript transcriptions and
               descriptions, or genetic editions. The cost of this enrichment is evidently that the
               TEI model becomes more complex, so much so that it is doubtful whether it makes any
               sense to talk of a single TEI model, even though some parts of it seem to be
               universal. The benefit of this enrichment is, equally evidently, the ability it
               confers for a far broader community of users to define models precisely fitted to
               their particular textual perspective, even if those models differ widely in the
               importance they attribute to particular textual features. Those for whom the digital
               edition is a carefully constructed textual reading or set of readings can use the TEI
               to encode them, just as effectively as those for whom it is a collection of
               scrupulously represented and analysed page images. Both communities benefit moreover
               from the availability of a set of common concepts which do not need to be redefined
               or disputed. </p>
            <p> It is often claimed that by focussing on the platonic essence of some collection of
               data, a data model will facilitate equally effectively many possible applications for
               that data. But in the real world, a compromise must be found: in the absence of any
               engagement at all with the way the data being modelled is intended to be used, a
               model risks being of theoretical interest only. The <q>processing model</q> recently
               added to the TEI ODD language is an example of a facility provided by that system
               which may be said to help redress that balance by formally specifying the kind of
               processing that the encoder considers appropriate for a given element. The processing
               model for an element might, for example, just indicate the class of formatting
               appropriate for it; or it might indicate that this is one of the so-called
                  <q>janus</q> elements which present alternative encodings for the same phenomenon.
               In either case, the intention is to simplify the task of the application developer
               faced with a specific customization of the TEI, by enlarging the scope of available
               information beyond what is provided by an XML schema. Such documentation will also
               clearly benefit the person attempting to curate the data for the long term. One of
               the many partially-fulfilled promises of the SGML revolution was that by abstracting
               data description away from data processing, data longevity would be assured. The
               experience of those who have tried to re-use existing TEI resources suggests that
               this is true, if only <q>up to a point, Lord Copper</q>. One of the take-home
               messages from ambitious re-use projects such as Project Monk (<ref type="bibl"
                  target="#monk2009">Unsworth and Mueller, 2009</ref>) appears to be that ease of
               reuse is directly proportionate to the availability of precise documentation
               concerning the way a projects used or intended to use the TEI. </p>
            <p>We should conclude therefore that the way a data model is recorded and documented is
               likely to be of critical importance in determining its long term usefulness, as well
               as its immediate effectiveness. Today&#8217;s digital projects are complex and
               sometimes over-engineered constructs; maintaining a clear and accurate record of the
               data models on which they are based is correspondingly necessary. </p>
         </div>
         <div n="3">
            <head>The importance of customization</head>
            <p>As suggested above, the richness of today&#8217;s TEI makes it almost essential to
               customize it for any given application, by selecting from the available
               specifications. To facilitate that task, the specifications are grouped together both
               physically into named <q>modules</q>, and logically into named <q>classes</q>. Each
               module contains a number of related declarations, and modules can be combined as
               necessary, though in practice there are one or two modules which provide components
               needed by almost any encoding. In earlier versions of the Guidelines, a distinction
               was made between modules which provided components specific to a particular kind of
               document (the <q>base</q> tagsets) and those which provided components specific to a
               particular kind of analysis (the <q>topping</q> tagsets). The idea was that a schema
               would typically use a single base and multiple toppings, though it was also possible
               to combine multiple bases. This, the so-called pizza model, did not survive into TEI
               P5, where all modules are considered equal.
               <!--<note place="end">The <ident>tei</ident> module supplies declarations for
                  generally useful macros, datatypes, model and attribute classes; the
                     <ident>core</ident> module which supplies declarations for elements needed in
                     <q>all kinds of document</q>; the <ident>header</ident> module which supplies
                  metadata elements; and the <ident>textstructure</ident> module which supports the
                  basic organization of book like objects, for example. </note>-->.
               A class by contrast is an abstract object to which elements point in order to express
               their semantic or structural status. Two kinds of class are distinguished: model
               classes and attribute classes. The members of a model class share structural
               properties, in particular the locations in a content model where they are permitted;
               the members of an attribute class share identically defined attributes. A
               customization may define new classes, delete existing ones, or modify the membership
               of a class, though these are facilities that can have unexpected consequences, as we
               discuss below. In SGML-based versions of the Guidelines, classes were represented by
               parameter entities which could be modified by a document instance, thus providing
               extension points for the encoding scheme. In RELAXNG, classes are represented as
               patterns, with similar capabilities. </p>
            <p>A customization which just specifies a selection of modules will over-generate, not
               only in the sense that the resulting schema will contain specifications for
               components that will never be used, but also because the TEI often provides multiple
               ways of encoding the same phenomenon. For example, the TEI provides three elements
               for the representation of a traditional bibliographic record : <gi>bibl</gi>,
                  <gi>biblStruct</gi> and <gi>biblFull</gi> ; these elements differ in their
               internal syntax, but are semantically identical. Similarly, the core module provides
               a handful of elements (<gi>foreign</gi>, <gi>emph</gi>, <gi>soCalled</gi> etc.) for
               signalling the function associated with visual distinctions such as italicisation or
               quote marks, while also providing a way of simply signalling the fact of visual
               salience or highlighting itself by means of the element <gi>hi</gi>. Any or all of
               these may use any or all of three attributes, <att>rend</att>, <att>rendition</att> ,
               or <att>style</att>, each of which offers a quite different way of representing how
               exactly the source is visually or otherwise salient. Similarly, the TEI
                  <ident>att.datable</ident> attribute class provides two distinct sets of
               attributes for normalising dates and times, one conforming to W3C, the other
               conforming to ISO. Plus, for good measure, a third sub-class called
                  <ident>att.datable.custom</ident> which allows the encoder to use their own
               conventions. The TEI is scrupulously agnostic even about how a TEI document itself is
               to be constructed: the classic TEI document comprises a TEI Header and a transcribed
               text; the transcribed text may however be combined with a set of digitized images, or
               replaced by one; it is also possible to replace (or complement) the traditional text
               transcription (which aims to capture the logical organization of the source document)
               with a <q>source-oriented</q> transcription which captures just its physical
               organization and eschews other interpretive gestures. And there are plans to add a
               further parallel component to contain annotations made upon the text in a
                  <q>standoff</q> manner (See further <ref type="bibl" target="#standoff">Pose et
                  al, 2014</ref>).</p>
            <p> This multiplicity of choice can be bewildering and may seem absurd. Yet every
               element and attribute in the TEI Guidelines is there because some member of the
               scholarly community has plausibly argued that it is essential to their needs; where
               there is a choice, therefore, it is not because the TEI is indecisive, it is because
               all of the available options have been considered necessary by someone, even if
               no-one (except perhaps those blessed with the task of maintaining the TEI) ever
               considers all of them together. </p>
            <p>A project wishing to use the TEI, and to document that usage accurately, is therefore
               obliged to proceed with caution. Just selecting a few promising modules is not
               necessarily the best approach: a selection must also be made from the components
               provided by those modules, since selecting everything available is a recipe for
               confusion. Those unwilling or inadequately resourced to make this effort can use one
               or other of the generic TEI customizations made available by the TEI itself (<ref
                  target="http://www.tei-c.org/release/doc/tei-p5-exemplars/html/tei_simplePrint.doc.html"
                  >TEI simplePrint</ref>, for example), or by specific research communities (<ref
                  target="http://www.stoa.org/epidoc/gl/latest/">Epidoc</ref>is an excellent
               example; see also <ref type="bibl" target="#bodard2010">Bodard 2010</ref>). But
               adopting an off-the-peg encoding system is always going to be less satisfactory than
               customizing one that fits more precisely the actual needs of a project and the actual
               data modelled within it. (It is assumed that a data analysis of some kind is a
               necessary precursor to any digital project). </p>
            <p>Furthermore, it is painfully true that nothing in digital form is ever really
               finished. Almost inevitably, as a project evolves, things that should have been done
               differently will emerge. In the light of experience, it becomes much easier to change
               the list of available elements to match more closely actual encoding practices.
               Beginners often think it is better to allow almost any kind of content in their
               schema: an extreme case of this misapprehension leads people to use
                  <ident>tei_all</ident> for everything. It may well be that a project starts off a
               little uncertain about the kind of data it will have to be able to handle. But as an
               encoding project matures, these uncertainties disappear and project-specific praxis
               becomes better understood. The cost benefit ratio of allowing for the unforeseen
               begins to change. Every element in your schema is another element to explain to the
               encoders, another element to document and find examples for, and another element
               whose usage needs to be checked for consistency. It is also another element that the
               poor over-worked software developer has to be prepared to handle. </p>
            <p>Similar considerations apply to attributes, and in particular to their range of
               values. At the outset of a project, it may have been impossible to predict what
               values would be appropriate for some attribute, and hence the initial model will have
               allowed anything. The price of this laissez-faire policy is that in the absence of
               guidance, encoders will supply widely varying values, for example <val>centre</val>,
                  <val>centered</val>, or <val>middle</val>, all meaning (probably) the same thing.
               Once it becomes clear which values are appropriate, it is better to provide such
               guidance, by adding a <gi>valList</gi> to the ODD, even if this entails some
               additional work cleaning up existing data. </p>
            <p>Customization is very often a simple matter of selection, or formally speaking a
               subsetting operation. For example, a customization such as this, which specifies that
               attribute values be taken from a closed list of possible values rather than being any
               token of the appropriate datatype, is a subsetting operation: the set of documents it
               considers valid is a pure subset of the set of documents considered valid by a schema
               lacking that particular customization. Similar considerations apply to some, though
               not all, changes of datatype. Many TEI attributes have very open ended datatypes,
               typically <code>teidata.word</code>, which will accept almost any string of
               characters not containing white space. But there are also more precise datatypes,
               such as <code>teidata.pointer</code>, which requires a string that is a valid URI, or
                  <code>teidata.numeric</code>, which requires a numeric string. A customization
               which restricts the range of permitted attribute values by changing its datatype from
                  <code>teidata.word</code> to <code>teidata.pointer</code> is also a subset, since
               the documents it will accept form a subset of those which the unmodified datatype
               would accept. This would not of course be true of the reverse modification, for
               example from <code>teidata.pointer</code> to <code>teidata.word</code>. </p>
            <p>Customization can also however involve extending the range of what is provided by the
               TEI. A modification may provide an alternative identifier for an existing element or
               attribute, for example to translate its canonical English name into another language.
               A modification may change the class memberships of an existing element, so that it
               acquires attributes not previously available, or so that it may appear in contexts
               where it previously could not. A modification may change the content model of an
               element to permit different child elements, or so that existing children elements may
               appear in a different order or with different cardinalities. And of course a
               modification can readily define entirely new elements, macros, classes or attributes,
               and reference them from existing TEI components. Such flexibility clearly has major
               implications for conformance, as discussed in the next section below. </p>
            <p>The following diagram represents the variety of possible customizations. </p>
            <figure>
               <graphic url="../Graphics/oddFlavours.png" width="720px" height="368px"/>
               <!-- image is 1034x726 px-->
               <head type="legend">Varieties of Customization</head>
            </figure>
            <p>Each of the shapes here may be understood to represent three different things: <list>
                  <item>an ODD : that is, a collection of TEI specifications constituting a
                     customization</item>
                  <item>a formal schema generated from that ODD, and its natural language
                     documentation</item>
                  <item>the set of documents considered valid by that schema</item>
               </list></p>
            <p>The TEI provides a monolithic unmodified schema called <ident>tei_all</ident> which
               contains all of the elements, classes, macros, etc. defined by the TEI. As noted
               above, for all practical purposes a user of the TEI must make a selection from this
               cornucopia, which I will call a <q>TEI customization</q>, represented as a named set
               of modifications and encoded by a TEI ODD. Of course there are many, many possible
               TEI customizations, each involving different choices of elements or attributes or
               classes, but there are at least two different kinds of customization: a <term>TEI
                  subset</term> and a <term>TEI extension</term>. (In proposing this terminology, I
               am reinventing a distinction proposed by David Birnbaum in a 2000 article (<ref
                  type="bibl" target="#birnb2000">Birnbaum 2000, esp section 5.1</ref>) which talks
               of modifications as <soCalled>supersets</soCalled> or <soCalled>subsets</soCalled>.) </p>
            <p> When a set of modifications results in a schema which regards as valid a subset of
               the documents considered valid by <ident>tei_all</ident>, I will call this a <q>TEI
                  subset</q>; the Guidelines also identify this as a <term>clean
               modification</term>. Where this is not the case, I propose the term <q>TEI
                  extension</q>, which the Guidelines identify as an <term>unclean
                  modification</term>. A customization which adds new elements or attributes, or one
               in which elements are systematically renamed, cannot result in a subset, because the
               set of documents the schema generated from it will consider valid is not a proper
               subset of the documents regarded as valid by the <ident>tei_all</ident> schema. </p>
            <p>A change to the content model of an existing TEI element may or may not result in a
               TEI subset. For example, if <ident>tei_all</ident> does not specify an order for the
               child elements of some content model, a customization which does constrain that order
               will be a TEI subset: every document it considers to be valid is also valid according
               to <ident>tei_all</ident>. The reverse is not the case, however: if
                  <ident>tei_all</ident> does specify an order, a customization which relaxes that
               constraint will result in a schema that considers valid some documents considered
               invalid by <ident>tei_all</ident>; it is therefore a <q>TEI extension</q>. Removing
               an element from an attribute class will result in that element losing the attributes
               supplied by the class which (on the assumption that none of them is mandatory) will
               result in a subset. Removing an element from a model class will similarly (in most
               cases) mean that the element ceases to be available in the content of other elements,
               and hence also usually results in a subset. Adding an element to a model class in
               which it did not previously figure, however, will usually result in a TEI extension.
               (Further examples of typical kinds of modification are given in the Guidelines,
               chapter 23) </p>
            <p>
               <!-- New elements or attributes should be explicitly attached to a
               different, non TEI, namespace, and new elements  -->
               TEI extensions which include TEI elements or attributes whose properties or semantics
               have been significantly changed are expected to place those elements or attributes in
               a different namespace. Such elements should, as far as possible, be included in
               existing content models by making them members of existing TEI classes, rather than
               by explicitly modifying the content model of an existing element. On the face of it,
               this means that any element referencing a new element will have a different content
               model, and should therefore be in a different namespace too. And the same ought to
               apply to <emph>its</emph> parent elements, and so on up to the TEI element itself.
               <!--<note place="foot">We might call this the <soCalled>turtles all the way
                     up</soCalled> scenario, in hommage to Douglas Hoftstadter.</note>-->
               Fortunately, there is a nuance of detail which means we do not need to invoke this
                  <soCalled>turtles all the way up</soCalled> scenario, provided content models are
               defined not in terms of specific elements but with reference to model classes. A
               class reference will be dereferenced to a specific set of elements only when an ODD
               is converted to a schema; this is necessary because the set in question will depend
               on which elements are available in the customization. Any element, including one from
               a non-TEI namespace, may claim membership in a TEI model class and hence legitimately
               appear in the content of a TEI element referencing that class. </p>
            <p>I argue in the next section that TEI conformance is not simply a matter of validity
               against a schema. Nevertheless it should not be forgotten that there are a few hard
               wired-rules built into the TEI model, which the customizer ignores at their (or
               rather, their potential audience&#8217;s) peril. </p>
            <p> For example, a TEI Header really <emph>must</emph> have a title statement containing
               at least one title, along with a publication statement and source description, even
               if the latter two have no significant content. A TEI <gi>text</gi> element really
                  <emph>must</emph> contain a <gi>body</gi> element. TEI <gi>div</gi> elements
               really <emph>must</emph> nest correctly within one other. The structural classes in
               terms of which content models are defined really <emph>must</emph> be respected:
               hence one <gi>p</gi> cannot contain another, and a phrase level element such as
                  <gi>hi</gi> cannot contain a block like element such as <gi>p</gi>. </p>
            <p>Some of these restrictions are the subject of regular debate on TEI-L and elsewhere,
               but for the most part they are in my view integral parts of the TEI model. It is a
               part of the definition of a TEI <gi>div</gi> that once you have encountered another
               nested <gi>div</gi> within it, only <gi>div</gi> elements at the same hierarchic
               level are permitted until it finishes; a non-tessellating division element might well
               be useful, but if one is defined it most be distinguished clearly from the existing
               TEI <gi>div</gi>, for example by placing it in a different namespace. </p>
            <p>Breaking these rules may have unexpected consequences. For example, a customization
               which removes the element <gi>title</gi> completely will result in a schema in which
               no TEI <gi>teiHeader</gi> element can ever be considered valid, since the mandatory
               components of the TEI Header are an essential part of it; a TEI Header which lacks
               them is a different kind of object, and should not present itself as being something
               which it is not. </p>
         </div>
         <div n="3">
            <head>What is TEI conformance? </head>
            <!-- A narrator should not supply interpretations of his work; otherwise he would not
               have written a novel, which is a machine for generating interpretations. 
              -->
            <!-- <p> The notion of TEI conformance is introduced in Chapter 23 of the TEI Guidelines but
               the chapter falls short of providing a consistent formal definition, either of what
               conformance means, or how it should be assessed. One motivation for this paper is to
               start a discussion on how best to rectify that. </p>-->
            <p>Umberto Eco remarks (<ref type="bibl" target="#eco">Eco 1984</ref>) that a novel is a
               machine for generating interpretations. We might say that the TEI is a machine for
               generating schemas to formally represent such interpretations. However, just as not
               all interpretations of a novel have equivalent expository force, so not all TEI
               customizations are of equal effectiveness or appropriateness; indeed, what is
               effective or appropriate for one purpose may not be for another. A customization
               documents and defines a view of what it is meaningful and appropriate for a given
               project to assert about a set of documents. It does this by reference to the very
               large pre-existing range of concepts distinguished by the TEI, selecting from that
               range the particular distinctions it wishes to make, possibly modifying some of them,
               possibly adding to them. I suggest that our assessment of the
                  <soCalled>appropriateness</soCalled> of a given customization — its conformance if
               you will — should take into account the way in which that customization is expressed
               and the claims it consequently makes about its understanding of concepts originally
               enumerated by the TEI. </p>
            <p>There are also good pragmatic grounds for wanting to know how a given customization
               has modified the TEI definitions. Such knowledge enables us to make comparisons
               amongst different customizations, to assess their relative closeness to the original
               Guidelines, and to determine what might be necessary to make documents using those
               different customizations interchangeable, if not interoperable. As Martin Holmes
                  (<ref type="bibl" target="#holmes2016">Holmes 2016</ref>) amongst others has
               pointed out, the pursuit of unmediated interoperability amongst TEI documents is
               largely chimerical, whereas the information provided by the documentation of a TEI
               customization will often be all that is needed to make documents using that
               customization interchangeable.</p>
            <p>Beyond pragmatic considerations, however, a definition of TEI conformance and some
               rules of thumb for assessing it, are surely needed if the TEI Guidelines are to be
               more than increasingly stale dogma. I suggest that the most useful definition of TEI
               conformance is one that takes into account the original design goals and
               recommendations of the Initiative (<ref type="bibl" target="#edp01">Sperberg-McQueen
                  and Burnard 1988</ref>), which are explicitly formulated to benefit a very broad
               range of applications and disciplines, rather than to impose a single
               one-size-fits-all standard. It follows that an assessment of TEI conformance involves
               more than simply checking whether the customization is a subset of TEI All or an
               extension of it in which all non-TEI components have been clearly identified as such.
               It must also take into account the extent to which the encoding respects the TEI
               semantic model. Where the encoding uses TEI-defined elements, these should represent
               the concepts associated with those elements by the TEI. Where an encoding enlarges
               that set of concepts, it should not misuse TEI elements to do so, but make explicit
               that it addresses concepts not addressed by the TEI, for example by placing elements
               in a non-TEI namespace. </p>
            <p>In assessing conformance, there is a natural tendency to attach particular importance
               to validity against a schema, since this is something which can be automatically
               tested, whereas checking the semantic validity of an encoding is not in principle
               automatable. Validation of a document which uses a TEI extension may additionally
               require the use of a namespace-aware validator such as <ident>onvdl</ident>, which
               routes different parts of an XML document for validation against possibly many
               different schemas, using the Namespace-based Validation Despatching Language, defined
               as part 4 of the ISO standard for Document Schema Definition Languages (<ref
                  type="bibl" target="#ISO19757_4">ISO/IEC 19757&#x2013;4</ref>). This is one reason
               why validity against <ident>tei_all</ident> has limited significance in assessing the
               conformance of a customization, other than to determine whether it is a TEI subset or
               a TEI extension. The TEI was designed to facilitate customization both by subsetting
               and by extension; either process therefore has the potential to result in something
               which should be considered <q>conformant</q>.</p>
            <p>Earlier versions of the P5 Guidelines introduced a notion of <soCalled>TEI
                  conformable</soCalled> or <soCalled>algorithmic conformance</soCalled> to identify
               TEI extensions which might be placed at the <q>acceptable</q> end of a notional scale
               of conformance. <q>A document is said to be TEI Conformable if it is a well-formed
                  XML document which can be transformed algorithmically and automatically into a TEI
                  Conformant document as defined above without loss of information</q> (TEI P5 ver
               1.1.0, p 659). A customization which systematically provides alternative identifiers
               for all the TEI elements it uses by means of the <gi>altIdent</gi> element provided
               for this purpose is clearly more <soCalled>conformable</soCalled> than one which
               simply redefines a few elements with different names, but the same semantics and the
               same content models as the existing ones. A customization which defines a new element
               (say <gi>botanicalName</gi>) and adds it to an existing class
                  (<ident>model.nameLike</ident>, for example) will be more <q>conformable</q> if it
               also provides an explicit TEI mapping for it, using the <gi>equiv</gi> element in its
               specification to indicate that this element is equivalent to <tag>name
                  type="botanical"</tag>. However, despite its initial attractiveness, the notion of
                  <q>conformability</q> is impossible to define exhaustively and precisely, since
               anything can be algorithmically converted to something else, given sufficient
               ingenuity, and it no longer features in the Guidelines discussion of conformance. </p>
            <p>Nevertheless, if the only distinction we can make as regards conformance is between a
               TEI subset (which is probably ipso facto conformant, though not necessarily), and a
               TEI extension (which is probably ipso facto non-conformant, though not necessarily),
               the notion is not a very helpful one. Intuitively, it seems evident that some
               modifications are closer in spirit to the TEI conceptual model than others, even if
               they result in a schema which is not a TEI subset as previously defined. At the
                  <q>more acceptable</q> end of the scale we might place the case of systematic
               renaming already cited; another might be the addition of additional attributes to an
               existing element, where that does not result in a conflict of any kind. For example,
               not all elements are members of the class <ident>att.typed</ident>, and thus cannot
               be subcategorised. A customisation in which (say) the <gi>address</gi> element gains
               a <att>type</att> attribute so that the encoder can distinguish postal addresses from
               email addresses seems entirely innocuous. A processor which knows about the TEI
               element <gi>address</gi> will not go badly astray if it simply ignores the new
               attribute. If however the new attribute has a value such as <code>machine</code> or
                  <code>IP</code> we might begin to feel that the concept of <q>address</q> has
               shifted somewhat, and an uninformed TEI processor might well be at a loss to deal
               with it. Subcategorisation of this kind should not be a backdoor to redefining the
               meaning of an element completely. </p>
            <p>A more problematic case of non-conformance would be where a generic subcategorisation
               attribute such as <att>type</att> is used to make a distinction already made by an
               existing more precise attribute. For example, <gi>title</gi> has both
                  <att>level</att> and <att>type</att> attributes; using the latter to specify the
               former would be a nonconformant usage, even though, in this case, no extension is
               involved. It is analogous to inventing a new non-TEI element that duplicates the
               function of an existing TEI element. Because the TEI is hospitable to other XML
               vocabularies, an extension using elements from another scheme may easily introduce
               such duplications, for example, if Dublin Core elements are embedded directly in the
               TEI Header they would duplicate the function of many existing TEI elements, with
               consequent integrity problems, even though the DC elements might be clearly labelled
               as non-TEI, or even embedded within the TEI <gi>xenodata</gi> element. </p>
            <p>The ability to extend the range of encodings supported by the TEI simply and
               straightforwardly remains a fundamental requirement for a scheme which is intended to
               serve the needs of research. This requirement has several important benefits: <list>
                  <item>it enables the TEI to integrate with comparative ease other specialised XML
                     vocabularies, such as MathML, SVG, or most recently MML;</item>
                  <item>it facilitates and encourages the development of new TEI components by the
                     broader community;</item>
                  <item>it simplifies the task of interchange by reducing the possibility of
                     ambiguous or incoherent encoding. </item>
               </list></p>
            <p>This polytheoricity underlies the TEI&#8217;s apparent complexity, and is also a
               major motivation for the requirement that a modification should use namespaces in a
               coherent manner: in particular, that elements not defined by the TEI, or TEI elements
               whose definition has been modified to such an extent that they arguably no longer
               represent the same concept should not be defined within the TEI namespace. Of course,
               reasonable people may reasonably disagree about whether two concepts are semantically
               different, just as they may disagree about how to define either concept in the first
               place. That is part of what Darrell Raymond (<ref type="bibl" target="#raymond1996"
                  >Raymond et al 1996</ref>) memorably called the <q>hellfire of ontology</q> into
               which the descriptive markup project has plunged an entire generation.</p>
            <p> As a simple example of these ontological anxieties, consider the TEI <gi>stamp</gi>
               element. This is intended, if one is to judge from the examples in the Guidelines, to
               document marks impressed on a manuscript or incunable with the aid of a rubber stamp
               or similar object, typically to indicate ownership. But what of marks impressed on a
               letter to indicate the time and date it was posted (the
               <soCalled>postmark</soCalled>)? What, indeed, of the little paper sticker affixed to
               a postcard or envelope to indicate that postage has been paid, the postage stamp? Is
               either of these semantically close enough to the TEI&#8217;s existing <gi>stamp</gi>
               for us to use that element to document them? If a postage stamp is not a kind of TEI
                  <gi>stamp</gi>, maybe it is a kind of TEI <gi>seal</gi>? A TEI customization
               designed for a collection of transcribed postcards might choose to make use of either
               of these existing elements for the purpose; or it might choose to define its own new
               element. A TEI application searching blindly through an archive for information about
               seals, or stamps (according to the TEI definitions), will be misled by either of the
               first modifications; whereas the presence of a new element should not confuse it, as
               previously noted. This suggests, perhaps paradoxically, that the use of a non-TEI
               element results in a more conformant document than the repurposing of existing,
               semantically related, elements. </p>
            <p>As a further example, consider the Dublin Core <gi>dc:title</gi> element. This has
               the same semantics and serves the same function as the TEI <gi>title</gi> which is a
               mandatory component of the TEI <gi>titleStmt</gi> in the TEI Header. A modification
               which redefines the TEI <gi>titleStmt</gi> to require a <gi>dc:title</gi> instead of
               a <gi>title</gi> might plausibly be argued to respect the TEI conceptual model, even
               though it is clearly invalid with respect to a TEI schema. </p>
            <p>The ability to use explicitly-labelled non-TEI elements in a TEI modification may be
               seen as an important coping mechanism, enabling the TEI community to experiment with
               changes to the usual ways of doing things and to enlarge the scope of the scheme in a
               controlled and non-disruptive way. I have argued elsewhere (<ref type="bibl"
                  target="#evolution">Burnard 2013</ref>) that one reason for the TEI&#8217;s
               continued longevity is precisely its ability to mutate and evolve. This ability is
               not without a price: the creation of a customization does require some knowledge of
               the whole architecture, and some technical expertise. For those already expert in
               database or non-TEI XML technologies, and for the novice alike, the effort to
               maintain TEI conformance, may seem an unnecessary additional hurdle. </p>
            <p>These difficulties do not however invalidate the general principle that TEI
               conformance should entail a respect for the consensus, just as much as it facilitates
               autonomy. As we have shown, even in the case of a customization which has eschewed
               extension and appears to be a straightforward TEI subset, an assessment of TEI
               conformance involves attention to some constraints which are not formally verifiable.
               I conclude by suggesting that conformance requires attention to two important if
               largely unenforceable requirements of <q>honesty</q> and <q>explicitness</q>. </p>
            <p>By <q>honesty</q> I mean that elements in the TEI namespace must respect the
               semantics which the TEI Guidelines supply as a part of their definition. For example,
               the TEI defines an element <gi>l</gi> as containing <q>a single, possibly incomplete,
                  line of verse</q>. If an encoding distinguishes verse and prose, it would be
               dishonest to use this element to mark line breaks in prose, since to do so would
               imply that the element contains verse rather than prose. Most TEI elements are
               provided in order to make an assertion about the semantics of a piece of text : that
               it contains a personal name rather than a place name, for example, or a date rather
               than a number. Misapplying such elements is clearly counter-productive. (Honestly
               made misreadings are of course entirely forgiveable: an encoding always asserts an
               interpretation, not the absolute truth of that interpretation)</p>
            <p> By <q>explicitness</q> I mean that modifications should be properly documented,
               preferably by means of an ODD specifying exactly how the TEI declarations on which
               they are based have been derived. (An ODD need not of course be based on the TEI at
               all, but in that case the question of TEI conformance does not arise). The ODD
               language is rich in documentary components, not all of which are automatically
               processable, if only because their processing is not fully specified (the
                  <gi>equiv</gi> and <gi>altIdentifier</gi> elements for example). But it is usually
               much easier to determine how the markup of a set of documents should be interpreted
               or processed from an ODD than it is from the many pages of human-readable
               documentation needed to explain everything about an idiosyncratic encoding scheme. </p>
            <p>To summarize and conclude, I suggest that we should say of a document that it is
                  <q>TEI conformant</q> iff : <list>
                  <item>it is a well formed XML document; and </item>
                  <item>it is valid against one or more schemas, which may be either a TEI subset or
                     a TEI extension; and </item>
                  <item>its usage of elements in the TEI namespace is compatible with the intended
                     function of those elements as defined by the TEI Guidelines; and </item>
                  <item>its usage of the TEI markup scheme is fully described by a TEI-conformant
                     ODD or analogous documentation. </item>
               </list></p>
            <p>The purpose of these rules is to make interchange of documents easier. They do not
               guarantee it, and they certainly do not provide any guarantee of interoperability.
               But they make much simpler for example the kind of scenario envisaged by <ref
                  type="bibl" target="#holmes2016">Holmes 2016</ref> in which a richly encoded
               highly personalised TEI encoding can be simply down-translated to other, possibly
               less expressive, semi-standardized encodings for purposes of interchange. As more and
               more independent agencies undertake mass digitization and encoding projects, the risk
               of a new confusion of tongues — the threatened Tower of Babel which the TEI was
               specifically created to resist — has not retreated. A definition of conformance which
               relies on an enforced lowest common denominator standard (Dublin Core springs to
               mind) makes it hard to benefit from truly sophisticated and scholarly standards. One
               which promotes permissiveness and extensibility, as the TEI does, has to balance the
               sophistication of what it makes feasible with a clear and accessible definition of
               its markup. Unlike many other standards, the goal of the TEI <q>standard</q> is not
               to enforce consistency of encoding, but to provide a means by which encoding choices
               and policies may be more readily understood, and hence more easily made
               algorithmically comparable.</p>
         </div>
      </body>
      <back>
         <div type="bibliography" xml:id="bibliography">
            <listBibl>
               <bibl xml:id="birnb2000">Birnbaum, David J. <title>The Relationship Between General
                     and Specific DTDs: Criticizing TEI Critical Editions</title> in <title
                     level="j">Markup Languages: Theory and Practice,</title> Volume 3 Issue 1,
                  December 2000, Pages 17&#x2013;53); online at <ptr
                     target="http://www.obdurodon.org/djb/tei-crit/"/></bibl>
               <bibl xml:id="bodard2010">Bodard, G. <title level="a">Epidoc: Epigraphic documents in
                     XML for publication and interchange.</title> in <title>Latin on Stone:
                     Epigraphic research and electronic archives</title> eds. Francisca
                  Feraudi-Gruenais and William Stenhouse. Lanham MD: Lexington Books, pp
                  101&#x2013;118. (<date>2010</date>)</bibl>
               <bibl xml:id="evolution">Burnard, Lou <title>The Evolution of the Text Encoding
                     Initiative: From Research Project to Research Infrastructure</title> , <title
                     level="j">Journal of the Text Encoding Initiative</title> [Online], Issue 5 |
                  2013, http://jtei.revues.org/811 ; DOI : 10.4000/jtei.811 </bibl>
               <bibl xml:id="deRose1990">De Rose, S. J., Durand, D. G., Mylonas, E., and Renear A.
                  H. (1990), <title level="a">What is Text, Really?</title> in <title level="j"
                     >Journal of Computing in Higher Education</title>, 1.2: 3&#x2013;26. DOI:
                  10.1007/BF02941632</bibl>
               <bibl xml:id="eco">Eco, Umberto <title>Postscript to The Name of the Rose. </title>
                  Translated by William Weaver. New York: Harcourt, 1984, p42.
                  <!--<title xml:lang="it">Opera aperta</title>. Milano:
               Bompiani. (<date>1962</date>)--></bibl>
               <!-- the novel
...  no longer offers us one story and one plot per book
but tries, rather, to alert us to the presence of more stories and more
plots in the same book 
            The Open Work (transl. Anna Cancogni, Harvard Univ Pr, 1989-->
               <bibl xml:id="holmes2016">Holmes, Martin <title>Whatever happened to
                     interchange?</title> in <title level="j"> Digital Scholarship in the
                     Humanities</title>, 2016. </bibl>
               <bibl xml:id="ISO19757_4">ISO/IEC 197574:2006 Information technology &#x2014;
                  Document Schema Definition Languages (DSDL) &#x2014; Part 4: Namespace-based
                  Validation Dispatching Language (NVDL)</bibl>
               <bibl xml:id="standoff">Pose, Javier, Patrice Lopez, and Laurent Romary. <title>A
                     Generic Formalism for Encoding Stand-off annotations in TEI</title>.
                     <date>2014</date>. <ref target="https://hal.inria.fr/hal-01061548v1"
                     >hal-01061548</ref></bibl>
               <bibl xml:id="rahtzBurnard2004">Burnard, Lou and Sebastian Rahtz: <title>RelaxNG with
                     Son of ODD</title>. Extreme Markup Languages. <ref
                     target="http://conferences.idealliance.org/extreme/html/2004/Burnard01/EML2004Burnard01.html"
                  /></bibl>
               <bibl xml:id="rahtzBurnard2013">Rahtz, Sebastian, and Lou Burnard. <title>Reviewing
                     the TEI ODD System</title>. In <title>Proceedings of the 2013 ACM Symposium on
                     Document Engineering. DocEng ’13.</title> ACM, 2013. <ref
                     target="http://doi.acm.org/10.1145/2494266.2494321."
                     >http://doi.acm.org/10.1145/2494266.2494321.</ref>; <ptr
                     target="https://ora.ox.ac.uk/objects/pubs:434097"/>
               </bibl>
               <bibl xml:id="raymond1996">Raymond, Darrell, Frank Tompa, and Derick Wood. <title
                     level="a">From Data Representation to Data Model: Meta-Semantic Issues in the
                     Evolution of SGML.</title> in <title level="s">Computer Standards &amp;
                     Interfaces</title> 18 (<date>1996</date>): <biblScope unit="page"
                     >25&#x2013;36</biblScope>.
                  doi:10.1016/0920&#x2013;5489(96)00033&#x2013;5</bibl>
               <bibl xml:id="robinson2009"> Robinson, Peter. <title level="a">What text really is
                     not, and why editors have to learn to swim</title>
                  <title level="j"> Literary and Linguistic Computing</title>, Volume 24, Issue 1, 1
                  April 2009, Pages 41–52, https://doi.org/10.1093/llc/fqn030 </bibl>
               <bibl xml:id="edp01">Sperberg-McQueen, C.M. and Lou Burnard <title>Design principles
                     for text encoding guidelines</title> (TEI ED P1, 1988, revised 1990) <ref
                     target="http://www.tei-c.org/Vault/EDP01.html"/></bibl>
               <bibl xml:id="monk2009">Unsworth, John and Martin Mueller.<title>The MONK Project
                     Final Report</title>. <date>September 2, 2009</date>. Online at <ref
                     target="http://www.monkproject.org/MONKProjectFinalReport.pdf"/></bibl>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
